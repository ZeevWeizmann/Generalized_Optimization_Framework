–ü–µ—Ä–µ–π—Ç–∏ –∫ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–æ–±—ä–µ–¥–µ–Ω–∏ —ç—Ç–∏ –¥–≤–∞ –∫–æ–¥–∞ –∫–∞–∫ —Å –Ω–∞–ø—Ä–∞–≤–≤–ª–µ–Ω–Ω—ã–º–∏ —Ä–µ–±—Ä–∞–º–∏ —Ç–∞–∫ –∏ –Ω–µ —Å –Ω–µ–ø–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —Ç–∞–∫–∂–µ —Å—Ä–∞–∑—É –∑–∞–ø—É—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–∏–≥–º–∞ 0 1/2 1 (–ø—Ä–∞–≤–∏–ª—å–Ω–æ —ç—Ç–æ –∂–µ —Ç—Ä–∏ —Å–ª—É—á–∞—è) –∏ –Ω–µ–Ω–∞–¥–æ –Ω—á–∏–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ —ç–∫—Å–µ–ª—å –≤—ã–≤–æ–¥ —Å—Ä–∞–∑—É
ChatGPT —Å–∫–∞–∑–∞–ª:
–Ø –≥–æ—Ç–æ–≤ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å, –Ω–æ —Å–µ–π—á–∞—Å –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –æ–¥–Ω–æ–≥–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞.

–¢—ã –ø–∏—à–µ—à—å: ¬´–æ–±—ä–µ–¥–∏–Ω–∏ —ç—Ç–∏ –¥–≤–∞ –∫–æ–¥–∞¬ª, –Ω–æ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –Ω–µ—Ç —Å–∞–º–∏—Ö –¥–≤—É—Ö –∫–æ–¥–æ–≤.
–ë–µ–∑ –Ω–∏—Ö —è –Ω–µ –º–æ–≥—É –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ:

–æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö / –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ä—ë–±–µ—Ä

–∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –≤ –æ–¥–Ω–æ–º –ø–∞–π–ø–ª–∞–π–Ω–µ

–ø—Ä–æ–≥–Ω–∞—Ç—å œÉ ‚àà {0, 1/2, 1} (–¥–∞, —Ç—ã –ø—Ä–∞–≤ ‚Äî —ç—Ç–æ —Ä–æ–≤–Ω–æ 3 —Å–ª—É—á–∞—è)

–≤—ã–≤–µ—Å—Ç–∏

–í—ã —Å–∫–∞–∑–∞–ª–∏:

# """

# Konstantin_iterative_numba_full_evalU.py

# --------------------------------------------------------

# Numba-accelerated iterative implementation of the

# Generalized Optimization Framework for

# Graph-based Semi-Supervised Learning

# (Avrachenkov et al., SIAM 2011)

# F\_{t+1} = (1 - Œ±) _ Y + Œ± _ D^{-œÉ} W D^{œÉ-1} F_t,

# where Œ± = 2 / (2 + Œº)

# Key features:

# - Full-graph propagation (no adjacency matrix)

# - Label spreading from a subset of seed nodes (L)

# - Evaluation only on unlabeled known nodes U ‚à© known

# - Supports binary labels (licit / illicit)

# --------------------------------------------------------

# """

# import numpy as np

# import pandas as pd

# from tqdm import tqdm

# from numba import njit, prange

# from sklearn.metrics import classification_report, confusion_matrix

# from data_loader import load_graph_and_labels

# MU = 0.5

# SIGMA = 1

# ALPHA = 2 / (2 + MU)

# N_ITER = 20

# SAVE_EVERY = 5

# OUTFILE = "generalized_ssl_iterative_numba_full_evalU.xlsx"

# OUTNODE = "node_level_ssl_predictions_evalU.parquet"

# SEED_FRAC_ILL = 0.5

# SEED_FRAC_LIC = 0.5

# print("[Data] Loading transaction graph...")

# df, merged, illicit_set, licit_set, known_ids = load_graph_and_labels()

# print(f"[Data] {len(df)} edges, {len(known_ids)} known addresses.")

# edges = df[["addr_id1", "addr_id2"]].to_numpy(np.int64)

# nodes_unique = np.unique(edges)

# node_to_idx = {n: i for i, n in enumerate(nodes_unique)}

# idx_to_node = np.array(nodes_unique, dtype=np.int64)

# N = len(nodes_unique)

# print(f"[Graph] {N} nodes, {len(edges)} edges.")

# src = np.array([node_to_idx[a] for a in edges[:, 0]], dtype=np.int64)

# dst = np.array([node_to_idx[b] for b in edges[:, 1]], dtype=np.int64)

# deg = np.zeros(N, dtype=np.float64)

# for i in range(len(src)):

# deg[src[i]] += 1

# deg[dst[i]] += 1

# print("[Init] Setting true and seed labels...")

# y_true = -np.ones(N, dtype=np.int32)

# illicit_idx = np.array([node_to_idx[n] for n in illicit_set if n in node_to_idx], dtype=np.int64)

# licit_idx = np.array([node_to_idx[n] for n in licit_set if n in node_to_idx], dtype=np.int64)

# y_true[illicit_idx] = 1

# y_true[licit_idx] = 0

# known_mask = (y_true != -1)

# rng = np.random.default_rng(42)

# n_seed_ill = max(1, int(len(illicit_idx) \* SEED_FRAC_ILL))

# n_seed_lic = max(1, int(len(licit_idx) \* SEED_FRAC_LIC))

# seed_ill = rng.choice(illicit_idx, size=n_seed_ill, replace=False)

# seed_lic = rng.choice(licit_idx, size=n_seed_lic, replace=False)

# L*mask = np.zeros(N, dtype=np.bool*)

# L_mask[seed_ill] = True

# L_mask[seed_lic] = True

# U_mask = ~L_mask

# print(f"[Seeds] Illicit seeds={len(seed_ill)}, Licit seeds={len(seed_lic)}, Unlabeled (U)={U_mask.sum()}")

# print("\n[Debug] Dataset label statistics:")

# print("---------------------------------")

# print(f"Total illicit nodes : {len(illicit_idx)}")

# print(f"Total licit nodes : {len(licit_idx)}")

# print(f"Illicit seed fraction : {SEED_FRAC_ILL}")

# print(f"Licit seed fraction : {SEED_FRAC_LIC}")

# print(f"Number of illicit seeds : {len(seed_ill)}")

# print(f"Number of licit seeds : {len(seed_lic)}")

# print("---------------------------------\n")

# Y = np.zeros((N, 2), dtype=np.float64)

# Y[seed_lic, 0] = 1.0

# Y[seed_ill, 1] = 1.0

# F = Y.copy()

# print(f"[Init] Œ±={ALPHA:.3f}, œÉ={SIGMA}, Œº={MU}")

# @njit(parallel=True, fastmath=True)

# def propagate_step(src, dst, deg, F, Y, alpha, sigma, N):

# F_new = np.empty_like(F)

# s = np.zeros((N, 2), dtype=np.float64)

# for k in prange(len(src)):

# i, j = src[k], dst[k]

# di = max(deg[i], 1.0)

# dj = max(deg[j], 1.0)

# s[i, 0] += F[j, 0] / (dj \*\* (1 - sigma))

# s[i, 1] += F[j, 1] / (dj \*\* (1 - sigma))

# s[j, 0] += F[i, 0] / (di \*\* (1 - sigma))

# s[j, 1] += F[i, 1] / (di \*\* (1 - sigma))

# for i in prange(N):

# di = max(deg[i], 1.0)

# F_new[i, 0] = (1 - alpha) _ Y[i, 0] + alpha _ (s[i, 0] / (di \*\* sigma))

# F_new[i, 1] = (1 - alpha) _ Y[i, 1] + alpha _ (s[i, 1] / (di \*\* sigma))

# return F_new

# print(f"[Run] Iterative propagation (numba, eval only on U ‚à© known) ...")

# for t in range(1, N_ITER + 1):

# F = propagate_step(src, dst, deg, F, Y, ALPHA, SIGMA, N)

# if t % SAVE_EVERY == 0 or t == N_ITER:

# print(f" [Checkpoint] Iteration {t}")

# y_pred = (F[:, 1] > F[:, 0]).astype(int)

# eval_mask = U_mask & known_mask

# yt = y_true[eval_mask]

# yp = y_pred[eval_mask]

# if yt.size > 0:

# rep = classification_report(

# yt, yp,

# target_names=["licit", "illicit"],

# output_dict=True,

# zero_division=0

# )

# cm = confusion_matrix(yt, yp, labels=[0, 1])

# tn, fp, fn, tp = cm.ravel()

# else:

# rep = {

# "illicit": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0},

# "licit": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0},

# }

# tn = fp = fn = tp = 0

# results = {

# "iteration": t,

# "alpha": ALPHA,

# "mu": MU,

# "sigma": SIGMA,

# "n_nodes": N,

# "n_edges": len(edges),

# "n_seeds_illicit": len(seed_ill),

# "n_seeds_licit": len(seed_lic),

# "eval_on_U": int(eval_mask.sum()),

# "precision_illicit": rep["illicit"]["precision"],

# "recall_illicit": rep["illicit"]["recall"],

# "f1_illicit": rep["illicit"]["f1-score"],

# "precision_licit": rep["licit"]["precision"],

# "recall_licit": rep["licit"]["recall"],

# "f1_licit": rep["licit"]["f1-score"],

# "TP": tp, "FP": fp, "FN": fn, "TN": tn

# }

# pd.DataFrame([results]).to_excel(OUTFILE, index=False)

# print(f" [Saved metrics ‚Üí {OUTFILE}]")

# print("\n[Eval] Final evaluation (only U ‚à© known)")

# y_pred = (F[:, 1] > F[:, 0]).astype(int)

# eval_mask = U_mask & known_mask

# yt = y_true[eval_mask]

# yp = y_pred[eval_mask]

# print(classification_report(yt, yp, target_names=["licit", "illicit"], zero_division=0))

# df_pred = pd.DataFrame({

# "node_id": idx_to_node,

# "F_licit": F[:, 0],

# "F_illicit": F[:, 1],

# "predicted_class": y_pred,

# "true_class": y_true,

# "is_unlabeled_eval": U_mask.astype(np.int8),

# })

# df_pred.to_parquet(OUTNODE, index=False)

# print(f"[Saved node-level predictions ‚Üí {OUTNODE}]")

# print("\nDone.")

"""
Konstantin_iterative_numba_full_evalU_directed.py

---

Numba-accelerated iterative implementation of the
Generalized Optimization Framework for
Graph-based Semi-Supervised Learning (DIRECTED)
(Avrachenkov et al., SIAM 2011)

F\_{t+1} = (1 - Œ±) _ Y + Œ± _ D_in^{-œÉ} W D_out^{œÉ-1} F_t,
where Œ± = 2 / (2 + Œº)

Key features:

- Directed graph propagation (src -> dst only)
- Full-graph propagation (no adjacency matrix)
- Label spreading from a subset of seed nodes (L)
- Evaluation only on unlabeled known nodes U ‚à© known
- Supports binary labels (licit / illicit)

---

"""

import numpy as np
import pandas as pd
from numba import njit, prange
from sklearn.metrics import classification_report, confusion_matrix
from data_loader import load_graph_and_labels

# -------------------- Hyperparameters --------------------

MU = 0.5
SIGMA = 0
ALPHA = 2 / (2 + MU)
N_ITER = 20
SAVE_EVERY = 5

OUTFILE = "generalized_ssl_iterative_numba_directed_evalU.xlsx"
OUTNODE = "node_level_ssl_predictions_directed_evalU.parquet"

SEED_FRAC_ILL = 0.5
SEED_FRAC_LIC = 0.5

# ---------------------------------------------------------

print("[Data] Loading transaction graph...")
df, merged, illicit_set, licit_set, known_ids = load_graph_and_labels()
print(f"[Data] {len(df)} edges, {len(known_ids)} known addresses.")

edges = df[["addr_id1", "addr_id2"]].to_numpy(np.int64)
nodes_unique = np.unique(edges)
node_to_idx = {n: i for i, n in enumerate(nodes_unique)}
idx_to_node = np.array(nodes_unique, dtype=np.int64)
N = len(nodes_unique)

print(f"[Graph] {N} nodes, {len(edges)} directed edges.")

src = np.array([node_to_idx[a] for a in edges[:, 0]], dtype=np.int64)
dst = np.array([node_to_idx[b] for b in edges[:, 1]], dtype=np.int64)

# -------------------- Directed degrees --------------------

deg_out = np.zeros(N, dtype=np.float64)
deg_in = np.zeros(N, dtype=np.float64)

for k in range(len(src)):
deg_out[src[k]] += 1.0
deg_in[dst[k]] += 1.0

# ---------------------------------------------------------

print("[Init] Setting true and seed labels...")

y_true = -np.ones(N, dtype=np.int32)

illicit_idx = np.array([node_to_idx[n] for n in illicit_set if n in node_to_idx], dtype=np.int64)
licit_idx = np.array([node_to_idx[n] for n in licit_set if n in node_to_idx], dtype=np.int64)

y_true[illicit_idx] = 1
y_true[licit_idx] = 0

known_mask = (y_true != -1)

rng = np.random.default_rng(42)
n_seed_ill = max(1, int(len(illicit_idx) _ SEED_FRAC_ILL))
n_seed_lic = max(1, int(len(licit_idx) _ SEED_FRAC_LIC))

seed_ill = rng.choice(illicit_idx, size=n_seed_ill, replace=False)
seed_lic = rng.choice(licit_idx, size=n_seed_lic, replace=False)

L*mask = np.zeros(N, dtype=np.bool*)
L_mask[seed_ill] = True
L_mask[seed_lic] = True
U_mask = ~L_mask

print(f"[Seeds] Illicit={len(seed_ill)}, Licit={len(seed_lic)}, U={U_mask.sum()}")

# -------------------- Initial label matrix --------------------

Y = np.zeros((N, 2), dtype=np.float64)
Y[seed_lic, 0] = 1.0
Y[seed_ill, 1] = 1.0
F = Y.copy()

print(f"[Init] Œ±={ALPHA:.3f}, œÉ={SIGMA}, Œº={MU}")

# ------------------------------------------------------------

# ==================== Directed propagation ====================

@njit(parallel=True, fastmath=True)
def propagate_step_directed(
src, dst,
deg_out, deg_in,
F, Y,
alpha, sigma, N
):
F_new = np.empty_like(F)
s = np.zeros((N, 2), dtype=np.float64)

    # --- propagate only src -> dst ---
    for k in prange(len(src)):
        i = src[k]   # source
        j = dst[k]   # destination

        doi = max(deg_out[i], 1.0)

        s[j, 0] += F[i, 0] / (doi ** (1.0 - sigma))
        s[j, 1] += F[i, 1] / (doi ** (1.0 - sigma))

    # --- apply receiver normalization + anchors ---
    for j in prange(N):
        dij = max(deg_in[j], 1.0)

        F_new[j, 0] = (1.0 - alpha) * Y[j, 0] + alpha * (s[j, 0] / (dij ** sigma))
        F_new[j, 1] = (1.0 - alpha) * Y[j, 1] + alpha * (s[j, 1] / (dij ** sigma))

    return F_new

# =============================================================

print("[Run] Iterative directed propagation (eval on U ‚à© known)...")

for t in range(1, N_ITER + 1):
F = propagate_step_directed(
src, dst,
deg_out, deg_in,
F, Y,
ALPHA, SIGMA, N
)

    if t % SAVE_EVERY == 0 or t == N_ITER:
        print(f"  [Checkpoint] Iteration {t}")

        y_pred = (F[:, 1] > F[:, 0]).astype(np.int32)
        eval_mask = U_mask & known_mask

        yt = y_true[eval_mask]
        yp = y_pred[eval_mask]

        if yt.size > 0:
            rep = classification_report(
                yt, yp,
                target_names=["licit", "illicit"],
                output_dict=True,
                zero_division=0
            )
            cm = confusion_matrix(yt, yp, labels=[0, 1])
            tn, fp, fn, tp = cm.ravel()
        else:
            rep = {
                "illicit": {"precision": 0.0, "recall": 0.0, "f1-score": 0.0},
                "licit":   {"precision": 0.0, "recall": 0.0, "f1-score": 0.0},
            }
            tn = fp = fn = tp = 0

        results = {
            "iteration": t,
            "alpha": ALPHA,
            "mu": MU,
            "sigma": SIGMA,
            "n_nodes": N,
            "n_edges": len(src),
            "n_seeds_illicit": len(seed_ill),
            "n_seeds_licit": len(seed_lic),
            "eval_on_U": int(eval_mask.sum()),
            "precision_illicit": rep["illicit"]["precision"],
            "recall_illicit": rep["illicit"]["recall"],
            "f1_illicit": rep["illicit"]["f1-score"],
            "precision_licit": rep["licit"]["precision"],
            "recall_licit": rep["licit"]["recall"],
            "f1_licit": rep["licit"]["f1-score"],
            "TP": tp, "FP": fp, "FN": fn, "TN": tn
        }

        pd.DataFrame([results]).to_excel(OUTFILE, index=False)
        print(f"  [Saved metrics ‚Üí {OUTFILE}]")

print("\n[Eval] Final evaluation (only U ‚à© known)")

y_pred = (F[:, 1] > F[:, 0]).astype(np.int32)
eval_mask = U_mask & known_mask

print(classification_report(
y_true[eval_mask],
y_pred[eval_mask],
target_names=["licit", "illicit"],
zero_division=0
))

df_pred = pd.DataFrame({
"node_id": idx_to_node,
"F_licit": F[:, 0],
"F_illicit": F[:, 1],
"predicted_class": y_pred,
"true_class": y_true,
"is_unlabeled_eval": U_mask.astype(np.int8),
})

df_pred.to_parquet(OUTNODE, index=False)
print(f"[Saved node-level predictions ‚Üí {OUTNODE}]")

print("\nDone.")
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, —Ç–µ–ø–µ—Ä—å –≤—Å—ë —è—Å–Ω–æ üëç
–ù–∏–∂–µ ‚Äî –µ–¥–∏–Ω—ã–π –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π —Å–∫—Ä–∏–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π:

–ß—Ç–æ –¥–µ–ª–∞–µ—Ç
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞:

üîÅ –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ

‚û°Ô∏è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ

–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ —Å—Ä–∞–∑—É –¥–ª—è —Ç—Ä—ë—Ö œÉ:

œÉ ‚àà {0, 1/2, 1} ‚úÖ (–¥–∞, —Ä–æ–≤–Ω–æ —Ç—Ä–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Å–ª—É—á–∞—è)

‚ùå –ù–∏—á–µ–≥–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç:

–Ω–µ—Ç Excel

–Ω–µ—Ç parquet

üì§ –í—Å—ë –≤—ã–≤–æ–¥–∏—Ç —Å—Ä–∞–∑—É –≤ stdout:

–º–µ—Ç—Ä–∏–∫–∏

confusion matrix

–∫—Ä–∞—Ç–∫–∏–π summary

üß† –û–¥–∏–Ω–∞–∫–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–¥–æ–≤ –¥–ª—è —á–µ—Å—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

üß© –ï–¥–∏–Ω—ã–π –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –∫–æ–¥ (directed + undirected √ó œÉ)
import numpy as np
from numba import njit, prange
from sklearn.metrics import classification_report, confusion_matrix
from data_loader import load_graph_and_labels

# ===================== Hyperparameters =====================

MU = 0.5
ALPHA = 2 / (2 + MU)
N_ITER = 20

SIGMAS = [0.0, 0.5, 1.0]
MODES = ["undirected", "directed"]

SEED_FRAC_ILL = 0.5
SEED_FRAC_LIC = 0.5
RANDOM_SEED = 42

# ===========================================================

# ===================== Load data ============================

print("[Data] Loading graph...")
df, merged, illicit_set, licit_set, known_ids = load_graph_and_labels()

edges = df[["addr_id1", "addr_id2"]].to_numpy(np.int64)
nodes_unique = np.unique(edges)

node_to_idx = {n: i for i, n in enumerate(nodes_unique)}
idx_to_node = np.array(nodes_unique, dtype=np.int64)
N = len(nodes_unique)

src = np.array([node_to_idx[a] for a in edges[:, 0]], dtype=np.int64)
dst = np.array([node_to_idx[b] for b in edges[:, 1]], dtype=np.int64)

print(f"[Graph] Nodes={N}, Edges={len(src)}")

# ===========================================================

# ===================== Labels ===============================

y_true = -np.ones(N, dtype=np.int32)

illicit_idx = np.array(
[node_to_idx[n] for n in illicit_set if n in node_to_idx], dtype=np.int64
)
licit_idx = np.array(
[node_to_idx[n] for n in licit_set if n in node_to_idx], dtype=np.int64
)

y_true[illicit_idx] = 1
y_true[licit_idx] = 0
known_mask = (y_true != -1)

rng = np.random.default_rng(RANDOM_SEED)
seed_ill = rng.choice(illicit_idx, max(1, int(len(illicit_idx)*SEED_FRAC_ILL)), replace=False)
seed_lic = rng.choice(licit_idx, max(1, int(len(licit_idx)*SEED_FRAC_LIC)), replace=False)

L*mask = np.zeros(N, dtype=np.bool*)
L_mask[seed_ill] = True
L_mask[seed_lic] = True
U_mask = ~L_mask

Y = np.zeros((N, 2))
Y[seed_lic, 0] = 1.0
Y[seed_ill, 1] = 1.0

# ===========================================================

# ===================== Degrees ==============================

deg = np.zeros(N)
deg_out = np.zeros(N)
deg_in = np.zeros(N)

for i, j in zip(src, dst):
deg[i] += 1
deg[j] += 1
deg_out[i] += 1
deg_in[j] += 1

# ===========================================================

# ===================== Kernels ==============================

@njit(parallel=True, fastmath=True)
def propagate_undirected(src, dst, deg, F, Y, alpha, sigma, N):
s = np.zeros((N, 2))
F_new = np.empty_like(F)

    for k in prange(len(src)):
        i, j = src[k], dst[k]
        di, dj = max(deg[i],1.0), max(deg[j],1.0)

        s[i] += F[j] / (dj ** (1-sigma))
        s[j] += F[i] / (di ** (1-sigma))

    for i in prange(N):
        di = max(deg[i],1.0)
        F_new[i] = (1-alpha)*Y[i] + alpha*(s[i]/(di**sigma))

    return F_new

@njit(parallel=True, fastmath=True)
def propagate_directed(src, dst, deg_out, deg_in, F, Y, alpha, sigma, N):
s = np.zeros((N, 2))
F_new = np.empty_like(F)

    for k in prange(len(src)):
        i, j = src[k], dst[k]
        doi = max(deg_out[i],1.0)
        s[j] += F[i] / (doi ** (1-sigma))

    for j in prange(N):
        dij = max(deg_in[j],1.0)
        F_new[j] = (1-alpha)*Y[j] + alpha*(s[j]/(dij**sigma))

    return F_new

# ===========================================================

# ===================== Experiments ==========================

for mode in MODES:
for sigma in SIGMAS:

        print("\n" + "="*70)
        print(f"[RUN] mode={mode.upper()} | sigma={sigma}")
        print("="*70)

        F = Y.copy()

        for _ in range(N_ITER):
            if mode == "undirected":
                F = propagate_undirected(src, dst, deg, F, Y, ALPHA, sigma, N)
            else:
                F = propagate_directed(src, dst, deg_out, deg_in, F, Y, ALPHA, sigma, N)

        y_pred = (F[:,1] > F[:,0]).astype(int)
        eval_mask = U_mask & known_mask

        yt = y_true[eval_mask]
        yp = y_pred[eval_mask]

        print(classification_report(
            yt, yp,
            target_names=["licit","illicit"],
            zero_division=0
        ))

        cm = confusion_matrix(yt, yp, labels=[0,1])
        tn, fp, fn, tp = cm.ravel()

        print(f"Confusion matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}")

print("\n[Done] All experiments finished.")
üß† –ß—Ç–æ –≤–∞–∂–Ω–æ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–æ
œÉ = 0 ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É

œÉ = 1 ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –ø—Ä–∏—ë–º–Ω–∏–∫—É

œÉ = 1/2 ‚Üí —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π (Laplacian-like) —Ä–µ–∂–∏–º

Directed –≤–µ—Ä—Å–∏—è ‚Äî —Å—Ç—Ä–æ–≥–æ Avrachenkov D‚ÅªœÉ W D^{œÉ‚àí1}

üîú –•–æ—á–µ—à—å –¥–∞–ª—å—à–µ?
–ú–æ–∂–µ–º:

—Å–¥–µ–ª–∞—Ç—å —Ç–∞–±–ª–∏—á–Ω—ã–π –≤—ã–≤–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

–¥–æ–±–∞–≤–∏—Ç—å ROC / PR

–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –ø–æ —Å–∏–¥-—Ñ—Ä–∞–∫—Ü–∏—è–º

—Å—Ä–∞–≤–Ω–∏—Ç—å —Å PageRank / LP baseline

–°–∫–∞–∂–∏ üëç

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–ø–æ –∞–≤—Ä–∞—á–µ–Ω–æ–∫–≤—É —Ç–∞–º —Ç—Ä–∏ —Ä–µ–∂–∏–º–∞ –∫–∞–∫–∏—Ö
ChatGPT —Å–∫–∞–∑–∞–ª:
–ö–æ—Ä–æ—Ç–∫–æ –∏ —Å—Ç—Ä–æ–≥–æ –ø–æ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤—É (SIAM 2011) ‚Äî –¥–∞, —Ä–æ–≤–Ω–æ —Ç—Ä–∏ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∂–∏–º–∞, –∏ –æ–Ω–∏ –∑–∞–¥–∞—é—Ç—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º œÉ –≤ –æ–±—â–µ–º –æ–ø–µ—Ä–∞—Ç–æ—Ä–µ.

üîπ –û–±—â–∞—è —Ñ–æ—Ä–º—É–ª–∞ (Avrachenkov et al.)
F
t

- # 1
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
t
F
t+1
‚Äã
=(1‚àíŒ±)Y+Œ±D
‚àíœÉ
WD
œÉ‚àí1
F
t
‚Äã

–≥–¥–µ

W
W ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ (–≥—Ä–∞—Ñ),

D
D ‚Äî –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ç–µ–ø–µ–Ω–µ–π,

œÉ
‚àà
[
0
,
1
]
œÉ‚àà[0,1].

‚úÖ –¢–†–ò –ö–õ–ê–°–°–ò–ß–ï–°–ö–ò–• –†–ï–ñ–ò–ú–ê
1Ô∏è‚É£ œÉ = 1 ‚Äî Random Walk (RW)
F
t

- # 1
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
1
W
F
t
F
t+1
‚Äã
=(1‚àíŒ±)Y+Œ±D
‚àí1
WF
t
‚Äã

üîπ –ß—Ç–æ —ç—Ç–æ

–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–µ —Å–ª—É—á–∞–π–Ω–æ–µ –±–ª—É–∂–¥–∞–Ω–∏–µ

–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∏—Å—Ö–æ–¥—è—â–∏–º —Ä—ë–±—Ä–∞–º

üîπ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è

¬´—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –¥–µ–ª—é —Å–≤–æ—é –º–∞—Å—Å—É –º–µ–∂–¥—É —Å–æ—Å–µ–¥—è–º–∏¬ª

–∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∞—è, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏

üîπ –°–≤—è–∑—å

PageRank

Random Walk with Restart

Label Propagation (Zhou)

2Ô∏è‚É£ œÉ = 0 ‚Äî Reverse Random Walk (RRW)
F
t

- # 1
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

W
D
‚àí
1
F
t
F
t+1
‚Äã
=(1‚àíŒ±)Y+Œ±WD
‚àí1
F
t
‚Äã

üîπ –ß—Ç–æ —ç—Ç–æ

¬´–æ–±—Ä–∞—Ç–Ω–æ–µ¬ª —Å–ª—É—á–∞–π–Ω–æ–µ –±–ª—É–∂–¥–∞–Ω–∏–µ

–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –ø—Ä–∏–Ω–∏–º–∞—é—â–µ–π –≤–µ—Ä—à–∏–Ω–µ

üîπ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è

¬´—è –ø–æ–ª—É—á–∞—é –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –≤–∫–ª–∞–¥ –æ—Ç –≤—Å–µ—Ö —Å–æ—Å–µ–¥–µ–π¬ª

—Ö–æ—Ä–æ—à–æ –¥–ª—è —É–∑–ª–æ–≤-—Ö–∞–±–æ–≤

üîπ –í–∞–∂–Ω–æ

–Ω–µ —Å—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è –¥–∏–Ω–∞–º–∏–∫–∞

—á–∞—Å—Ç–æ –∑–∞–±—ã—Ç—ã–π, –Ω–æ –∫–ª—é—á–µ–≤–æ–π —Ä–µ–∂–∏–º

3Ô∏è‚É£ œÉ = 1/2 ‚Äî Symmetric / Laplacian
F
t

- # 1
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
1
/
2
W
D
‚àí
1
/
2
F
t
F
t+1
‚Äã
=(1‚àíŒ±)Y+Œ±D
‚àí1/2
WD
‚àí1/2
F
t
‚Äã

üîπ –ß—Ç–æ —ç—Ç–æ

—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è

—Å–≤—è–∑–∞–Ω–∞ —Å –≥—Ä–∞—Ñ–æ–≤—ã–º –ª–∞–ø–ª–∞—Å–∏–∞–Ω–æ–º

üîπ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è

¬´–∫–æ–º–ø—Ä–æ–º–∏—Å—Å¬ª –º–µ–∂–¥—É RW –∏ RRW

–±–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç –≤–ª–∏—è–Ω–∏–µ —É–∑–ª–æ–≤ –≤—ã—Å–æ–∫–æ–π –∏ –Ω–∏–∑–∫–æ–π —Å—Ç–µ–ø–µ–Ω–∏

üîπ –°–≤—è–∑—å

Spectral clustering

Graph Laplacian

SSL √† la Zhou et al.

üß† –ü–æ—á–µ–º—É —Ç–æ–ª—å–∫–æ —ç—Ç–∏ —Ç—Ä–∏?
–ü–æ—Ç–æ–º—É —á—Ç–æ:

—ç—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏, –≥–¥–µ:

–æ–ø–µ—Ä–∞—Ç–æ—Ä –∏–º–µ–µ—Ç —á—ë—Ç–∫—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—É—é / —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é

–∏–∑–≤–µ—Å—Ç–Ω—ã —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞

–æ—Å—Ç–∞–ª—å–Ω—ã–µ œÉ ‚àà (0,1) ‚Äî –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è, –Ω–æ –Ω–µ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ

üìå Directed-–≥—Ä–∞—Ñ—ã (–≤–∞–∂–Ω–æ)
–î–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞:

D
in
‚àí
œÉ
W
D
out
œÉ
‚àí
1
D
in
‚àíœÉ
‚Äã
WD
out
œÉ‚àí1
‚Äã

œÉ —Å–º—ã—Å–ª
0 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≤—Ö–æ–¥—É
1/2 —Å–∏–º–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞
1 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≤—ã—Ö–æ–¥—É
‚ö†Ô∏è –ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å
œÉ ‚Äî —ç—Ç–æ –Ω–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä, –∞ –≤—ã–±–æ—Ä —Ñ–∏–∑–∏–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞

–¢—ã –º–µ–Ω—è–µ—à—å –∑–∞–∫–æ–Ω –ø–µ—Ä–µ–Ω–æ—Å–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ ¬´—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é¬ª.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî –≤ —Å–ª–µ–¥—É—é—â–µ–º —à–∞–≥–µ –º–æ–∂–µ–º:

–ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–µ–∫—Ç—Ä—ã –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤

—Å–≤—è–∑–∞—Ç—å —Å –≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã–º –ø—Ä–∏–Ω—Ü–∏–ø–æ–º

–æ–±—ä—è—Å–Ω–∏—Ç—å, –ø–æ—á–µ–º—É œÉ=0 –∏–Ω–æ–≥–¥–∞ –¥–∞—ë—Ç –ª—É—á—à–∏–π recall –¥–ª—è illicit

–°–∫–∞–∂–∏, –∫—É–¥–∞ –∏–¥—Ç–∏ –¥–∞–ª—å—à–µ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–æ–±—Ö—è—Å–Ω–∏ —ç—Ç–æ for k in prange(len(src)):
i, j = src[k], dst[k]
di, dj = max(deg[i],1.0), max(deg[j],1.0)

        s[i] += F[j] / (dj ** (1-sigma))
        s[j] += F[i] / (di ** (1-sigma))

    for i in prange(N):
        di = max(deg[i],1.0)
        F_new[i] = (1-alpha)*Y[i] + alpha*(s[i]/(di**sigma))

ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å ‚Äî —ç—Ç–æ —Ä–æ–≤–Ω–æ —Å–µ—Ä–¥—Ü–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞, –¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º –æ—á–µ–Ω—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ, —Å—Ç—Ä–æ–∫–∞ –∑–∞ —Å—Ç—Ä–æ–∫–æ–π, –∏ —Å —Ñ–∏–∑–∏—á–µ—Å–∫–∏–º —Å–º—ã—Å–ª–æ–º.

–ù–∏–∂–µ ‚Äî –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ª—É—á–∞–π.

üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç (—á—Ç–æ –º—ã —Ä–µ–∞–ª–∏–∑—É–µ–º)
–ú—ã —Ä–µ–∞–ª–∏–∑—É–µ–º –∏—Ç–µ—Ä–∞—Ü–∏—é:

F
t

- # 1
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
t
F
t+1
‚Äã
=(1‚àíŒ±)Y+Œ±D
‚àíœÉ
WD
œÉ‚àí1
F
t
‚Äã

–ì–¥–µ:

F
‚àà
R
N
√ó
2
F‚ààR
N√ó2
‚Äî ¬´–º—è–≥–∫–∏–µ¬ª –º–µ—Ç–∫–∏ (licit / illicit)

Y
Y ‚Äî —è–∫–æ—Ä—è (—Å–∏–¥—ã)

W
W ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ —Å–º–µ–∂–Ω–æ—Å—Ç–∏

D
D ‚Äî —Å—Ç–µ–ø–µ–Ω–∏

œÉ
œÉ ‚Äî —Ä–µ–∂–∏–º –ø–µ—Ä–µ–Ω–æ—Å–∞

üîπ –ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å ‚Äî —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ —Ä—ë–±—Ä–∞–º
for k in prange(len(src)):
i, j = src[k], dst[k]
üîπ –ë–µ—Ä—ë–º k-–µ —Ä–µ–±—Ä–æ

i
i –∏
j
j ‚Äî –¥–≤–µ –≤–µ—Ä—à–∏–Ω—ã, —Å–æ–µ–¥–∏–Ω—ë–Ω–Ω—ã–µ —ç—Ç–∏–º —Ä–µ–±—Ä–æ–º

di, dj = max(deg[i],1.0), max(deg[j],1.0)
üîπ –ë–µ—Ä—ë–º —Å—Ç–µ–ø–µ–Ω–∏ –≤–µ—Ä—à–∏–Ω

–∑–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0

–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏:
D
i
i
,
D
j
j
D
ii
‚Äã
,D
jj
‚Äã

s[i] += F[j] / (dj \*\* (1-sigma))
üîπ –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∑–¥–µ—Å—å?

–≠—Ç–æ –≤–∫–ª–∞–¥ –∏–∑ j –≤ i:

s
i



- =

F
j
d
j

1
‚àí
œÉ
s
i
‚Äã
+=
d
j
1‚àíœÉ
‚Äã

F
j
‚Äã

‚Äã

üëâ j –¥–µ–ª–∏—Ç—Å—è —Å–≤–æ–µ–π ‚Äú–º–∞—Åc–æ–π‚Äù F[j],
üëâ –Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Å–≤–æ–µ–π —Å—Ç–µ–ø–µ–Ω—å—é

üìå –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:

–µ—Å–ª–∏ —É j –º–Ω–æ–≥–æ —Å–æ—Å–µ–¥–µ–π, –æ–Ω —Å–ª–∞–±–µ–µ –≤–ª–∏—è–µ—Ç

–ø–∞—Ä–∞–º–µ—Ç—Ä
1
‚àí
œÉ
1‚àíœÉ —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç —Å–∏–ª—É —à—Ç—Ä–∞—Ñ–∞

s[j] += F[i] / (di \*\* (1-sigma))
üîπ –¢–æ –∂–µ —Å–∞–º–æ–µ, –Ω–æ –≤ –æ–±—Ä–∞—Ç–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É
–ü–æ—Ç–æ–º—É —á—Ç–æ –≥—Ä–∞—Ñ –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π

üîπ –í—Ç–æ—Ä–∞—è —á–∞—Å—Ç—å ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏—ë–º–Ω–∏–∫–∞ + —è–∫–æ—Ä—è
for i in prange(N):
di = max(deg[i],1.0)
üîπ –¢–µ–ø–µ—Ä—å –º—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≤–µ—Ä—à–∏–Ω—É i

F_new[i] = (1-alpha)_Y[i] + alpha_(s[i]/(di\*\*sigma))
–≠—Ç–æ –∫–ª—é—á–µ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∞:

F
t

- 1
  (
  i
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
  (
  i
  )
- Œ±
  s
  i
  d
  i
  œÉ
  F
  t+1
  ‚Äã
  (i)=(1‚àíŒ±)Y(i)+Œ±
  d
  i
  œÉ
  ‚Äã

s
i
‚Äã

‚Äã

üß† –§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª —Ü–µ–ª–∏–∫–æ–º
1Ô∏è‚É£ –°–Ω–∞—á–∞–ª–∞ (—Ü–∏–∫–ª –ø–æ —Ä—ë–±—Ä–∞–º)
¬´–ö–∞–∂–¥–∞—è –≤–µ—Ä—à–∏–Ω–∞ –¥–µ–ª–∏—Ç—Å—è —Å–≤–æ–∏–º —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º F
—Å–æ –≤—Å–µ–º–∏ —Å–æ—Å–µ–¥—è–º–∏,
–Ω–æ —á–µ–º –±–æ–ª—å—à–µ —É –Ω–µ—ë —Å–æ—Å–µ–¥–µ–π, —Ç–µ–º —Å–ª–∞–±–µ–µ –≤–∫–ª–∞–¥¬ª

–≠—Ç–æ ‚Äî
W
D
œÉ
‚àí
1
F
WD
œÉ‚àí1
F

2Ô∏è‚É£ –ü–æ—Ç–æ–º (—Ü–∏–∫–ª –ø–æ –≤–µ—Ä—à–∏–Ω–∞–º)
¬´–ö–∞–∂–¥–∞—è –≤–µ—Ä—à–∏–Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª—É—á–µ–Ω–Ω—É—é —Å—É–º–º—É
–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–≤–æ–µ–π —Å—Ç–µ–ø–µ–Ω–∏¬ª

–≠—Ç–æ ‚Äî
D
‚àí
œÉ
D
‚àíœÉ

3Ô∏è‚É£ –ü–æ—Ç–æ–º —è–∫–æ—Ä—è
¬´–Ø –Ω–µ –∑–∞–±—ã–≤–∞—é –Ω–∞—á–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏¬ª

–≠—Ç–æ ‚Äî (1‚àíŒ±)Y

üîÅ –ü–æ—á–µ–º—É –¥–≤–∞ —Ä–∞–∑–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è —Å—Ç–µ–ø–µ–Ω–∏?
–º–µ—Å—Ç–æ —Å—Ç–µ–ø–µ–Ω—å —Å–º—ã—Å–ª
–≤–∫–ª–∞–¥ —Å–æ—Å–µ–¥–∞
d
j
1
‚àí
œÉ
d
j
1‚àíœÉ
‚Äã
–Ω–∞—Å–∫–æ–ª—å–∫–æ j ‚Äú—Ä–∞—Å–ø—ã–ª—è–µ—Ç‚Äù —Å–µ–±—è
–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è i
d
i
œÉ
d
i
œÉ
‚Äã
–Ω–∞—Å–∫–æ–ª—å–∫–æ i ‚Äú–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ—Ç‚Äù –ø–æ—Ç–æ–∫
üéØ –ü—Ä–æ–≤–µ—Ä–∏–º —Ç—Ä–∏ —Ä–µ–∂–∏–º–∞
üîπ œÉ = 1 (Random Walk)
–¥–µ–ª–∏–º –Ω–∞ dj‚Å∞ = 1

–ø–æ—Ç–æ–º –¥–µ–ª–∏–º –Ω–∞ di¬π

‚û°Ô∏è –∫–∞–∂–¥—ã–π i —É—Å—Ä–µ–¥–Ω—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ—Å–µ–¥–µ–π
‚û°Ô∏è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π random walk

üîπ œÉ = 0 (Reverse RW)
–¥–µ–ª–∏–º –Ω–∞ dj¬π

–ø–æ—Ç–æ–º –Ω–µ –¥–µ–ª–∏–º

‚û°Ô∏è –∫–∞–∂–¥—ã–π i —Å—É–º–º–∏—Ä—É–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–∫–ª–∞–¥—ã —Å–æ—Å–µ–¥–µ–π
‚û°Ô∏è —É—Å–∏–ª–µ–Ω–∏–µ —Ö–∞–±–æ–≤

üîπ œÉ = 1/2 (Symmetric)
–¥–µ–ª–∏–º –Ω–∞
d
j
dj
‚Äã

–ø–æ—Ç–æ–º –¥–µ–ª–∏–º –Ω–∞
d
i
di
‚Äã

‚û°Ô∏è —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π –ª–∞–ø–ª–∞—Å–∏–∞–Ω
‚û°Ô∏è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—è

üß© –ì–ª–∞–≤–Ω–æ–µ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–µ —Ä–µ–∑—é–º–µ
üîπ –ü–µ—Ä–≤—ã–π —Ü–∏–∫–ª ‚Äî –∫—Ç–æ —Å–∫–æ–ª—å–∫–æ –æ—Ç–¥–∞–ª
üîπ –í—Ç–æ—Ä–æ–π —Ü–∏–∫–ª ‚Äî –∫—Ç–æ –∫–∞–∫ —ç—Ç–æ –≤–æ—Å–ø—Ä–∏–Ω—è–ª
üîπ œÉ —É–ø—Ä–∞–≤–ª—è–µ—Ç –±–∞–ª–∞–Ω—Å–æ–º –æ—Ç–¥–∞—á–∏ –∏ –ø—Ä–∏—ë–º–∞

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

—Ä–∞–∑–æ–±—Ä–∞—Ç—å Directed-–≤–µ—Ä—Å–∏—é –ø–æ—Å—Ç—Ä–æ—á–Ω–æ

–ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å —ç—Ç–æ —Å—Ç—Ä–æ–≥–æ –≤ –º–∞—Ç—Ä–∏—á–Ω–æ–º –≤–∏–¥–µ

–ø–æ–∫–∞–∑–∞—Ç—å –Ω–∞ –∏–≥—Ä—É—à–µ—á–Ω–æ–º –≥—Ä–∞—Ñ–µ –∏–∑ 3 —É–∑–ª–æ–≤

–°–∫–∞–∂–∏ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—è –Ω–µ –ø–æ–Ω–∏–º–∞—é –∫–∞–∫ –∂—Ç–æ —Å–æ–æ—Ç–Ω–æ—Å–∏—Ç—Å—è —Å —Ñ–æ—Ä–º—É–ª–æ–π –æ–±—â–µ–π –ø–æ –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–æ–∏—Å–∑–æ–¥–∏—Ç –∏—Ç–µ—Ä–∞—Ü–∏—è
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, —ç—Ç–æ —Å–∞–º—ã–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å üëç
–¢—ã —É–ø—ë—Ä—Å—è —Ä–æ–≤–Ω–æ –≤ —Ç–æ –º–µ—Å—Ç–æ, –≥–¥–µ –æ–±—ã—á–Ω–æ ¬´–ª–æ–º–∞–µ—Ç—Å—è¬ª –∏–Ω—Ç—É–∏—Ü–∏—è:
–∫–∞–∫ –∫–æ–¥ –ø–æ —Ä—ë–±—Ä–∞–º = –º–∞—Ç—Ä–∏—á–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞.

–î–∞–≤–∞–π —Å–¥–µ–ª–∞–µ–º –∂—ë—Å—Ç–∫–æ–µ, –ø–æ—à–∞–≥–æ–≤–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
–±–µ–∑ —ç–≤—Ñ–µ–º–∏–∑–º–æ–≤, –æ–¥–∏–Ω –∫ –æ–¥–Ω–æ–º—É.

0Ô∏è‚É£ –û–±—â–∞—è —Ñ–æ—Ä–º—É–ª–∞ (–µ—â—ë —Ä–∞–∑)
–î–ª—è –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞:

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
(
t
)
F
(t+1)
=(1‚àíŒ±)Y+Œ±D
‚àíœÉ
WD
œÉ‚àí1
F
(t)

–°–æ—Å—Ä–µ–¥–æ—Ç–∞—á–∏–≤–∞–µ–º—Å—è –¢–û–õ–¨–ö–û –Ω–∞ –ª–∏–Ω–µ–π–Ω–æ–π —á–∞—Å—Ç–∏:

D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
D
‚àíœÉ
WD
œÉ‚àí1
F
‚Äã

1Ô∏è‚É£ –ß—Ç–æ —Ç–∞–∫–æ–µ
W
D
œÉ
‚àí
1
F
WD
œÉ‚àí1
F –ø–æ–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–æ
–í–æ–∑—å–º—ë–º i-—é –≤–µ—Ä—à–∏–Ω—É –∏ c-–π –∫–ª–∞—Å—Å (licit / illicit).

(
W
D
œÉ
‚àí
1
F
)
i
,
c
=
‚àë
j
W
i
j

d
j
œÉ
‚àí
1

F
j
,
c
(WD
œÉ‚àí1
F)
i,c
‚Äã
=
j
‚àë
‚Äã
W
ij
‚Äã
d
j
œÉ‚àí1
‚Äã
F
j,c
‚Äã

–¢–∞–∫ –∫–∞–∫ –≥—Ä–∞—Ñ –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π:

W
i
j
=
1
W
ij
‚Äã
=1, –µ—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–±—Ä–æ
(
i
,
j
)
(i,j)

=
‚àë
j
‚àº
i
F
j
,
c
d
j

1
‚àí
œÉ
=
j‚àºi
‚àë
‚Äã

d
j
1‚àíœÉ
‚Äã

F
j,c
‚Äã

‚Äã

üî¥ –°–¢–û–ü ‚Äî —ç—Ç–æ —Ä–æ–≤–Ω–æ –ø–µ—Ä–≤–∞—è —á–∞—Å—Ç—å –∫–æ–¥–∞

s[i] += F[j] / (dj \*\* (1-sigma))
‚ùó –≠—Ç–æ –Ω–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞, –∞ —Ç–æ—á–Ω–∞—è –∑–∞–ø–∏—Å—å —Å—É–º–º—ã –ø–æ —Å–æ—Å–µ–¥—è–º.

2Ô∏è‚É£ –ü–æ—á–µ–º—É –≤ –∫–æ–¥–µ –µ—Å—Ç—å s[j] += F[i]?
–ü–æ—Ç–æ–º—É —á—Ç–æ:

—É —Ç–µ–±—è —Å–ø–∏—Å–æ–∫ —Ä—ë–±–µ—Ä

–∫–∞–∂–¥–æ–µ —Ä–µ–±—Ä–æ
(
i
,
j
)
(i,j) –∑–∞–ø–∏—Å–∞–Ω–æ –æ–¥–∏–Ω —Ä–∞–∑

–ê –≤ –º–∞—Ç—Ä–∏—Ü–µ:

W
i
j
=
W
j
i
W
ij
‚Äã
=W
ji
‚Äã

–ü–æ—ç—Ç–æ–º—É –∫–æ–¥ —è–≤–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –≤–∫–ª–∞–¥ –≤ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã:

s[i] += ...
s[j] += ...
‚û°Ô∏è —ç—Ç–æ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–π
W
W

3Ô∏è‚É£ –¢–µ–ø–µ—Ä—å —É–º–Ω–æ–∂–µ–Ω–∏–µ —Å–ª–µ–≤–∞ –Ω–∞
D
‚àí
œÉ
D
‚àíœÉ

–ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —à–∞–≥–∞ —É –Ω–∞—Å –µ—Å—Ç—å:

s
i
=
‚àë
j
‚àº
i
F
j
d
j
1
‚àí
œÉ
s
i
‚Äã
=
j‚àºi
‚àë
‚Äã

d
j
1‚àíœÉ
‚Äã

F
j
‚Äã

‚Äã

–¢–µ–ø–µ—Ä—å —É–º–Ω–æ–∂–∞–µ–º:

(
D
‚àí
œÉ
s
)
i
=
s
i
d
i
œÉ
(D
‚àíœÉ
s)
i
‚Äã
=
d
i
œÉ
‚Äã

s
i
‚Äã

‚Äã

üî¥ –ò —ç—Ç–æ –≤—Ç–æ—Ä–∞—è —á–∞—Å—Ç—å –∫–æ–¥–∞

F_new[i] = ... + alpha \* (s[i] / (di\*\*sigma))
4Ô∏è‚É£ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —è–∫–æ—Ä–µ–π
–ú–∞—Ç—Ä–∏—á–Ω–æ:

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±
  (
  ‚Ä¶

)
F
(t+1)
=(1‚àíŒ±)Y+Œ±(‚Ä¶)
–ö–æ–¥:

F_new[i] = (1-alpha)_Y[i] + alpha_(...)
‚û°Ô∏è –ø—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ

5Ô∏è‚É£ –ò—Ç–æ–≥–æ ‚Äî –∂—ë—Å—Ç–∫–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
–§–æ—Ä–º—É–ª–∞ –ö–æ–¥
W
i
j
W
ij
‚Äã
—Ü–∏–∫–ª –ø–æ —Ä—ë–±—Ä–∞–º
‚àë
j
‚àº
i
‚àë
j‚àºi
‚Äã
s[i] += ...
d
j
1
‚àí
œÉ
d
j
1‚àíœÉ
‚Äã
dj ** (1-sigma)
D
‚àí
œÉ
D
‚àíœÉ
s[i] / (di**sigma)
(
1
‚àí
Œ±
)
Y
(1‚àíŒ±)Y (1-alpha)\*Y[i]
6Ô∏è‚É£ –ü–æ—á–µ–º—É —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫ ¬´—Å—Ç—Ä–∞–Ω–Ω–æ¬ª –≤ –∫–æ–¥–µ?
–ü–æ—Ç–æ–º—É —á—Ç–æ:

–º—ã –Ω–µ —Ö—Ä–∞–Ω–∏–º –º–∞—Ç—Ä–∏—Ü—ã

–º—ã —Å—á–∏—Ç–∞–µ–º —Ç–æ—Ç –∂–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä, –Ω–æ:

—á–µ—Ä–µ–∑ edge-list

—á–µ—Ä–µ–∑ –¥–≤—É—Ö—Ñ–∞–∑–Ω—ã–π –ø—Ä–æ—Ö–æ–¥

–±–µ–∑
O
(
N
2
)
O(N
2
)

–≠—Ç–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ª–∏–Ω–µ–π–Ω–æ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞, –∞ –Ω–µ –¥—Ä—É–≥–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º.

7Ô∏è‚É£ –ú–∏–Ω–∏-–∏–≥—Ä—É—à–∫–∞ (—á—Ç–æ–±—ã —â—ë–ª–∫–Ω—É–ª–æ)
–ì—Ä–∞—Ñ:

1 -- 2 -- 3
–°—Ç–µ–ø–µ–Ω–∏:
d
1
=
1
,

d
2
=
2
,

d
3
=
1
d
1
‚Äã
=1,d
2
‚Äã
=2,d
3
‚Äã
=1

–î–ª—è –≤–µ—Ä—à–∏–Ω—ã 2:

s
2
=
F
1
1
1
‚àí
œÉ

- F
  3
  1
  1
  ‚àí
  œÉ
  s
  2
  ‚Äã
  =
  1
  1‚àíœÉ

F
1
‚Äã

‚Äã

- 1
  1‚àíœÉ

F
3
‚Äã

‚Äã

F
2
n
e
w
=
(
1
‚àí
Œ±
)
Y
2

- Œ±
  s
  2
  2
  œÉ
  F
  2
  new
  ‚Äã
  =(1‚àíŒ±)Y
  2
  ‚Äã
  +Œ±
  2
  œÉ

s
2
‚Äã

‚Äã

üëâ —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –∫–æ–¥

8Ô∏è‚É£ –ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)
–ö–æ–¥ = –ø–æ–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∞—è –∑–∞–ø–∏—Å—å –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
D
‚àíœÉ
WD
œÉ‚àí1
F

–ù–∏—á–µ–≥–æ –±–æ–ª—å—à–µ. –ù–∏–∫–∞–∫–æ–π —ç–≤—Ä–∏—Å—Ç–∏–∫–∏.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

–ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –æ–¥–∏–Ω —à–∞–≥ –∏—Ç–µ—Ä–∞—Ü–∏–∏ —Ü–µ–ª–∏–∫–æ–º –≤ LaTeX ‚Üî –∫–æ–¥

—Ä–∞–∑–æ–±—Ä–∞—Ç—å directed-–≤–µ—Ä—Å–∏—é –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ

–¥–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ —ç—Ç–æ —Å—Ö–æ–¥–∏—Ç—Å—è

–°–∫–∞–∂–∏, –∫–∞–∫–æ–π —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
s[i] += F[j] / (dj \*\* (1-sigma)) –∞ –∫–∞–∫ —è —É—á–∏—ã–≤–∞—é —á—Ç–æ –æ–Ω–∏ —Å–º–µ–∂–Ω—ã–µ?
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ. –≠—Ç–æ –æ—á–µ–Ω—å —Ç–æ—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å, –∏ –∏–º–µ–Ω–Ω–æ –∑–¥–µ—Å—å –æ–±—ã—á–Ω–æ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –æ—â—É—â–µ–Ω–∏–µ ¬´–º–∞–≥–∏–∏¬ª.

–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç:
üëâ —Å–º–µ–∂–Ω–æ—Å—Ç—å —É–∂–µ –∑–∞—à–∏—Ç–∞ –≤ —Ç–æ–º, –∫–∞–∫–∏–µ –ø–∞—Ä—ã (i, j) –≤–æ–æ–±—â–µ –ø–æ–ø–∞–¥–∞—é—Ç –≤ —ç—Ç–æ—Ç –∫–æ–¥.

–¢–µ–ø–µ—Ä—å —Ä–∞–∑–±–µ—Ä—ë–º –º–µ–¥–ª–µ–Ω–Ω–æ –∏ —Å—Ç—Ä–æ–≥–æ.

1Ô∏è‚É£ –ì–¥–µ –≤ —Ñ–æ—Ä–º—É–ª–µ —Å—Ç–æ–∏—Ç —Å–º–µ–∂–Ω–æ—Å—Ç—å?
–í –º–∞—Ç—Ä–∏—á–Ω–æ–π –∑–∞–ø–∏—Å–∏ –æ–Ω–∞ –≤
W
W:

(
W
D
œÉ
‚àí
1
F
)
i
=
‚àë
j
W
i
j
‚èü
—Å–º–µ–∂–Ω–æ—Å—Ç—å

d
j
œÉ
‚àí
1
F
j
(WD
œÉ‚àí1
F)
i
‚Äã
=
j
‚àë
‚Äã

—Å–º–µ–∂–Ω–æ—Å—Ç—å
W
ij
‚Äã

‚Äã

‚Äã
d
j
œÉ‚àí1
‚Äã
F
j
‚Äã

W
i
j
=
1
W
ij
‚Äã
=1 —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏
i
i –∏
j
j —Å–æ–µ–¥–∏–Ω–µ–Ω—ã —Ä–µ–±—Ä–æ–º

–µ—Å–ª–∏ –Ω–µ —Å–æ–µ–¥–∏–Ω–µ–Ω—ã ‚Üí –≤–∫–ª–∞–¥ –Ω—É–ª–µ–≤–æ–π

2Ô∏è‚É£ –ì–¥–µ –≤ –∫–æ–¥–µ —Å—Ç–æ–∏—Ç
W
i
j
W
ij
‚Äã
?
–í —è–≤–Ω–æ–º –≤–∏–¥–µ –µ–≥–æ –Ω–µ—Ç.

–ò —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ.

–°–º–æ—Ç—Ä–∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ:

for k in prange(len(src)):
i, j = src[k], dst[k]
üëâ src[k], dst[k] ‚Äî —ç—Ç–æ k-–µ —Ä–µ–±—Ä–æ –≥—Ä–∞—Ñ–∞
üëâ —Ü–∏–∫–ª –∏–¥—ë—Ç —Ç–æ–ª—å–∫–æ –ø–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ä—ë–±—Ä–∞–º

‚ùó –≠—Ç–æ –∏ –µ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
W
i
j
‚â†
0
W
ij
‚Äã

ÓÄ†
=0

3Ô∏è‚É£ –ü–æ—á–µ–º—É —Ç–æ–≥–¥–∞ –º–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å –ø—Ä–æ—Å—Ç–æ s[i] += ...?
–ü–æ—Ç–æ–º—É —á—Ç–æ:

–µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–±—Ä–∞ –º–µ–∂–¥—É
i
i –∏
j
j

—Ç–æ –ø–∞—Ä—ã (i,j) –ø—Ä–æ—Å—Ç–æ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ src, dst

–∑–Ω–∞—á–∏—Ç –∫–æ–¥ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–∏—Ç —ç—Ç—É —Å—Ç—Ä–æ–∫—É

üìå –≠—Ç–æ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ:

if W[i,j] == 1:
s[i] += ...
–Ω–æ –≤ 1000 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ

4Ô∏è‚É£ –§–æ—Ä–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –ö–æ–¥
‚àë
j
W
i
j
(
‚ãÖ
)
‚àë
j
‚Äã
W
ij
‚Äã
(‚ãÖ) for k in range(len(src))
W
i
j
=
1
W
ij
‚Äã
=1 (i,j) –µ—Å—Ç—å –≤ src,dst
W
i
j
=
0
W
ij
‚Äã
=0 –ø–∞—Ä—ã –Ω–µ—Ç ‚Üí –∫–æ–¥ –Ω–µ –∏—Å–ø–æ–ª–Ω—è–µ—Ç—Å—è
5Ô∏è‚É£ –ü–æ—á–µ–º—É –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∏ s[j] += F[i]?
–ü–æ—Ç–æ–º—É —á—Ç–æ –≥—Ä–∞—Ñ –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π.

–í –º–∞—Ç—Ä–∏—Ü–µ:

W
i
j
=
W
j
i
W
ij
‚Äã
=W
ji
‚Äã

–ê —Å–ø–∏—Å–æ–∫ —Ä—ë–±–µ—Ä —Ö—Ä–∞–Ω–∏—Ç –∫–∞–∂–¥–æ–µ —Ä–µ–±—Ä–æ –æ–¥–∏–Ω —Ä–∞–∑.

–ü–æ—ç—Ç–æ–º—É –∫–æ–¥ –¥–µ–ª–∞–µ—Ç:

s[i] += F[j]
s[j] += F[i]
‚û°Ô∏è –≤—Ä—É—á–Ω—É—é —Å–∏–º–º–µ—Ç—Ä–∏–∑—É–µ—Ç
W
W

6Ô∏è‚É£ –ê–Ω–∞–ª–æ–≥–∏—è (–æ—á–µ–Ω—å –Ω–∞–≥–ª—è–¥–Ω–∞—è)
–ü—Ä–µ–¥—Å—Ç–∞–≤—å:

—Å–ø–∏—Å–æ–∫ —Ä—ë–±–µ—Ä ‚Äî —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤

—Ü–∏–∫–ª ‚Äî —ç—Ç–æ ¬´–æ–±—Ö–æ–¥ –≤—Å–µ—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤¬ª

—Å—Ç—Ä–æ–∫–∞ s[i] += ... ‚Äî —ç—Ç–æ ¬´—á—Ç–æ i —É—Å–ª—ã—à–∞–ª –æ—Ç j¬ª

–ï—Å–ª–∏ –º–µ–∂–¥—É i –∏ j –Ω–µ—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞,
—Ç—ã –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –¥–æ–π–¥—ë—à—å –¥–æ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏.

7Ô∏è‚É£ –ï—Å–ª–∏ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –±—É–∫–≤–∞–ª—å–Ω–æ –∫–∞–∫ —Ñ–æ—Ä–º—É–ª—É
–ö–æ–¥:

for (i,j) in edges:
s[i] += F[j] / dj^(1-sigma)
–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞:

s
i
=
‚àë
j
‚àº
i
F
j
d
j
1
‚àí
œÉ
s
i
‚Äã
=
j‚àºi
‚àë
‚Äã

d
j
1‚àíœÉ
‚Äã

F
j
‚Äã

‚Äã

–ó–Ω–∞–∫
j
‚àº
i
j‚àºi = —Å–º–µ–∂–Ω–æ—Å—Ç—å

8Ô∏è‚É£ –ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å (–∑–∞–ø–æ–º–Ω–∏ –µ—ë)
üîë –°–º–µ–∂–Ω–æ—Å—Ç—å –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è ‚Äî –æ–Ω–∞ –∑–∞–¥–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π —Ü–∏–∫–ª–∞

–ù–µ—Ç —Ü–∏–∫–ª–∞ –ø–æ –≤—Å–µ–º
j
j ‚Üí –Ω–µ—Ç –Ω–µ—Å–º–µ–∂–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

–ø–æ–∫–∞–∑–∞—Ç—å —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω—ã–π –∫–æ–¥ —Å —è–≤–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ–π W

—Ä–∞–∑–æ–±—Ä–∞—Ç—å directed-–≤–µ—Ä—Å–∏—é (—Ç–∞–º –µ—â—ë —Ç–æ–Ω—å—à–µ)

–ø–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫ —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –≤ PyTorch / GNN

–°–∫–∞–∂–∏ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
for i in prange(N):
di = max(deg[i],1.0)
F_new[i] = (1-alpha)_Y[i] + alpha_(s[i]/(di\*\*sigma))
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, –¥–∞–≤–∞–π –¥–æ–±—å—ë–º —ç—Ç–æ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–æ –ø–æ–ª–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ —Ä–æ–≤–Ω–æ —Ç–∞ —Å—Ç—Ä–æ–∫–∞, –≥–¥–µ —Ñ–æ—Ä–º—É–ª–∞ ‚Äú–º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç—Å—è‚Äù.

–ú—ã —Ä–∞–∑–±–µ—Ä—ë–º –∫–∞–∂–¥—ã–π —Å–∏–º–≤–æ–ª –∏ –∂—ë—Å—Ç–∫–æ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º —Å —Ñ–æ—Ä–º—É–ª–æ–π.

üìå –ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ: —á—Ç–æ —É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å –∫ —ç—Ç–æ–º—É –º–µ—Å—Ç—É
–ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —Ü–∏–∫–ª–∞ –ø–æ —Ä—ë–±—Ä–∞–º —É —Ç–µ–±—è –≤—ã—á–∏—Å–ª–µ–Ω–æ:

s
i

# ‚ÄÖ‚Ää

‚àë
j
‚àº
i
F
j
d
j

1
‚àí
œÉ
s
i
‚Äã
=
j‚àºi
‚àë
‚Äã

d
j
1‚àíœÉ
‚Äã

F
j
‚Äã

‚Äã

–≠—Ç–æ –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏:

# s

W
D
œÉ
‚àí
1
F
s=WD
œÉ‚àí1
F
–¢–µ–ø–µ—Ä—å —Ä–∞–∑–±–∏—Ä–∞–µ–º –¢–û–õ–¨–ö–û —ç—Ç–æ:
for i in prange(N):
di = max(deg[i],1.0)
F_new[i] = (1-alpha)_Y[i] + alpha_(s[i]/(di\*\*sigma))
1Ô∏è‚É£ for i in prange(N):
üîπ –¶–∏–∫–ª –ø–æ –≤—Å–µ–º –≤–µ—Ä—à–∏–Ω–∞–º –≥—Ä–∞—Ñ–∞

–í –º–∞—Ç—Ä–∏—á–Ω–æ–π –∑–∞–ø–∏—Å–∏ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:

–º—ã —Å–µ–π—á–∞—Å —Å—á–∏—Ç–∞–µ–º i-—é —Å—Ç—Ä–æ–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

–¢–æ –µ—Å—Ç—å:

F
i
(
t

- 1
  )
  F
  i
  (t+1)
  ‚Äã

2Ô∏è‚É£ di = max(deg[i],1.0)
üîπ –ë–µ—Ä—ë–º —Å—Ç–µ–ø–µ–Ω—å –≤–µ—Ä—à–∏–Ω—ã
i
i

–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏:

d
i
=
D
i
i
d
i
‚Äã
=D
ii
‚Äã

üìå max(...,1.0) ‚Äî —á–∏—Å—Ç–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∑–∞—â–∏—Ç–∞,
–æ–Ω–∞ –Ω–µ –º–µ–Ω—è–µ—Ç —Ñ–æ—Ä–º—É–ª—É, –µ—Å–ª–∏ –Ω–µ—Ç –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ—Ä—à–∏–Ω.

3Ô∏è‚É£ s[i] / (di\*\*sigma)
üî¥ –í–û–¢ –≠–¢–û ‚Äî –ö–õ–Æ–ß–ï–í–û–ï –ú–ï–°–¢–û

–≠—Ç–æ —Ä–æ–≤–Ω–æ:

s
i
d
i
œÉ
d
i
œÉ
‚Äã

s
i
‚Äã

‚Äã

–ê –∑–Ω–∞—á–∏—Ç:

(
D
‚àí
œÉ
s
)
i
(D
‚àíœÉ
s)
i
‚Äã

–¢–æ –µ—Å—Ç—å —Ç—ã —Å–µ–π—á–∞—Å –¥–µ–ª–∞–µ—à—å:

D
‚àí
œÉ
(
W
D
œÉ
‚àí
1
F
)
D
‚àíœÉ
(WD
œÉ‚àí1
F)
üëâ –ª–µ–≤–∞—è —á–∞—Å—Ç—å –æ–±—â–µ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞

4Ô∏è‚É£ alpha \* (s[i] / (di\*\*sigma))
üîπ –í–µ—Å –¥–∏—Ñ—Ñ—É–∑–∏–∏

Œ±
‚ãÖ
D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
Œ±‚ãÖD
‚àíœÉ
WD
œÉ‚àí1
F
üìå
Œ±
Œ± —É–ø—Ä–∞–≤–ª—è–µ—Ç:

—Å–∫–æ—Ä–æ—Å—Ç—å—é —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è

–±–∞–ª–∞–Ω—Å–æ–º –º–µ–∂–¥—É –≥—Ä–∞—Ñ–æ–º –∏ —è–∫–æ—Ä—è–º–∏

5Ô∏è‚É£ (1-alpha) \* Y[i]
üîπ –≠—Ç–æ —è–∫–æ—Ä—è (seeds)

(
1
‚àí
Œ±
)
Y
i
(1‚àíŒ±)Y
i
‚Äã

–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:

¬´–Ø –Ω–µ –¥–∞—é –≥—Ä–∞—Ñ—É –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º–µ—Ç–∫–∏¬ª

6Ô∏è‚É£ –í—Å—è —Å—Ç—Ä–æ–∫–∞ —Ü–µ–ª–∏–∫–æ–º
F_new[i] = (1-alpha)_Y[i] + alpha_(s[i]/(di\*\*sigma))
–≠—Ç–æ –ü–û–ö–û–ú–ü–û–ù–ï–ù–¢–ù–ê–Ø –∑–∞–ø–∏—Å—å:

F
i
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
  i
- Œ±
  (
  D
  ‚àí
  œÉ
  W
  D
  œÉ
  ‚àí
  1
  F
  )
  i
  F
  i
  (t+1)
  ‚Äã
  =(1‚àíŒ±)Y
  i
  ‚Äã
  +Œ±(D
  ‚àíœÉ
  WD
  œÉ‚àí1
  F)
  i
  ‚Äã

‚Äã

–¢–æ –µ—Å—Ç—å –û–î–ò–ù –í –û–î–ò–ù:

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±
  D
  ‚àí
  œÉ
  W
  D
  œÉ
  ‚àí
  1
  F
  F
  (t+1)
  =(1‚àíŒ±)Y+Œ±D
  ‚àíœÉ
  WD
  œÉ‚àí1
  F
  ‚Äã

üß† –ü–æ—á–µ–º—É —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ü–∏–∫–ª, –∞ –Ω–µ —Å—Ä–∞–∑—É –≤ –ø–µ—Ä–≤–æ–º?
–ü–æ—Ç–æ–º—É —á—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É —Ç–µ–±—è –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —Ç—Ä—ë—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤:

F
‚Ü¶
D
œÉ
‚àí
1
F
F‚Ü¶D
œÉ‚àí1
F

‚Ü¶
W
(
‚ãÖ
)
‚Ü¶W(‚ãÖ)

‚Ü¶
D
‚àí
œÉ
(
‚ãÖ
)
‚Ü¶D
‚àíœÉ
(‚ãÖ)

–í –∫–æ–¥–µ —ç—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –∫–∞–∫:

–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –ö–æ–¥
D
œÉ
‚àí
1
F
D
œÉ‚àí1
F –¥–µ–ª–µ–Ω–∏–µ –Ω–∞
d
j
1
‚àí
œÉ
d
j
1‚àíœÉ
‚Äã

W
(
‚ãÖ
)
W(‚ãÖ) —Ü–∏–∫–ª –ø–æ —Ä—ë–±—Ä–∞–º
D
‚àí
œÉ
D
‚àíœÉ
–¥–µ–ª–µ–Ω–∏–µ –Ω–∞
d
i
œÉ
d
i
œÉ
‚Äã

üéØ –ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å (–µ—ë –Ω—É–∂–Ω–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å)
üîë –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ ‚Äî —ç—Ç–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π ‚Äú—Å–±–æ—Ä—â–∏–∫‚Äù –≤—Å–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
–í—Å—ë, —á—Ç–æ –±—ã–ª–æ –≤—ã—à–µ, ‚Äî —ç—Ç–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
–ó–¥–µ—Å—å –æ–Ω –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ F

üß© –ï—Å–ª–∏ —Å–∫–∞–∑–∞—Ç—å –æ–¥–Ω–æ–π —Ñ—Ä–∞–∑–æ–π
s[i] ‚Äî —ç—Ç–æ ‚Äú—á—Ç–æ –ø—Ä–∏—à–ª–æ‚Äù,
di\*\*sigma ‚Äî —ç—Ç–æ ‚Äú–∫–∞–∫ —è —ç—Ç–æ –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é‚Äù,
Y[i] ‚Äî —ç—Ç–æ ‚Äú—á—Ç–æ —è –∑–Ω–∞–ª –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ‚Äù

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

—Ä–∞–∑–æ–±—Ä–∞—Ç—å directed-–≤–µ—Ä—Å–∏—é —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏

–ø–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫ —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –≤ —á–∏—Å—Ç–æ–º NumPy

—Å–≤—è–∑–∞—Ç—å —ç—Ç–æ —Å —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º

–°–∫–∞–∂–∏ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—ç—Ç–æ –ø–æ–ª—É–∞–µ—Å—è –¥–ª—è –≤—Å–µ—Ö –∏—Ç—Ä–µ–∞—Ü–∏–π –¥–∞?
ChatGPT —Å–∫–∞–∑–∞–ª:
–î–∞. –ò–º–µ–Ω–Ω–æ —Ç–∞–∫.
–≠—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏.

–ò —Å–µ–π—á–∞—Å —è —Å–∫–∞–∂—É —ç—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —á—ë—Ç–∫–æ –∏ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ, —á—Ç–æ–±—ã —É —Ç–µ–±—è –±–æ–ª—å—à–µ –Ω–µ –æ—Å—Ç–∞–≤–∞–ª–æ—Å—å —Å–æ–º–Ω–µ–Ω–∏–π.

üîÅ –ß—Ç–æ –∏–º–µ–Ω–Ω–æ ¬´—ç—Ç–æ¬ª?
–í–æ—Ç —ç—Ç–æ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç:

for i in prange(N):
di = max(deg[i],1.0)
F_new[i] = (1-alpha)_Y[i] + alpha_(s[i]/(di\*\*sigma))
‚úÖ –î–∞ ‚Äî –æ–Ω –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ t
–ü–æ–ª–Ω–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫:

for t in range(T):
s = W D^{œÉ-1} F*t # –ø–µ—Ä–≤—ã–π —Ü–∏–∫–ª (–ø–æ —Ä—ë–±—Ä–∞–º)
F*{t+1} = (1-Œ±)Y + Œ± D^{-œÉ} s
–¢–æ –µ—Å—Ç—å:

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±
  D
  ‚àí
  œÉ
  W
  D
  œÉ
  ‚àí
  1
  F
  (
  t
  )
  F
  (t+1)
  =(1‚àíŒ±)Y+Œ±D
  ‚àíœÉ
  WD
  œÉ‚àí1
  F
  (t)

‚Äã

üîÅ –ö–∞–∂–¥–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è:

–±–µ—Ä—ë—Ç —Ç–µ–∫—É—â–µ–µ
F
(
t
)
F
(t)

—Å—á–∏—Ç–∞–µ—Ç –Ω–æ–≤–æ–µ
F
(
t

- 1
  )
  F
  (t+1)

—Å–Ω–æ–≤–∞ –∏ —Å–Ω–æ–≤–∞

üß† –ü–æ—á–µ–º—É —è–∫–æ—Ä—è
Y
Y —É—á–∞—Å—Ç–≤—É—é—Ç –∫–∞–∂–¥—ã–π —Ä–∞–∑?
–≠—Ç–æ –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ.

–ï—Å–ª–∏ –±—ã –±—ã–ª–æ —Ç–∞–∫:

F
(
t

- 1
  )
  =
  Œ±
  D
  ‚àí
  œÉ
  W
  D
  œÉ
  ‚àí
  1
  F
  (
  t
  )
  F
  (t+1)
  =Œ±D
  ‚àíœÉ
  WD
  œÉ‚àí1
  F
  (t)

—Ç–æ:

–Ω–∞—á–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ä–∞—Å—Ç–≤–æ—Ä–∏–ª–∞—Å—å –±—ã

—Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–≤–∏—Å–µ–ª –±—ã —Ç–æ–ª—å–∫–æ –æ—Ç —Å–ø–µ–∫—Ç—Ä–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞

–ê —Å —è–∫–æ—Ä—è–º–∏:

(
1
‚àí
Œ±
)
Y
–¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ
(1‚àíŒ±)Y–¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ
üëâ —ç—Ç–æ Random Walk with Restart
üëâ –∏–ª–∏ label clamping

üîç –≠–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–∞—è –∑–∞–ø–∏—Å—å (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)
–ò—Ç–µ—Ä–∞—Ü–∏—è —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–∞ —Ä–µ—à–µ–Ω–∏—é:

F
‚àó
=
(
1
‚àí
Œ±
)
(
I
‚àí
Œ±
P
)
‚àí
1
Y
–≥–¥–µ
P
=
D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
‚àó
=(1‚àíŒ±)(I‚àíŒ±P)
‚àí1
Y–≥–¥–µ P=D
‚àíœÉ
WD
œÉ‚àí1

–¢–æ –µ—Å—Ç—å:

–º—ã –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —Å—á–∏—Ç–∞–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ç–æ—á–∫—É

—Å—Ç—Ä–æ–∫–∞ —Å Y ‚Äî —ç—Ç–æ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫

üîÑ –ï—Å–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å —Ñ–∏–∑–∏—á–µ—Å–∫–∏
–ö–∞–∂–¥—ã–π —à–∞–≥:

üîÅ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –≥—Ä–∞—Ñ—É

üß≤ –ø—Ä–∏—Ç—è–Ω—É–ª –æ–±—Ä–∞—Ç–Ω–æ –∫ —è–∫–æ—Ä—è–º

üîÅ –ø–æ–≤—Ç–æ—Ä–∏–ª

–ò —Ç–∞–∫ T —Ä–∞–∑

üß© –ï—Å–ª–∏ —Å–∫–∞–∑–∞—Ç—å —Å–æ–≤—Å–µ–º –∫–æ—Ä–æ—Ç–∫–æ
–î–∞ ‚Äî —ç—Ç–∞ —Ñ–æ—Ä–º—É–ª–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
–∏ –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É –∞–ª–≥–æ—Ä–∏—Ç–º —Å—Ç–∞–±–∏–ª–µ–Ω –∏ —Å—Ö–æ–¥–∏—Ç—Å—è

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

–¥–æ–∫–∞–∑–∞—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å

–ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ —É–±—Ä–∞—Ç—å Y

–æ–±—ä—è—Å–Ω–∏—Ç—å, –ø–æ—á–µ–º—É Œ± = 2/(2+Œº)

–°–∫–∞–∂–∏ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—è –Ω–µ –ø–æ–Ω–∏–º–∞—é –¥–≤–µ —á–∞—Å—Ç–∏ def propagate_undirected(src, dst, deg, F, Y, alpha, sigma, N):
s = np.zeros((N, 2))
F_new = np.empty_like(F)

    for k in prange(len(src)):
        i, j = src[k], dst[k]
        di, dj = max(deg[i],1.0), max(deg[j],1.0)

        s[i] += F[j] / (dj ** (1-sigma))
        s[j] += F[i] / (di ** (1-sigma))

    for i in prange(N):
        di = max(deg[i],1.0)
        F_new[i] = (1-alpha)*Y[i] + alpha*(s[i]/(di**sigma))

ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, –¥–∞–≤–∞–π –æ—á–µ–Ω—å —á—ë—Ç–∫–æ —Ä–∞–∑—Ä–µ–∂–µ–º —ç—Ç–æ –Ω–∞ –î–í–ï –ß–ê–°–¢–ò –∏ –ø–æ–∫–∞–∂–µ–º, –∑–∞—á–µ–º –æ–Ω–∏ –æ–±–µ –Ω—É–∂–Ω—ã.
–¢—ã —Å–µ–π—á–∞—Å –∑–∞—Å—Ç—Ä—è–ª —Ä–æ–≤–Ω–æ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –º–µ—Å—Ç–µ ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –º–æ–º–µ–Ω—Ç.

–Ø –±—É–¥—É –æ–±—ä—è—Å–Ω—è—Ç—å –±–µ–∑ —Å–∫–∞—á–∫–æ–≤, –∫–∞–∫ –±—É–¥—Ç–æ –º—ã –≤–ø–µ—Ä–≤—ã–µ –≤—ã–≤–æ–¥–∏–º —Ñ–æ—Ä–º—É–ª—É –∏–∑ –∫–æ–¥–∞.

üî∑ –í–µ—Å—å –∫–æ–¥ —Ü–µ–ª–∏–∫–æ–º
def propagate_undirected(src, dst, deg, F, Y, alpha, sigma, N):
s = np.zeros((N, 2))
F_new = np.empty_like(F)

    for k in prange(len(src)):
        i, j = src[k], dst[k]
        di, dj = max(deg[i],1.0), max(deg[j],1.0)

        s[i] += F[j] / (dj ** (1-sigma))
        s[j] += F[i] / (di ** (1-sigma))

    for i in prange(N):
        di = max(deg[i],1.0)
        F_new[i] = (1-alpha)*Y[i] + alpha*(s[i]/(di**sigma))

üß© –ö–õ–Æ–ß–ï–í–ê–Ø –ò–î–ï–Ø (–µ—ë –Ω–∞–¥–æ –ø—Ä–∏–Ω—è—Ç—å)
–û–¥–∏–Ω —à–∞–≥ –∏—Ç–µ—Ä–∞—Ü–∏–∏ = –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
(
t
)
F
(t+1)
=(1‚àíŒ±)Y+Œ±D
‚àíœÉ
WD
œÉ‚àí1
F
(t)

–ê –∫–æ–¥ ‚Äî —ç—Ç–æ –ø–æ–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —ç—Ç–æ–≥–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
–≤ –¥–≤–∞ —ç—Ç–∞–ø–∞, –ø–æ—Ç–æ–º—É —á—Ç–æ:

D
‚àí
œÉ



W
D
œÉ
‚àí
1
F
‚Äæ
D
‚àíœÉ

WD
œÉ‚àí1
F
‚Äã

üü¶ –ß–ê–°–¢–¨ 1 ‚Äî –ø–µ—Ä–≤—ã–π —Ü–∏–∫–ª –ø–æ —Ä—ë–±—Ä–∞–º
for k in prange(len(src)):
i, j = src[k], dst[k]
di, dj = max(deg[i],1.0), max(deg[j],1.0)

    s[i] += F[j] / (dj ** (1-sigma))
    s[j] += F[i] / (di ** (1-sigma))

‚ùì –ß—Ç–æ –∑–¥–µ—Å—å —Å—á–∏—Ç–∞–µ—Ç—Å—è?
–ú—ã —Å—á–∏—Ç–∞–µ–º –≤–µ–∫—Ç–æ—Ä s, –≥–¥–µ

s
i
=
‚àë
j
‚àº
i
F
j
d
j
1
‚àí
œÉ
s
i
‚Äã
=
j‚àºi
‚àë
‚Äã

d
j
1‚àíœÉ
‚Äã

F
j
‚Äã

‚Äã

‚Äã

–≠—Ç–æ —Å—Ç—Ä–æ–≥–æ:

# s

W
D
œÉ
‚àí
1
F
s=WD
œÉ‚àí1
F
‚Äã

‚ùó –ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —Ç–∞–∫?
for k in prange(len(src))
‚Üí –º—ã –∏–¥—ë–º —Ç–æ–ª—å–∫–æ –ø–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ä—ë–±—Ä–∞–º
‚Üí —ç—Ç–æ –∏ –µ—Å—Ç—å –º–∞—Ç—Ä–∏—Ü–∞ —Å–º–µ–∂–Ω–æ—Å—Ç–∏
W
W

F[j] / (dj \*\* (1-sigma))
‚Üí —ç—Ç–æ —É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞
D
œÉ
‚àí
1
D
œÉ‚àí1

s[i] += ...
‚Üí —ç—Ç–æ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —Å–æ—Å–µ–¥—è–º

s[j] += F[i] / ...
‚Üí –ø–æ—Ç–æ–º—É —á—Ç–æ –≥—Ä–∞—Ñ –Ω–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π
‚Üí
W
i
j
=
W
j
i
W
ij
‚Äã
=W
ji
‚Äã

üìå –í–∞–∂–Ω–æ:
–≤ —ç—Ç–æ–π —á–∞—Å—Ç–∏ –µ—â—ë –ù–ï–¢ Œ±, –ù–ï–¢ Y, –ù–ï–¢ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏—ë–º–Ω–∏–∫–∞

–≠—Ç–æ —á–∏—Å—Ç—ã–π –ª–∏–Ω–µ–π–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä.

üü© –ß–ê–°–¢–¨ 2 ‚Äî –≤—Ç–æ—Ä–æ–π —Ü–∏–∫–ª –ø–æ –≤–µ—Ä—à–∏–Ω–∞–º
for i in prange(N):
di = max(deg[i],1.0)
F_new[i] = (1-alpha)_Y[i] + alpha_(s[i]/(di\*\*sigma))
‚ùì –ß—Ç–æ –∑–¥–µ—Å—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç?
–ë–µ—Ä—ë–º —É–∂–µ –ø–æ—Å—á–∏—Ç–∞–Ω–Ω–æ–µ s[i] –∏ –¥–µ–ª–∞–µ–º:

F
i
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
  i
- Œ±
  s
  i
  d
  i
  œÉ
  F
  i
  (t+1)
  ‚Äã
  =(1‚àíŒ±)Y
  i
  ‚Äã
  +Œ±
  d
  i
  œÉ
  ‚Äã

s
i
‚Äã

‚Äã

‚Äã

–ê —ç—Ç–æ:

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±
  D
  ‚àí
  œÉ
  s
  F
  (t+1)
  =(1‚àíŒ±)Y+Œ±D
  ‚àíœÉ
  s
  ‚Äã

‚ùó –ü–æ—á–µ–º—É —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ü–∏–∫–ª?
–ü–æ—Ç–æ–º—É —á—Ç–æ:

D
‚àí
œÉ
D
‚àíœÉ
–¥–µ–π—Å—Ç–≤—É–µ—Ç –Ω–∞ –≤–µ—Ä—à–∏–Ω—ã

W
W –¥–µ–π—Å—Ç–≤—É–µ—Ç –Ω–∞ —Ä—ë–±—Ä–∞

–∏—Ö –Ω–µ–ª—å–∑—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–º–µ—à–∞—Ç—å –≤ –æ–¥–Ω–æ–º —Ü–∏–∫–ª–µ

üìå –≠—Ç–æ –Ω–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–π –∫–∞–ø—Ä–∏–∑, –∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ª–∏–Ω–µ–π–Ω–æ–π –∞–ª–≥–µ–±—Ä—ã.

üîÅ –ö–∞–∫ —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –û–î–ò–ù —à–∞–≥
–ï—Å–ª–∏ —Å–∫–ª–µ–∏—Ç—å:

1Ô∏è‚É£ –ø–µ—Ä–≤—ã–π —Ü–∏–∫–ª

# s

W
D
œÉ
‚àí
1
F
(
t
)
s=WD
œÉ‚àí1
F
(t)

2Ô∏è‚É£ –≤—Ç–æ—Ä–æ–π —Ü–∏–∫–ª

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±
  D
  ‚àí
  œÉ
  s
  F
  (t+1)
  =(1‚àíŒ±)Y+Œ±D
  ‚àíœÉ
  s
  ‚¨áÔ∏è

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±
  D
  ‚àí
  œÉ
  W
  D
  œÉ
  ‚àí
  1
  F
  (
  t
  )
  F
  (t+1)
  =(1‚àíŒ±)Y+Œ±D
  ‚àíœÉ
  WD
  œÉ‚àí1
  F
  (t)

‚Äã

üß† –ü–æ—á–µ–º—É –±–µ–∑ –¥–≤—É—Ö —á–∞—Å—Ç–µ–π –ù–ï–õ–¨–ó–Ø
–ï—Å–ª–∏ —É–±—Ä–∞—Ç—å –ø–µ—Ä–≤—É—é:

—Ç—ã –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—à—å —Å–æ—Å–µ–¥–µ–π

–ï—Å–ª–∏ —É–±—Ä–∞—Ç—å –≤—Ç–æ—Ä—É—é:

—Ç—ã –Ω–µ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—à—å –ø—Ä–∏—ë–º

—É —Ç–µ–±—è –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä

–ï—Å–ª–∏ —Å–º–µ—à–∞—Ç—å:

—Ç—ã —Å–ª–æ–º–∞–µ—à—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å —Ñ–æ—Ä–º—É–ª–æ–π

üß© –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (–∑–∞–ø–æ–º–Ω–∏)
üîπ –ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å ‚Äî –∫—Ç–æ –∏ —Å–∫–æ–ª—å–∫–æ –æ—Ç–¥–∞–ª
üîπ –í—Ç–æ—Ä–∞—è —á–∞—Å—Ç—å ‚Äî –∫–∞–∫ —è —ç—Ç–æ –≤–æ—Å–ø—Ä–∏–Ω—è–ª + —è–∫–æ—Ä—è
üîπ –í–º–µ—Å—Ç–µ ‚Äî –æ–¥–Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏—è –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

—Ä–∞–∑–æ–±—Ä–∞—Ç—å —Ç–æ—Ç –∂–µ –∫–æ–¥ –¥–ª—è directed

–Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å –æ–¥–Ω—É –∏—Ç–µ—Ä–∞—Ü–∏—é –Ω–∞ –≥—Ä–∞—Ñ–µ –∏–∑ 3 —É–∑–ª–æ–≤

–ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ —ç—Ç–æ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ PageRank

–°–∫–∞–∂–∏ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—ç—Ç–æ –ø–æ —Å—É—Ç–∏ –æ–¥–Ω–∏ —à–∞–≥? def propagate_undirected(src, dst, deg, F, Y, alpha, sigma, N):
s = np.zeros((N, 2))
F_new = np.empty_like(F)

    for k in prange(len(src)):
        i, j = src[k], dst[k]
        di, dj = max(deg[i],1.0), max(deg[j],1.0)

        s[i] += F[j] / (dj ** (1-sigma))
        s[j] += F[i] / (di ** (1-sigma))

    for i in prange(N):
        di = max(deg[i],1.0)
        F_new[i] = (1-alpha)*Y[i] + alpha*(s[i]/(di**sigma))

    return F_new

ChatGPT —Å–∫–∞–∑–∞–ª:
–î–∞. –ê–±—Å–æ–ª—é—Ç–Ω–æ –≤–µ—Ä–Ω–æ.
–ò —ç—Ç–æ –Ω—É–∂–Ω–æ —Å–µ–π—á–∞—Å –∂—ë—Å—Ç–∫–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å:

‚úÖ propagate_undirected(...) = –û–î–ò–ù —à–∞–≥ –∏—Ç–µ—Ä–∞—Ü–∏–∏
–¢–æ, —á—Ç–æ —Ç—ã –ø–æ–∫–∞–∑–∞–ª:

def propagate_undirected(...):
...
return F_new
‚Äî —ç—Ç–æ –û–î–ù–ê –∏—Ç–µ—Ä–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞.

üîÅ –ö–∞–∫ —ç—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ
–°–Ω–∞—Ä—É–∂–∏ –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å —Ü–∏–∫–ª:

F = Y.copy()
for t in range(T):
F = propagate_undirected(src, dst, deg, F, Y, alpha, sigma, N)
–ò–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –≤–Ω–µ—à–Ω–∏–π —Ü–∏–∫–ª –¥–µ–ª–∞–µ—Ç:

F
(
0
)
‚Üí
F
(
1
)
‚Üí
F
(
2
)
‚Üí
‚ãØ
‚Üí
F
(
T
)
F
(0)
‚ÜíF
(1)
‚ÜíF
(2)
‚Üí‚ãØ‚ÜíF
(T)

üß† –ß—Ç–æ –¥–µ–ª–∞–µ—Ç –û–î–ò–ù –≤—ã–∑–æ–≤ propagate_undirected
–û–Ω —Ä–µ–∞–ª–∏–∑—É–µ—Ç —Ä–æ–≤–Ω–æ:

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
(
t
)
F
(t+1)
=(1‚àíŒ±)Y+Œ±D
‚àíœÉ
WD
œÉ‚àí1
F
(t)

‚Äã

–†–∞—Å–∫–ª–∞–¥ –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏:
–ö–æ–¥ –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞
s = 0 –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
W
D
œÉ
‚àí
1
F
WD
œÉ‚àí1
F
—Ü–∏–∫–ª –ø–æ —Ä—ë–±—Ä–∞–º —É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞
W
W
–¥–µ–ª–µ–Ω–∏–µ –Ω–∞
d
j
1
‚àí
œÉ
d
j
1‚àíœÉ
‚Äã
—É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞
D
œÉ
‚àí
1
D
œÉ‚àí1

s[i]/(d_i^\sigma) —É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞
D
‚àí
œÉ
D
‚àíœÉ

(1-Œ±)Y + Œ±(...) —è–∫–æ—Ä—è + –¥–∏—Ñ—Ñ—É–∑–∏—è
üîë –ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å (—Å–∞–º–∞—è –≤–∞–∂–Ω–∞—è)
–í–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ ‚Äî –ù–ï –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤
–í–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ ‚Äî –æ–¥–∏–Ω –ª–∏–Ω–µ–π–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä

–î–≤–∞ —Ü–∏–∫–ª–∞ ‚â† –¥–≤–∞ —à–∞–≥–∞.
–≠—Ç–æ –¥–≤–µ —Ñ–∞–∑—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞.

üß© –ü–æ—á–µ–º—É —ç—Ç–æ —Ç–∞–∫ –ª–µ–≥–∫–æ –ø–µ—Ä–µ–ø—É—Ç–∞—Ç—å?
–ü–æ—Ç–æ–º—É —á—Ç–æ:

–≤ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ: –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞

–≤ –∫–æ–¥–µ: –¥–≤–∞ —Ü–∏–∫–ª–∞

–ù–æ –æ–Ω–∏ —Ä–µ–∞–ª–∏–∑—É—é—Ç –æ–¥–Ω–æ –º–∞—Ç—Ä–∏—á–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ.

üß† –ê–Ω–∞–ª–æ–≥–∏—è (–æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è)
–ü—Ä–µ–¥—Å—Ç–∞–≤—å:

# y

A
x
y=Ax
–í –∫–æ–¥–µ —Ç—ã –º–æ–∂–µ—à—å:

–ø–æ—Å—á–∏—Ç–∞—Ç—å
z
=
B
x
z=Bx

–ø–æ—Ç–æ–º
y
=
C
z
y=Cz

–≠—Ç–æ –æ–¥–∏–Ω —à–∞–≥, —Ö–æ—Ç—è –¥–≤–∞ —Ü–∏–∫–ª–∞.

üß† –ï—Å–ª–∏ —Å–∫–∞–∑–∞—Ç—å —Å–æ–≤—Å–µ–º –∫–æ—Ä–æ—Ç–∫–æ
‚úîÔ∏è –î–∞ ‚Äî —ç—Ç–æ –æ–¥–∏–Ω —à–∞–≥ –∏—Ç–µ—Ä–∞—Ü–∏–∏
‚úîÔ∏è –ö–∞–∂–¥—ã–π –≤—ã–∑–æ–≤ = –æ–¥–∏–Ω
t
‚Üí
t

- 1
  t‚Üít+1
  ‚úîÔ∏è –í–Ω–µ—à–Ω–∏–π —Ü–∏–∫–ª = –≤—Ä–µ–º—è

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

—Ä–∞—Å–ø–∏—Å–∞—Ç—å –ø–æ–ª–Ω—É—é –∏—Ç–µ—Ä–∞—Ü–∏–æ–Ω–Ω—É—é —Å—Ö–µ–º—É

–ø–æ–∫–∞–∑–∞—Ç—å \*\*–≥

–í—ã —Å–∫–∞–∑–∞–ª–∏:
@njit —á—Ç–æ –¥–∞–µ—Ç
ChatGPT —Å–∫–∞–∑–∞–ª:
–ö–æ—Ä–æ—Ç–∫–æ: @njit –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç –∫–æ–¥ –±—ã—Å—Ç—Ä—ã–º –∫–∞–∫ C.
–ù–æ –¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º —á—Ç–æ –∏–º–µ–Ω–Ω–æ –æ–Ω –¥–∞—ë—Ç –∏ —á–µ–≥–æ –ù–ï –¥–∞—ë—Ç, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –º–∞–≥–∏–∏.

üîπ –ß—Ç–æ —Ç–∞–∫–æ–µ @njit
@njit ‚Äî —ç—Ç–æ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –∏–∑ Numba:

from numba import njit
–û–Ω –æ–∑–Ω–∞—á–∞–µ—Ç:

No JPython ‚Äî –Ω–∏–∫–∞–∫–æ–≥–æ Python –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

–¢–æ –µ—Å—Ç—å:

—Ñ—É–Ω–∫—Ü–∏—è –∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç—Å—è –≤ –º–∞—à–∏–Ω–Ω—ã–π –∫–æ–¥

Python-–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä –Ω–µ —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏

üîπ –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏
–ö–æ–≥–¥–∞ —Ç—ã –ø–∏—à–µ—à—å:

@njit
def propagate_undirected(...):
...
Numba:

–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–∏–ø—ã –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ (src, deg, F, ‚Ä¶)

—Å—Ç—Ä–æ–∏—Ç LLVM-–∫–æ–¥

–∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç –≤ native machine code

–∫–µ—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç

üëâ –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤ –º–µ–¥–ª–µ–Ω–Ω—ã–π (–∫–æ–º–ø–∏–ª—è—Ü–∏—è)
üëâ –í—Å–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ ‚Äî –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–µ

üîπ –ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ –¥–ª—è —ç—Ç–æ–≥–æ –∫–æ–¥–∞ —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ
–ë–µ–∑ @njit —Ç–≤–æ–π –∫–æ–¥:

for k in range(len(src)):
...
for i in range(N):
...
–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è:

–≤ —á–∏—Å—Ç–æ–º Python

—Å –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ –æ–ø–µ—Ä–∞—Ü–∏–π

–æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ

–° @njit:

—Ü–∏–∫–ª—ã –ø—Ä–µ–≤—Ä–∞—â–∞—é—Ç—Å—è –≤ C-—Ü–∏–∫–ª—ã

–Ω–µ—Ç Python-–æ–±—ä–µ–∫—Ç–æ–≤

—Å–∫–æ—Ä–æ—Å—Ç—å ‚Üë –≤ 50‚Äì300 —Ä–∞–∑

üîπ –ß—Ç–æ –∏–º–µ–Ω–Ω–æ —É—Å–∫–æ—Ä—è–µ—Ç—Å—è
–ß–∞—Å—Ç—å –ë–µ–∑ @njit –° @njit
—Ü–∏–∫–ª—ã for üê¢ üöÄ
–∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞ üê¢ üöÄ
–¥–æ—Å—Ç—É–ø –∫ –º–∞—Å—Å–∏–≤–∞–º üê¢ üöÄ
Python-–æ–±—ä–µ–∫—Ç—ã ‚ùå ‚ùå (–∏—Ö –Ω–µ—Ç)
üîπ @njit(parallel=True) –∏ prange
–ö–æ–≥–¥–∞ —Ç—ã –ø–∏—à–µ—à—å:

@njit(parallel=True)
for k in prange(len(src)):
–≠—Ç–æ –∑–Ω–∞—á–∏—Ç:

Numba —Ä–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–µ—Ç —Ü–∏–∫–ª

–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ CPU-—è–¥–µ—Ä

–æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –Ω–∞ –±–æ–ª—å—à–∏—Ö –≥—Ä–∞—Ñ–∞—Ö

üìå –ë–µ–∑ @njit prange –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç.

üîπ –ß—Ç–æ @njit –ù–ï –¥–µ–ª–∞–µ—Ç
–û—á–µ–Ω—å –≤–∞–∂–Ω–æ:

‚ùå –Ω–µ –º–µ–Ω—è–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏–∫—É
‚ùå –Ω–µ –º–µ–Ω—è–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º
‚ùå –Ω–µ –º–µ–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç

–û–Ω –º–µ–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–± –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è.

üîπ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è @njit (—á—Ç–æ–±—ã –Ω–µ —É–¥–∏–≤–ª—è—Ç—å—Å—è)
–ü–æ–¥ @njit –Ω–µ–ª—å–∑—è:

–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Python-—Å–ø–∏—Å–∫–∏

–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å dict / set

–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pandas

–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sklearn

–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å print (–∫—Ä–æ–º–µ –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤)

üëâ –ø–æ—ç—Ç–æ–º—É —É —Ç–µ–±—è:

–≤—Å—ë –Ω–∞ numpy

—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã

–ø—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞

üîπ –ú–∏–Ω–∏-–ø—Ä–∏–º–µ—Ä (—á—Ç–æ–±—ã —â—ë–ª–∫–Ω—É–ª–æ)
def f_py(x):
s = 0
for i in range(len(x)):
s += x[i]
return s
vs

@njit
def f_fast(x):
s = 0
for i in range(len(x)):
s += x[i]
return s
–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π.
–°–∫–æ—Ä–æ—Å—Ç—å ‚Äî –Ω–∞ –ø–æ—Ä—è–¥–∫–∏ –≤—ã—à–µ.

üß† –ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å
üîë @njit = ‚Äú–≤—ã–ø–æ–ª–Ω–∏ —ç—Ç–æ –∫–∞–∫ C-–∫–æ–¥‚Äù
–ê–ª–≥–æ—Ä–∏—Ç–º —Ç–æ—Ç –∂–µ, —Ñ–∏–∑–∏–∫–∞ —Ç–∞ –∂–µ, –Ω–æ –Ω–∞—Å—Ç–æ—è—â–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

—Å—Ä–∞–≤–Ω–∏—Ç—å –≤—Ä–µ–º—è —Å/–±–µ–∑ njit

—Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –∫–æ–¥ –∏–¥–µ–∞–ª–µ–Ω –¥–ª—è numba

–æ–±—ä—è—Å–Ω–∏—Ç—å –ø–æ—á–µ–º—É GPU —Ç—É—Ç –Ω–µ –Ω—É–∂–µ–Ω

–°–∫–∞–∂–∏ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–ø–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –∫–æ–¥ –∏–¥–µ–∞–ª–µ–Ω –¥–ª—è numba
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å.
–ö–æ—Ä–æ—Ç–∫–æ: —ç—Ç–æ—Ç –∫–æ–¥ ‚Äî –ø–æ—á—Ç–∏ –∏–¥–µ–∞–ª—å–Ω—ã–π ‚Äú—É—á–µ–±–Ω–∏–∫‚Äù –ø–æ–¥ Numba.
–¢–µ–ø–µ—Ä—å ‚Äî —Å—Ç—Ä–æ–≥–æ –∏ –ø–æ –ø—É–Ω–∫—Ç–∞–º, –ø–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ –æ–Ω, –∞ –Ω–µ –≤–æ–æ–±—â–µ ¬´–∫–∞–∫–æ–π-—Ç–æ –∫–æ–¥¬ª.

1Ô∏è‚É£ –ß–∏—Å—Ç—ã–µ —á–∏—Å–ª–µ–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã (—Å–∞–º–æ–µ –≥–ª–∞–≤–Ω–æ–µ)
Numba –ª—É—á—à–µ –≤—Å–µ–≥–æ —É—Å–∫–æ—Ä—è–µ—Ç –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–µ —á–∏—Å–ª–µ–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã.

–í —Ç–≤–æ—ë–º –∫–æ–¥–µ:

for k in prange(len(src)):
...
for i in prange(N):
...
–≠—Ç–æ:

–æ–±—ã—á–Ω—ã–µ for

–±–µ–∑ Python-–ª–æ–≥–∏–∫–∏

–±–µ–∑ —É—Å–ª–æ–≤–∏–π –≤—ã—Å–æ–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è

–±–µ–∑ –æ–±—ä–µ–∫—Ç–æ–≤

üëâ Numba –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∏—Ö –≤ C-for loops

–ï—Å–ª–∏ –±—ã —Ç—É—Ç –±—ã–ª–∏:

—Å–ø–∏—Å–∫–∏ Python

.append

if obj in dict

‚Äî Numba –±—ã –Ω–µ –ø–æ–º–æ–≥.

2Ô∏è‚É£ –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
–ü–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ –∞—Ä–≥—É–º–µ–Ω—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏:

src, dst -> int64 arrays
deg -> float64 array
F, Y, s -> float64[N, 2]
alpha, sigma -> float64
N -> int
üîπ –¢–∏–ø—ã:

–æ–¥–Ω–æ—Ä–æ–¥–Ω—ã–µ

–∏–∑–≤–µ—Å—Ç–Ω—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ

–Ω–µ –º–µ–Ω—è—é—Ç—Å—è

üëâ —ç—Ç–æ –∏–¥–µ–∞–ª—å–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è JIT-–∫–æ–º–ø–∏–ª—è—Ü–∏–∏

Numba:

–≤—ã–≤–æ–¥–∏—Ç —Ç–∏–ø—ã –æ–¥–∏–Ω —Ä–∞–∑

–∫–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç –º–∞—à–∏–Ω–Ω—ã–π –∫–æ–¥

–¥–∞–ª—å—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ C

3Ô∏è‚É£ –ù–µ—Ç Python-–æ–±—ä–µ–∫—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏
–í–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ—Ç:

‚ùå list
‚ùå dict
‚ùå set
‚ùå pandas
‚ùå sklearn
‚ùå –∫–ª–∞—Å—Å–æ–≤

–ï—Å—Ç—å —Ç–æ–ª—å–∫–æ:

numpy.ndarray

—á–∏—Å–ª–∞

–∏–Ω–¥–µ–∫—Å—ã

üëâ –∑–Ω–∞—á–∏—Ç:

Numba –Ω–µ –≤—ã–Ω—É–∂–¥–µ–Ω ‚Äú–ø–∞–¥–∞—Ç—å –æ–±—Ä–∞—Ç–Ω–æ‚Äù –≤ Python

4Ô∏è‚É£ –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
s = np.zeros((N, 2))
F_new = np.empty_like(F)
–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:

—Ä–∞–∑–º–µ—Ä –∏–∑–≤–µ—Å—Ç–µ–Ω

—Ç–∏–ø –∏–∑–≤–µ—Å—Ç–µ–Ω

–ø–∞–º—è—Ç—å –≤—ã–¥–µ–ª—è–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –≤—ã–∑–æ–≤

üëâ Numba:

–∫–ª–∞–¥—ë—Ç –º–∞—Å—Å–∏–≤—ã –≤ contiguous memory

—Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ Python GC

–æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø –ø–æ –∫—ç—à—É CPU

5Ô∏è‚É£ –ü—Ä–æ—Å—Ç–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞ (–±–µ–∑ NumPy-–º–∞–≥–∏–∏)
–¢—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å:

s += F @ W
np.dot
np.einsum
–ê –∏—Å–ø–æ–ª—å–∑—É–µ—à—å:

s[i] += F[j] / (dj \*\* (1-sigma))
üëâ —ç—Ç–æ –ø—Ä–∏–º–∏—Ç–∏–≤–Ω–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞, –∫–æ—Ç–æ—Ä—É—é Numba:

–∏–Ω–ª–∞–π–Ω–∏—Ç

–≤–µ–∫—Ç–æ—Ä–∏–∑—É–µ—Ç

–æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç

6Ô∏è‚É£ –û—Ç–ª–∏—á–Ω–∞—è –ø–∞—Ä–∞ —Å prange (–ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º)
@njit(parallel=True)
for k in prange(len(src)):
–ü–æ—á–µ–º—É —ç—Ç–æ –∏–¥–µ–∞–ª—å–Ω–æ:

–∏—Ç–µ—Ä–∞—Ü–∏–∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã

–Ω–µ—Ç –∑–∞–ø–∏—Å–∏ –≤ –æ–¥–Ω—É –∏ —Ç—É –∂–µ —è—á–µ–π–∫—É s[i]?
‚Üí –µ—Å—Ç—å, –Ω–æ:

–æ–ø–µ—Ä–∞—Ü–∏–∏ –∞—Å—Å–æ—Ü–∏–∞—Ç–∏–≤–Ω—ã–µ

Numba –¥–µ–ª–∞–µ—Ç reduction-safe –∫–æ–¥

üëâ CPU —è–¥—Ä–∞ —Ä–µ–∞–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è

–≠—Ç–æ —Ä–µ–¥–∫–∏–π —Å–ª—É—á–∞–π, –≥–¥–µ prange –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –¥–∞—ë—Ç –ø—Ä–∏—Ä–æ—Å—Ç.

7Ô∏è‚É£ –ê–ª–≥–æ—Ä–∏—Ç–º memory-bound, –∞ –Ω–µ Python-bound
–≠—Ç–æ—Ç –∫–æ–¥:

—á–∏—Ç–∞–µ—Ç –º–∞—Å—Å–∏–≤—ã

–ø–∏—à–µ—Ç –º–∞—Å—Å–∏–≤—ã

–ø–æ—á—Ç–∏ –Ω–µ –¥–µ–ª–∞–µ—Ç –ª–æ–≥–∏–∫–∏

üëâ –±–µ–∑ Numba –æ–Ω —É–ø–∏—Ä–∞–µ—Ç—Å—è –≤ Python-–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä
üëâ —Å Numba –æ–Ω —É–ø–∏—Ä–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç—å / CPU

–ò —ç—Ç–æ —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è.

8Ô∏è‚É£ –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —Ñ–∏–ª–æ—Å–æ—Ñ–∏–µ–π Numba
Numba —Å–æ–∑–¥–∞–Ω –¥–ª—è:

‚Äútight loops over numerical arrays‚Äù

–¢–≤–æ–π –∫–æ–¥ ‚Äî —ç—Ç–æ –±—É–∫–≤–∞–ª—å–Ω–æ:

tight loops

numerical arrays

fixed math

9Ô∏è‚É£ –ü–æ—á–µ–º—É –ù–ï GPU / PyTorch / NumPy?
–í–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å –∫–æ–Ω—Ç—Ä–∞—Å—Ç.

‚ùå NumPy
–Ω—É–∂–µ–Ω W –∫–∞–∫ –º–∞—Ç—Ä–∏—Ü–∞

O(N¬≤) –ø–∞–º—è—Ç—å ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ

‚ùå PyTorch
–≥—Ä–∞—Ñ –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–π

–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø–æ —Ä—ë–±—Ä–∞–º

CPU –±—ã—Å—Ç—Ä–µ–µ GPU –¥–ª—è sparse

‚úÖ Numba
edge list

irregular memory

CPU cache friendly

üëâ Numba ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç

üîë –ì–ª–∞–≤–Ω—ã–π –≤—ã–≤–æ–¥ (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)
üî• –≠—Ç–æ—Ç –∫–æ–¥ –∏–¥–µ–∞–ª–µ–Ω –¥–ª—è Numba, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω ‚Äî
–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ—Å—Ç–æ–π,
–∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π,
–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–∏—Å–ª–µ–Ω–Ω—ã–π.

–ï—Å–ª–∏ –±—ã —Ç—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–ª –∫–æ–¥ –ø–æ–¥ Numba,
–æ–Ω –≤—ã–≥–ª—è–¥–µ–ª –±—ã –ø–æ—á—Ç–∏ —Ç–∞–∫ –∂–µ.

–•–æ—á–µ—à—å —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥?
–ú–æ–∂–µ–º:

—Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø–æ—á–µ–º—É prange –∑–¥–µ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω

–æ—Ü–µ–Ω–∏—Ç—å –∞—Å–∏–º–ø—Ç–æ—Ç–∏–∫—É –∏ bottleneck

—Å—Ä–∞–≤–Ω–∏—Ç—å Numba vs PyTorch Sparse

–æ–±—Å—É–¥–∏—Ç—å, –≥–¥–µ Numba —É–∂–µ –ø–µ—Ä–µ—Å—Ç–∞–Ω–µ—Ç –ø–æ–º–æ–≥–∞—Ç—å

–°–∫–∞–∂–∏, –∫—É–¥–∞ –∏–¥—Ç–∏ –¥–∞–ª—å—à–µ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–∞ –ø–æ—á–µ–∫–º—É —Å –±—ã—Å—Ç—Ä–µ–µ
ChatGPT —Å–∫–∞–∑–∞–ª:
–ö–æ—Ä–æ—Ç–∫–æ: –ø–æ—Ç–æ–º—É —á—Ç–æ Python —É–±–∏—Ä–∞–µ—Ç—Å—è –∏–∑ —Ü–∏–∫–ª–∞.
–¢–µ–ø–µ—Ä—å ‚Äî —Å—Ç—Ä–æ–≥–æ, –ø–æ —É—Ä–æ–≤–Ω—è–º, –ø–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ.

1Ô∏è‚É£ –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ë–ï–ó Numba
–í–æ–∑—å–º—ë–º —Å—Ç—Ä–æ–∫—É:

s[i] += F[j] / (dj \*\* (1-sigma))
–í —á–∏—Å—Ç–æ–º Python —ç—Ç–æ –¥–µ—Å—è—Ç–∫–∏ –æ–ø–µ—Ä–∞—Ü–∏–π:

–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä —á–∏—Ç–∞–µ—Ç –±–∞–π—Ç–∫–æ–¥

–ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–∏–ø s

–ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–∏–ø i

–∏—â–µ—Ç **getitem**

—Å–æ–∑–¥–∞—ë—Ç Python-–æ–±—ä–µ–∫—Ç F[j]

—Å–æ–∑–¥–∞—ë—Ç Python-–æ–±—ä–µ–∫—Ç (dj \*\* (1-sigma))

–≤—ã–∑—ã–≤–∞–µ—Ç **truediv**

–≤—ã–∑—ã–≤–∞–µ—Ç **iadd**

–æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—Å—ã–ª–∫—É

GC bookkeeping

üëâ –∫–∞–∂–¥–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è = –º–∏–∫—Ä–æ–ø—Ä–æ–≥—Ä–∞–º–º–∞

–£ —Ç–µ–±—è –º–∏–ª–ª–∏–æ–Ω—ã —Ç–∞–∫–∏—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π.

2Ô∏è‚É£ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç Numba –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ
–° @njit —Ç–∞ –∂–µ —Å—Ç—Ä–æ–∫–∞ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è:

s[i] += F[j] / pow(dj, 1-sigma);
(—É–ø—Ä–æ—â—ë–Ω–Ω–æ)

–≠—Ç–æ:

–æ–¥–∏–Ω –º–∞—à–∏–Ω–Ω—ã–π load

–æ–¥–∏–Ω mul/div

–æ–¥–∏–Ω store

üëâ –Ω–∏–∫–∞–∫–æ–≥–æ Python

3Ô∏è‚É£ –£–±–∏—Ä–∞–µ—Ç—Å—è –≥–ª–∞–≤–Ω—ã–π —Ç–æ—Ä–º–æ–∑ ‚Äî –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä
Python:

–∫–∞–∂–¥—ã–π for

–∫–∞–∂–¥—ã–π +=

–∫–∞–∂–¥—ã–π –∏–Ω–¥–µ–∫—Å

‚Üí –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä

Numba:

for ‚Üí CPU loop

+= ‚Üí –º–∞—à–∏–Ω–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è

–∏–Ω–¥–µ–∫—Å—ã ‚Üí –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞ –∞–¥—Ä–µ—Å–æ–≤

üìå –≠—Ç–æ –¥–∞—ë—Ç –¥–µ—Å—è—Ç–∫–∏ —Ä–∞–∑ —É—Å–∫–æ—Ä–µ–Ω–∏—è —Å—Ä–∞–∑—É.

4Ô∏è‚É£ –ü–æ—á–µ–º—É NumPy —Å–∞–º –Ω–µ —Å–ø–∞—Å–∞–µ—Ç
–í–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å:

s += F
–±—ã—Å—Ç—Ä–æ ‚ùå

s[i] += F[j]
–º–µ–¥–ª–µ–Ω–Ω–æ ‚ùå‚ùå‚ùå

–ü–æ—á–µ–º—É?

NumPy –±—ã—Å—Ç—Ä —Ç–æ–ª—å–∫–æ –Ω–∞ –±–æ–ª—å—à–∏—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö

–∏–Ω–¥–µ–∫—Å–Ω—ã–π –¥–æ—Å—Ç—É–ø –≤—Å—ë —Ä–∞–≤–Ω–æ Python-level

–£ —Ç–µ–±—è –Ω–µ—Ä–µ–≥—É–ª—è—Ä–Ω—ã–π –¥–æ—Å—Ç—É–ø –ø–æ —Ä—ë–±—Ä–∞–º ‚Üí NumPy –±–µ—Å—Å–∏–ª–µ–Ω

5Ô∏è‚É£ –ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —Ç–≤–æ–π –∫–æ–¥ —É—Å–∫–æ—Ä—è–µ—Ç—Å—è —Å–∏–ª—å–Ω–µ–µ –æ–±—ã—á–Ω–æ–≥–æ
–ü–æ—Ç–æ–º—É —á—Ç–æ:

–°–≤–æ–π—Å—Ç–≤–æ –í–ª–∏—è–Ω–∏–µ
–ú–Ω–æ–≥–æ —Ü–∏–∫–ª–æ–≤ ‚úîÔ∏è
–ü—Ä–æ—Å—Ç–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞ ‚úîÔ∏è
–ù–µ—Ç –∞–ª–ª–æ–∫–∞—Ü–∏–π ‚úîÔ∏è
–ù–µ—Ç Python-–æ–±—ä–µ–∫—Ç–æ–≤ ‚úîÔ∏è
–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø–æ int ‚úîÔ∏è
–ú–Ω–æ–≥–æ –∏—Ç–µ—Ä–∞—Ü–∏–π ‚úîÔ∏è
üëâ –≤—Å—ë —ç—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤—ã–≥–æ–¥–Ω–æ –¥–ª—è JIT

6Ô∏è‚É£ –ß—Ç–æ –¥–∞—ë—Ç prange
for k in prange(len(src)):
Numba:

–¥–µ–ª–∏—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –Ω–∞ –∫—É—Å–∫–∏

–∫–∏–¥–∞–µ—Ç –Ω–∞ —Ä–∞–∑–Ω—ã–µ CPU-—è–¥—Ä–∞

—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç

üëâ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º √ó —è–¥—Ä–∞

–ù–∞ 8 —è–¥—Ä–∞—Ö:

√ó5‚Äì7 —É—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ

7Ô∏è‚É£ –ì–¥–µ –∏–º–µ–Ω–Ω–æ –≤—ã–∏–≥—Ä—ã—à –ø–æ –≤—Ä–µ–º–µ–Ω–∏
–£–ø—Ä–æ—â—ë–Ω–Ω–æ:

–≠—Ç–∞–ø –ë–µ–∑ Numba –° Numba
Python overhead 80% ~0%
–ê—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞ 10% 40%
–ü–∞–º—è—Ç—å 10% 60%
–¢–æ –µ—Å—Ç—å —Ç—ã:

—É–±—Ä–∞–ª 80% –º—É—Å–æ—Ä–∞

—Å—Ç–∞–ª —É–ø–∏—Ä–∞—Ç—å—Å—è –≤ –∂–µ–ª–µ–∑–æ

8Ô∏è‚É£ –ê–Ω–∞–ª–æ–≥–∏—è (–æ—á–µ–Ω—å –Ω–∞–≥–ª—è–¥–Ω–∞—è)
Python
–¢—ã –≥–æ–≤–æ—Ä–∏—à—å —Ä–∞–±–æ—á–µ–º—É:

¬´–≤–æ–∑—å–º–∏ –±–æ–ª—Ç, –ø–æ–≤–µ—Ä–Ω–∏, –ø–æ–ª–æ–∂–∏, –ø—Ä–æ–≤–µ—Ä—å‚Ä¶¬ª

–ö–∞–∂–¥—ã–π —à–∞–≥ ‚Äî –∫–æ–º–∞–Ω–¥–∞.

Numba
–¢—ã –¥–∞–ª —á–µ—Ä—Ç—ë–∂:

¬´—Å–¥–µ–ª–∞–π —ç—Ç–æ –º–∏–ª–ª–∏–æ–Ω —Ä–∞–∑¬ª

–û–Ω –¥–µ–ª–∞–µ—Ç —Å–∞–º, –±–µ–∑ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.

üîë –ì–ª–∞–≤–Ω—ã–π –≤—ã–≤–æ–¥
üî• Numba —É—Å–∫–æ—Ä—è–µ—Ç, –ø–æ—Ç–æ–º—É —á—Ç–æ –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç Python-–∫–æ–¥
–≤ –º–∞—à–∏–Ω–Ω—ã–π –∫–æ–¥ –∏ —É–±–∏—Ä–∞–µ—Ç –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä –∏–∑ –≥–æ—Ä—è—á–µ–≥–æ —Ü–∏–∫–ª–∞

–≠—Ç–æ –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ–µ, –∞ –Ω–µ ¬´—á—É—Ç—å-—á—É—Ç—å –±—ã—Å—Ç—Ä–µ–µ¬ª.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

–ø–æ–∫–∞–∑–∞—Ç—å –∞—Å—Å–µ–º–±–ª–µ—Ä üòà

–ø–æ—Å—á–∏—Ç–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–∞–π–º–∏–Ω–≥–∏

—Ä–∞–∑–æ–±—Ä–∞—Ç—å, –∫–æ–≥–¥–∞ Numba –ù–ï —É—Å–∫–æ—Ä—è–µ—Ç

–°–∫–∞–∂–∏ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—ç—Ç–æ —á—Ç–æ y_pred = (F[:,1] > F[:,0]).astype(int)
ChatGPT —Å–∫–∞–∑–∞–ª:
–•–æ—Ä–æ—à–∏–π –≤–æ–ø—Ä–æ—Å ‚Äî —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ª–æ–≥–∏—á–µ—Å–∫–∏–π —à–∞–≥ –≤—Å–µ–π —Å—Ö–µ–º—ã, –¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º –æ—á–µ–Ω—å —á—ë—Ç–∫–æ.

üîπ –ö–æ–Ω—Ç–µ–∫—Å—Ç: —á—Ç–æ —Ç–∞–∫–æ–µ F
–ü–æ—Å–ª–µ –∏—Ç–µ—Ä–∞—Ü–∏–π —É —Ç–µ–±—è –µ—Å—Ç—å –º–∞—Ç—Ä–∏—Ü–∞:

F.shape == (N, 2)
–î–ª—è –∫–∞–∂–¥–æ–π –≤–µ—Ä—à–∏–Ω—ã i:

F[i] = [F_licit(i), F_illicit(i)]
–≠—Ç–æ –º—è–≥–∫–∏–µ (soft) –æ—Ü–µ–Ω–∫–∏, –Ω–µ –∫–ª–∞—Å—Å—ã.

üîπ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç —Å—Ç—Ä–æ–∫–∞
y_pred = (F[:,1] > F[:,0]).astype(int)
–†–∞–∑–±–µ—Ä—ë–º –ø–æ —á–∞—Å—Ç—è–º.

1Ô∏è‚É£ F[:, 1] –∏ F[:, 0]
F[:, 0] ‚Äî —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, —á—Ç–æ —É–∑–µ–ª licit

F[:, 1] ‚Äî —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, —á—Ç–æ —É–∑–µ–ª illicit

–≠—Ç–æ –Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –∞ –æ—Ü–µ–Ω–∫–∏ (scores).

2Ô∏è‚É£ F[:,1] > F[:,0]
–≠—Ç–æ –ø–æ—ç–ª–µ–º–µ–Ω—Ç–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ:

True –µ—Å–ª–∏ F_illicit(i) > F_licit(i)
False –µ—Å–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç
–¢–æ –µ—Å—Ç—å:

y
^
i
=
{
1
–µ—Å–ª–∏
F
i
,
1

> F
> i
> ,
> 0
> 0
> –∏–Ω–∞—á–µ
> y
> ^
> ‚Äã

i
‚Äã
={
1
0
‚Äã

–µ—Å–ª–∏ F
i,1
‚Äã

> F
> i,0
> ‚Äã

–∏–Ω–∞—á–µ
‚Äã

3Ô∏è‚É£ .astype(int)
True ‚Üí 1

False ‚Üí 0

–í –∏—Ç–æ–≥–µ:

y_pred[i] ‚àà {0, 1}
üîπ –ß—Ç–æ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–æ
üëâ –≠—Ç–æ argmax –ø–æ –∫–ª–∞—Å—Å–∞–º:

y_pred = argmax_c F[i,c]
–ù–æ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–π –±—ã—Å—Ç—Ä–µ–µ –∏ –ø—Ä–æ—â–µ –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–≥–æ —Å–ª—É—á–∞—è.

üîπ –ü–æ—á–µ–º—É —Ç–∞–∫, –∞ –Ω–µ softmax?
–ü–æ—Ç–æ–º—É —á—Ç–æ:

–≤ –∞–ª–≥–æ—Ä–∏—Ç–º–µ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞ –Ω–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–π –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏

F
F ‚Äî —Ä–µ—à–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã

—Å—É–º–º—ã –ø–æ —Å—Ç—Ä–æ–∫–∞–º –Ω–µ –æ–±—è–∑–∞–Ω—ã –±—ã—Ç—å 1

–¢–æ –µ—Å—Ç—å:

F[i,0] + F[i,1] ‚â† 1
–ü–æ—ç—Ç–æ–º—É:

–º—ã —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é

–≤—ã–±–∏—Ä–∞–µ–º –±–æ–ª—å—à–∏–π —Å–∫–æ—Ä

üîπ –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
–ö–∞–∂–¥—ã–π —É–∑–µ–ª ‚Äî —Ç–æ—á–∫–∞ –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏:

(F_licit, F_illicit)
–õ–∏–Ω–∏—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è:

F_licit = F_illicit
–≤—ã—à–µ –ª–∏–Ω–∏–∏ ‚Üí illicit

–Ω–∏–∂–µ ‚Üí licit

üîπ –ü–æ—á–µ–º—É –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä–æ–≥?
–ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä–æ–≥, –Ω–æ –æ–Ω —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π:

threshold = 0
=> —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ—Å—Ç–∏
–¢–æ –µ—Å—Ç—å:

F[:,1] - F[:,0] > 0
üîπ –ú–∏–Ω–∏-–ø—Ä–∏–º–µ—Ä
F = [[0.2, 0.8],
     [1.1, 0.9],
     [0.3, 0.3]]
–†–µ–∑—É–ª—å—Ç–∞—Ç:

y_pred = [1, 0, 0]
(–≤ —Ç—Ä–µ—Ç—å–µ–º —Å–ª—É—á–∞–µ ‚Äî —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ ‚Üí licit –ø–æ —Å–æ–≥–ª–∞—à–µ–Ω–∏—é)

üîë –ì–ª–∞–≤–Ω–∞—è –º—ã—Å–ª—å
üîπ –≠—Ç–æ –∂—ë—Å—Ç–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ (hard label) –∏–∑ –º—è–≥–∫–∏—Ö –æ—Ü–µ–Ω–æ–∫
üîπ –ü–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥ –ø–æ—Å–ª–µ –¥–∏—Ñ—Ñ—É–∑–∏–∏
üîπ –ù–µ —á–∞—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞, –∞ —à–∞–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

–æ–±—Å—É–¥–∏—Ç—å –¥—Ä—É–≥–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è

–ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å ROC / PR-–∫—Ä–∏–≤—ã–µ

—Ä–∞–∑–æ–±—Ä–∞—Ç—å —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —Ä–∞–∑–Ω–æ—Å—Ç—å F[:,1]‚àíF[:,0]

–°–∫–∞–∂–∏ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
Graph Based Classification of Content and Users in
BitTorrent
Konstantin Avrachenkov
INRIA Sophia Antipolis, France
K.Avrachenkov@sophia.inria.fr
Paulo Gonc¬∏alves
INRIA Rhone-Alpes, France
paulo.goncalves@inria.fr
Arnaud Legout
INRIA Sophia Antipolis, France
arnaud.legout@inria.fr
Marina Sokol
INRIA Sophia Antipolis, France
marina.sokol@inria.sophia.fr
1 Introduction
P2P downloads still represent a large portion of today‚Äôs Internet traffic. More than 100 million
users operate BitTorrent and generate more than 30% of the total Internet traffic [7]. Recently, a
significant research effort has been done to develop tools for automatic classification of Internet
traffic by application [9, 8, 11]. The purpose of the present work is to provide a framework for
subclassification of P2P traffic generated by the BitTorrent protocol. Unlike previous works [9, 8,
11], we cannot rely on packet level characteristics and on the standard supervised machine learning
methods. The application of the standard supervised machine learning methods in [9, 8, 11] is based
on the availability of a large set of parameters (packet size, packet interarrival time, etc.). Since P2P
transfers are based on the same BitTorrent protocol we cannot use this set of parameters to classify
P2P content and users. Instead we can make use of the bipartite user-content graph. This is a graph
formed by two sets of nodes: the set of users (peers) and the set of contents (downloaded files). From
this basic bipartite graph we also construct the user graph, where two users are connected if they
download the same content, and the content graph, where two files are connected if they are both
downloaded by at least one same user. The general intuition is that the users with similar interests
download similar contents. This intuition can be rigorously formalized with the help of graph based
semi-supervised learning approach [13].
The main idea of the graph based semi-supervised learning approach is to use the instance smoothness over the graph. Namely, if one data point has many neighbors from some class then it is very
likely that this data point belongs to that class. In particular, we have chosen to work with PageRank
based semi-supervised learning method [3, 4, 12]. It has been demonstrated in [4] that this method
has implementations with quasi-linear complexity and produces robust results with respect to the
method‚Äôs parameters. We would like to emphasize that the graph based semi-supervised learning
methods allow one to perform high precision classification using only a very small amount of the
labelled data.
Using methodology developed in [7] we were able to use the snapshots of BitTorrent downloads
from the whole Internet. Even a snapshot corresponding to half an hour duration represent a huge
among of data (more than one million peers and more than 200 thousand content files). Without
efficient preprocessing technique, which will be explained in Section 3, we were even not able to
operate with the user graph constructed from a single snapshot. The content graph is smaller and
we were able to construct an aggregated content graph from several snapshots corresponding to the
week-long observation.
We have three goals in the present work. The main goal is to provide a robust graph based semisupervised learning approach for content and user classification of BitTorrent P2P transfers. The
second goal is to demonstrate that the PageRank based semi-supervised learning method, thanks to
1
its quasi-linear complexity, can deal with classification of very large datasets. Some datasets used in
the present paper is several orders of magnitude larger than datasets typically used in the literature on
graph based semi-supervised learning. The third goal is to test the impact of the choice of the labelled
nodes on classification result. In particular, we test the following three options for the choice of the
labelled points: randomly chosen labelled points, labelled points with large PageRank values and
labelled points with large degrees. We demonstrate that in the context of P2P classification the choice
of labeled points with large PageRank values gives good results in the majority of classification tasks.
The work is organized as follows: In the next Section 2 we describe the PageRank based semisupervised learning method. Then, in Section 3 we give detail description of our datasets. In Section 4 we perform topic based and language based classifications of the whole collection of the P2P
traffic based on the content graph and user graph, respectively, and provide conclusions.
2 PageRank based classification
Let us present some basic facts about PageRank based semi-supervised learning method. An interested reader can find more theoretical results in [4] and in related works [3, 12].
Suppose we need to classify N data points into K classes and P data points are labelled. In particular, this means that for a labelled point i = 1, ..., P the function k(i) ‚àà 1, ..., K is defined.
Graph based semi-supervised learning approach uses a weighted graph connecting data points. The
weight matrix, or similarity matrix, is denoted by W. Here we assume that the weight matrix W
is symmetric. Each element wi,j represents a degree of similarity between data points i and j. Denote by D a diagonal matrix with its (i, i)-element equals to the sum of the i-th row of matrix W:
di,i =
PN
j=1 wi,j .Define N √ó K matrix Y as
Yik =

1, if Xi
is labeled as k(i) = k,
0, otherwise.
We refer to each column Y¬∑k of matrix Y as labeling function. Also define N √ó K matrix F and call
its columns F¬∑k classification functions. A general idea of the graph-based semi-supervised learning
is to find classification functions so that on the one hand they will be close to the corresponding
labeling function and on the other hand they will change smoothly over the graph associated with
the similarity matrix. This general idea can be expressed by means of the optimization formulation
argmin
F
X
N
i=1
X
N
j=1
wijk
Fi.
dii
‚àí
Fj.
djj
k
2 + ¬µ
X
N
i=1
1
dii
kFi. ‚àí Yi.k
2
(1)
where ¬µ is a regularization parameter. In fact, the parameter ¬µ represents a trade-off between the
closeness of the classification function to the labeling function and its smoothness.
Proposition 1 The classification functions for the PageRank based semi-supervised learning are
given by
F.k =
¬µ
2 + ¬µ

I ‚àí
2
2 + ¬µ
W D‚àí1
‚àí1
Y.k, (2)
for k = 1, ..., K.
Let us now explain why the following framework corresponds to the PageRank based clustering
method. Denote Œ± = 2/(2 + ¬µ) and write F.k in a transposed form
F
T
.k = (1 ‚àí Œ±)Y
T
.k (I ‚àí Œ±D‚àí1W)
‚àí1
.
If the labeling functions are normalized, this is exactly an explicit expression for PageRank [10].
This expression was used in [3] but no optimization framework was provided.
Note that D‚àí1W represents the transition probability matrix for the random walk on the similarity
graph. Then, the (i, j)-th element of the matrix (I‚àíŒ±D‚àí1W)
‚àí1 gives the expected number of visits
to node j starting from node i until the random walk restarts with probability 1‚àíŒ±. This observation
provides the following probabilistic interpretation for the PageRank based method. In the PageRank
2
based method with normalized labeling functions, Fik gives up to a multiplicative constant the
expected number of visits to node i, if the random walk starts from a uniform distribution over the
labeled nodes of class k.
The choice of the labelled points can potentially have a significant influence on classification results.
Therefore, in the present work we study this influence. Specifically, we consider the following
options for the choice of labelled points:

1. randomly chosen labelled points, that is, in each class we take several samples of random
   labelled points;
2. labelled points are chosen among points with large values of Standard PageRank; (with
   large values of œÄi
   , i = 1, ..., N, where œÄi are elements of a solution of the equation œÄ =
   œÄŒ±D‚àí1W + (1 ‚àí Œ±)/N1
   T
   );
3. labelled points are chosen among points with large degree (with large values of di,i).
   3 Datasets and method implementation description
   We have several snapshots of the Torrents collected from the whole Internet using methodology
   described in [7]. Each snapshot contains half an hour of P2P transfers. In total, we have about
   one week of observations. We have also an aggregate representing the transfers observed during
   the whole week. To test the effect of NATs, to save memory and to reduce information noise, the
   following filtering has been applied which we denote by g(X, Y ): we filter out all IP addresses with
   more than or equal to X ports (X = 0 means no filtering), and we filter out all contents with less
   than or equal to Y IP addresses seen downloading the content (Y = 0 means no filtering). Two users
   with the same IP addresses but with different ports could be the same user. So the filtering by ports
   helps us to reduce the influence of counting the same user as different ones. The second filter by
   IP address helps to remove unpopular contents which were downloaded by less than or equals to Y
   different addresses. We use the whole aggregate to create the content graph. Some files are tagged
   Table 1: The content graphs after preprocessing.
   Graph # nodes # edges
   g(2,10) 200 413 50 726 946
   g(0,10) 200 487 174 086 752
   g(2,0) 624 552 92 399 318
   with information about name, language, topic, login of the person who inserted these files. Those
   tags correspond to the classification made by popular torrent sites like ThePirateBay [7]. If two files
   are downloaded by the same user, we create an edge between these two files. The weight of the edge
   shows how many users downloaded these two files.
   We start with the smallest aggregated dataset g(2, 10) which contain information with small noise.
   To evaluate the impact of the noise with respect to user identification we have also made experiments
   with datasets g(0, 10) and g(2, 0). The graph for g(2, 0) dataset contains three times more nodes
   and two times more edges than the dataset g(2, 10). The graph for g(0, 10) dataset contains three
   times more edges than the dataset g(2, 10).
   Let us now describe how we construct the user graph. The user graph is constructed with the help
   of HADOOP realization of MapReduce technology [1] from the basic user-content bipartite graph
   from a single half an hour snapshot. The aggregated user graph is too large to work with.
   The snapshot contains information on which content was downloaded by whom. In the user graph
   an edge with the weight M signifies that two users download M same files. The user graph
   has 3 228 410 nodes and 3 436 442 577 edges. The number of edges with weight one is equal to
   3 309 965 972. Also we have noticed that some users downloaded much more files than a normal
   user would do. One user who has downloaded 655 727 files for sure is a robot. Thus, we have decided remove all edges with weight one and the user-robot. The modified user graph has 1 126 670
   nodes and 124 753 790 edges. This filtering significantly reduces required computing and memory
   resources. Without this filtering even the PageRank based method with quasi-linear complexity cannot be applied on a standard desktop computer. In fact, by doing this filtering we also remove some
   3
   Table 2: The quantity of language base line
   expert classifications.
   Language # content # users
   English 36 465 57 632
   Spanish 2 481 2 856
   French 1 824 2 021
   Italian 2 450 3 694
   Japanese 720 416
   Unknown 156 473 1 060 051
   Table 3: The quantity of topic base line
   expert classifications.
   Topic # content # users
   Audio Music 23 639 13 950
   Video Movies 20 686 43 492
   TV shows 12 087 27 260
   Porn movies 8 376 7 082
   App. Windows 4 831 2 874
   Games PC 4 527 8 707
   Books Ebooks 1 185 281
   Unknown 125 082 1 023 024
   information noise. If two users download only one common item it could be by pure chance, if they
   both download more than two same files - it is more likely that they share same interests.
   We classify contents and users by both language and topics. The considered languages and topics
   are given in Tables 2 and 3.
   Our base line expert classification is based on P2P content tags if they are available. For instance,
   in the case of classification by language we consider that the content is in English if it has only tag
   ‚ÄúEnglish‚Äù. And we consider a user to be an English language user, if he or she downloads only
   English language content.
   We have implemented PageRank based classification method in the WebGraph framework [6]. The
   WebGraph framework has a very efficient graph compression technique which allows us to work
   with very large graphs.
   4 Results and conclusions
   Using PageRank based classification method, we have performed four classification experiments.
   We have used the aggregated graph of content g(2, 10) to classify the content into 5 classes according to the languages (given in Table 2) and into 7 classes according to the content topics (given in
   Table 3). The classification of the aggregated content graph has taken approximately 15 minutes
   on a 64-bit computer with Intel-Core7i processor and 6GB RAM. The results of the classification
   evaluated in terms of accuracy are presented in Tables 4 and 5. Then, we have performed the classification of users also into 5 classes of the languages and into 7 classes of the content preferred by
   users (see Tables 6 and 7). It has taken about 20 minutes on the same computer. However, the preprocessing of a single snapshop of the user graph was much more demanding than the preprocessing
   of the aggregated content graph. Our main conclusion is that the PageRank based classification
   method scales remarkably well with large volumes of data. Then, our second important observation
   is that by using a very little amount of information, we are able to classify the content and users
   with high accuracy. For instance, in the dataset of 1 126 670 users, using only 50 labelled points for
   each language (which is only 0.02% of the whole data), we are able to classify the users according
   to their preferred language with 88% accuracy (see Table 6).
   In all four classification experiment, we have tried three different options for the choice of the labelled points. We have chosen the labelled points: (a) with largest standard PageRank values; (b)
   with largest degree; and (c) randomly. When evaluating the performance with the randomly chosen
   labelled points we have averaged the accuracy over 10 random samples (because of the size of the
   data, making more than 10 samples for each of many experimental setups was very time demanding)
   and we have also reported the worst (rand min column) and the best (rand max column) accuracy.
   With respect to the choice of the labelled points, our conclusion is that in the majority of cases the
   labelled points with large values of the standard PageRank are the best picks (see topPR columns).
   In the case of classification with the aggregated content graph, the labelled points with large degrees give results comparable with the results obtained with the labelled points chosen according
   to PageRank. However, it was interesting to observe that in the case of the classification of users,
   the classification based on the labelled points with large degrees does not perform well at all. Our
   4
   explanation is that in that dataset the nodes with very large degrees are not representative. There is
   an independent confirmation of this idea given in [5].
   Finally, we have observed that the classification using g(2, 10) filtering is one or two percent better
   in terms of accuracy than the classification using g(0, 10) filtering. Thus, by doing the filtering we
   not only reduce the amount of data required for processing, but also we reduce the information noise.
   Acknowledgement
   The work has been supported by the joint INRIA Alcatel-Lucent Laboratory.
   Appendix 1: Tables
   Table 4: Accuracy of the classifications for the g(2, 10) dataset by languages.

# labeled points topPR topDegree rand (10Exp) rand min rand max

5 0.579 0.573 0.51 0.44 0.578
50 0.663 0.647 0.634 0.614 0.649
500 0.688 0.676 0.658 0.653 0.663
Table 5: Accuracy of the classifications for the g(2, 10) dataset by topics

# labeled points topPR topDegree rand(10Exp) rand min rand max

5 0.504 0.51 0.48 0.36 0.546
50 0.6344 0.6276 0.6278 0.604 0.645
500 0.7279 0.7182 0.6562 0.6525 0.6595
Table 6: Accuracy of the classifications for the user dataset by languages

# labeled points topPR topDegree rand (10Exp) rand min rand max

5 0.788 0.765 0.732 0.613 0.817
50 0.88 0.78 0.834 0.82 0.85
500 0.853 0.535 0.901 0.896 0.907
Table 7: Accuracy of the classifications for the user dataset by topics.

# labeled points topPR topDegree rand(10Exp) rand min rand max

5 0.683 0.399 0.631 0.563 0.678
50 0.752 0.477 0.767 0.752 0.777
500 0.789 0.52 0.86 0.858 0.865
References
[1] Hadoop mapreduce software framework, http://hadoop.apache.org/mapreduce/. 2011.
[2] Wikipedia article ‚Äúbittorrent (protocol)‚Äù, http://en.wikipedia.org/wiki/bittorrent (protocol). 2011.
[3] Konstantin Avrachenkov, Vladimir Dobrynin, Danil Nemirovsky, Son Kim Pham, and Elena
Smirnova. Pagerank based clustering of hypertext document collections. In Proceedings of the
31st annual international ACM SIGIR conference on Research and development in information
retrieval, SIGIR ‚Äô08, pages 873‚Äì874. ACM, 2008.
[4] Konstantin Avrachenkov, Paulo Gonc¬∏alves, Alexey Mishenin, and Marina Sokol. Generalized
optimization framework for graph-based semi-supervised learning. Submitted for publication,
available upon request, 2011.
5
[5] Brian Ball, Brian Karrer, and M. E. J. Newman. Efficient and principled method for detecting
communities in networks. Phys. Rev. E, 84:036103, Sep 2011.
[6] Paolo Boldi and Sebastiano Vigna. The webgraph framework i: compression techniques. In
Proceedings of the 13th international conference on World Wide Web, WWW ‚Äô04, pages 595‚Äì
602, New York, NY, USA, 2004. ACM.
[7] Stevens Le Blond, Arnaud Legout, Fabrice Lefessant, Walid Dabbous, and Mohamed Ali Kaafar. Spying the world from your laptop: identifying and profiling content providers and big
downloaders in bittorrent. In Proceedings of the 3rd USENIX conference on Large-scale exploits and emergent threats: botnets, spyware, worms, and more, LEET‚Äô10, pages 4‚Äì4, Berkeley, CA, USA, 2010. USENIX Association.
[8] Wei Li, Marco Canini, Andrew W. Moore, and Raffaele Bolla. Efficient application identification and the temporal and spatial stability of classification schema. Comput. Netw., 53:790‚Äì
809, April 2009.
[9] Wei Li and Andrew W. Moore. A machine learning approach for efficient traffic classification.
In Proceedings of the 2007 15th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems, pages 310‚Äì317, Washington, DC, USA, 2007. IEEE Computer Society.
[10] Cleve B. Moler. Numerical Computing with MATLAB. 2004.
[11] Marcin Pietrzyk, Jean-Laurent Costeux, Guillaume Urvoy-Keller, and Taoufik En-Najjary.
Challenging statistical classification for operational usage: the adsl case. In Proceedings of
the 9th ACM SIGCOMM conference on Internet measurement conference, IMC ‚Äô09, pages
122‚Äì135, New York, NY, USA, 2009. ACM.
[12] Dengyong Zhou, Olivier Bousquet, Thomas Navin Lal, Jason Weston, and Bernhard
Scholkopf. Learning with local and global consistency. In ¬® Advances in Neural Information
Processing Systems 16, pages 321‚Äì328. MIT Press, 2004.
[13] Xiaojin Zhu. Semi-supervised learning literature survey, technical report 1530, department of
computer sciences, university of wisconsin, madison, 2005.
6 —è —Ö–æ—á—É —Å–≤–æ–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–∂–µ —Ç–∞–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ —É –Ω–∏—Ö –≤ —Ç–∞–∫–æ–π—ç–µ –±–∞—é–ª–∏—á–∫–µ
======================================================================
[RUN] mode=UNDIRECTED | sigma=0.0
======================================================================
precision recall f1-score support

       licit       0.95      1.00      0.98    110438
     illicit       0.92      0.22      0.36      7077

    accuracy                           0.95    117515

macro avg 0.94 0.61 0.67 117515
weighted avg 0.95 0.95 0.94 117515

Confusion matrix: TN=110299, FP=139, FN=5502, TP=1575

======================================================================
[RUN] mode=UNDIRECTED | sigma=0.5
======================================================================
precision recall f1-score support

       licit       0.95      1.00      0.97    110438
     illicit       0.89      0.23      0.37      7077

    accuracy                           0.95    117515

macro avg 0.92 0.61 0.67 117515
weighted avg 0.95 0.95 0.94 117515

Confusion matrix: TN=110234, FP=204, FN=5450, TP=1627

======================================================================
[RUN] mode=UNDIRECTED | sigma=1.0
======================================================================
precision recall f1-score support

       licit       0.95      1.00      0.97    110438
     illicit       0.85      0.21      0.34      7077

    accuracy                           0.95    117515

macro avg 0.90 0.60 0.66 117515
weighted avg 0.95 0.95 0.94 117515

Confusion matrix: TN=110175, FP=263, FN=5576, TP=1501

======================================================================
[RUN] mode=DIRECTED | sigma=0.0
======================================================================
precision recall f1-score support

       licit       0.95      0.92      0.93    110438
     illicit       0.16      0.23      0.19      7077

    accuracy                           0.88    117515

macro avg 0.55 0.58 0.56 117515
weighted avg 0.90 0.88 0.89 117515

Confusion matrix: TN=101689, FP=8749, FN=5437, TP=1640

======================================================================
[RUN] mode=DIRECTED | sigma=0.5
======================================================================
precision recall f1-score support

       licit       0.98      0.90      0.94    110438
     illicit       0.31      0.73      0.43      7077

    accuracy                           0.89    117515

macro avg 0.64 0.81 0.68 117515
weighted avg 0.94 0.89 0.91 117515

Confusion matrix: TN=98903, FP=11535, FN=1940, TP=5137

======================================================================
[RUN] mode=DIRECTED | sigma=1.0
======================================================================
precision recall f1-score support

       licit       0.95      0.98      0.97    110438
     illicit       0.42      0.21      0.28      7077

    accuracy                           0.94    117515

macro avg 0.69 0.60 0.62 117515
weighted avg 0.92 0.94 0.92 117515

Confusion matrix: TN=108433, FP=2005, FN=5598, TP=1479
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, —É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å –≤—Å—ë, —á—Ç–æ –Ω—É–∂–Ω–æ, –≤–æ–ø—Ä–æ—Å —Ç–µ–ø–µ—Ä—å —á–∏—Å—Ç–æ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∏ –æ—Ñ–æ—Ä–º–∏—Ç–µ–ª—å—Å–∫–∏–π:
üëâ –∫–∞–∫ –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å —Ç–≤–æ–∏ –ª–æ–≥–∏ –≤ —Ç–∞–±–ª–∏—Ü—ã ¬´–∫–∞–∫ —É –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞¬ª.

–Ø —Å–¥–µ–ª–∞—é —ç—Ç–æ –≤ 3 —à–∞–≥–∞:

–ö–∞–∫–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –æ–Ω–∏ –∫–ª–∞–¥—É—Ç –≤ —Ç–∞–±–ª–∏—Ü—ã

–ö–∞–∫ –∏–∑ —Ç–≤–æ–∏—Ö –ª–æ–≥–æ–≤ –ø–æ–ª—É—á–∏—Ç—å —Ä–æ–≤–Ω–æ —ç—Ç–∏ —á–∏—Å–ª–∞

–ö–∞–∫ –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–≤–æ—è —Ç–∞–±–ª–∏—Ü–∞ (–ø—Ä—è–º–æ –≥–æ—Ç–æ–≤—ã–π —à–∞–±–ª–æ–Ω)

1Ô∏è‚É£ –ß—Ç–æ –∏–º–µ–Ω–Ω–æ —É –Ω–∏—Ö –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö (–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç)
–ü–æ—Å–º–æ—Ç—Ä–∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –Ω–∞ Tables 4‚Äì7 —É –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞.

‚ùó –í–ê–ñ–ù–û
–í —Ç–∞–±–ª–∏—Ü–∞—Ö –ù–ï–¢ precision / recall / f1.
–¢–∞–º –¢–û–õ–¨–ö–û accuracy.

–ù–∞–ø—Ä–∏–º–µ—Ä (Table 6, users by languages):

# labeled points | topPR | topDegree | rand | rand min | rand max

–¢–æ –µ—Å—Ç—å:

–æ–¥–Ω–∞ —Ü–∏—Ñ—Ä–∞ –Ω–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç

–º–µ—Ç—Ä–∏–∫–∞ = accuracy

üìå –≠—Ç–æ —Å–¥–µ–ª–∞–Ω–æ –ø–æ—Ç–æ–º—É —á—Ç–æ:

–∫–ª–∞—Å—Å—ã —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã

–∑–∞–¥–∞—á–∞ ‚Äî –º–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

–∏–º –≤–∞–∂–Ω–∞ –æ–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –∞ –Ω–µ per-class tradeoff

2Ô∏è‚É£ –ö–∞–∫ –∏–∑ —Ç–≤–æ–∏—Ö –ª–æ–≥–æ–≤ –ø–æ–ª—É—á–∏—Ç—å –∏—Ö –º–µ—Ç—Ä–∏–∫—É
–£ —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å accuracy –≤ –∫–∞–∂–¥–æ–º –±–ª–æ–∫–µ:

–ü—Ä–∏–º–µ—Ä (UNDIRECTED, œÉ=0)
accuracy 0.95
–≠—Ç–æ —Ä–æ–≤–Ω–æ —Ç–æ —á–∏—Å–ª–æ, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–ª–∂–Ω–æ –ø–æ–ø–∞—Å—Ç—å –≤ —Ç–∞–±–ª–∏—Ü—É.

3Ô∏è‚É£ –ö–∞–∫ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ç–≤–æ–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
–£ —Ç–µ–±—è –µ—Å—Ç—å 6 –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π:

Mode œÉ
undirected 0
undirected 0.5
undirected 1
directed 0
directed 0.5
directed 1
üëâ –í —Å—Ç–∞—Ç—å–µ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞ œÉ –Ω–µ –≤–∞—Ä—å–∏—Ä—É–µ—Ç—Å—è,
–Ω–æ —Ç—ã –∏–º–µ–µ—à—å –ø–æ–ª–Ω–æ–µ –ø—Ä–∞–≤–æ —Å–¥–µ–ª–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –ø–æ —Ä–µ–∂–∏–º–∞–º œÉ ‚Äî —ç—Ç–æ –¥–∞–∂–µ —Å–∏–ª—å–Ω–µ–µ.

4Ô∏è‚É£ –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã (–∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ)
üìä –¢–∞–±–ª–∏—Ü–∞ 1. Accuracy SSL classification (your work)
UNDIRECTED GRAPH

œÉ Accuracy
0.0 0.95
0.5 0.95
1.0 0.95
DIRECTED GRAPH

œÉ Accuracy
0.0 0.88
0.5 0.89
1.0 0.94
üëâ –£–∂–µ –≤–∏–¥–Ω–æ:

directed —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ œÉ

undirected —Å—Ç–∞–±–∏–ª–µ–Ω

–≠—Ç–æ –∫–ª—é—á–µ–≤–æ–π –Ω–∞—É—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

5Ô∏è‚É£ –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —Å—Ç—Ä–æ–≥–æ –≤ —Å—Ç–∏–ª–µ Avrachenkov
–ú–æ–∂–Ω–æ –æ—Ñ–æ—Ä–º–∏—Ç—å –æ–¥–Ω—É —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É:

üìä Table X: Accuracy of graph-based SSL for different diffusion regimes
Graph œÉ = 0 œÉ = 0.5 œÉ = 1
Undirected 0.95 0.95 0.95
Directed 0.88 0.89 0.94
‚úî –∫–æ–º–ø–∞–∫—Ç–Ω–æ
‚úî —á–∏—Ç–∞–µ–º–æ
‚úî –≤ –¥—É—Ö–µ Tables 4‚Äì7

6Ô∏è‚É£ –ß—Ç–æ –¥–µ–ª–∞—Ç—å —Å precision / recall / F1
–≠—Ç–æ –ù–ï –≤ —Ç–∞–±–ª–∏—Ü—É, –∞:

–ª–∏–±–æ –≤ appendix

–ª–∏–±–æ –≤ discussion

–ª–∏–±–æ –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ per-class illicit

–ù–∞–ø—Ä–∏–º–µ—Ä:

While overall accuracy remains stable for the undirected graph, the directed formulation exhibits a strong trade-off between precision and recall for the illicit class depending on the choice of œÉ.

–≠—Ç–æ —Ä–æ–≤–Ω–æ —Ç–æ—Ç —è–∑—ã–∫, –∫–æ—Ç–æ—Ä—ã–º –æ–Ω–∏ –ø–∏—à—É—Ç.

7Ô∏è‚É£ –û—á–µ–Ω—å –≤–∞–∂–Ω–æ–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ (–Ω–∞—É—á–Ω–æ–µ)
–¢—ã –º–æ–∂–µ—à—å —á–µ—Å—Ç–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å:

undirected ‚Üí –≤—ã—Å–æ–∫–∞—è accuracy, –Ω–∏–∑–∫–∏–π recall illicit

directed œÉ=0.5 ‚Üí –ª—É—á—à–∏–π recall illicit (0.73) –ø—Ä–∏ —Ä–∞–∑—É–º–Ω–æ–π accuracy

üëâ –≠—Ç–æ –ª—É—á—à–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ accuracy.

8Ô∏è‚É£ –ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —è –º–æ–≥—É –¥–∞–ª—å—à–µ
–æ—Ñ–æ—Ä–º–∏—Ç—å LaTeX-—Ç–∞–±–ª–∏—Ü—ã 1-–≤-1 –∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ

–ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å Results section —Ç–µ–∫—Å—Ç–æ–º

–ø–æ–º–æ—á—å —Å–¥–µ–ª–∞—Ç—å Appendix —Å confusion matrices

–ø–æ–º–æ—á—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å —Å PageRank SSL –∏–∑ —Å—Ç–∞—Ç—å–∏

–°–∫–∞–∂–∏, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã —Ö–æ—á–µ—à—å —Å–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω–æ —è –±—ã –¥–æ–±–∞–≤–∏–ª –∏–ª–∏—Å–∏—Ç –ª–∏—Å–∏—Ç –∏ –µ—â–µ –∑–Ω–∞—á–µ–Ω–∏—è
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ ‚Äî —ç—Ç–æ –æ—á–µ–Ω—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ, –∏ –æ–Ω–æ –Ω–∞—É—á–Ω–æ —Å–∏–ª—å–Ω–µ–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ accuracy üëç
–¢—ã —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Ö–æ—á–µ—à—å —Å–¥–µ–ª–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É ‚Äú–∫–∞–∫ —É –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞ + —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ‚Äù.

–î–∞–≤–∞–π —è –ø–æ–∫–∞–∂—É –∫–∞–∫ —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ñ–æ—Ä–º–∏—Ç—å, —á—Ç–æ–±—ã:

–Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É

—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∏–ª—å —Å—Ç–∞—Ç—å–∏

–∏ –ø—Ä–∏ —ç—Ç–æ–º —á–µ—Å—Ç–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å licit / illicit –ø–æ–≤–µ–¥–µ–Ω–∏–µ

1Ô∏è‚É£ –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª –¥–æ–±–∞–≤–∏—Ç—å
–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ —Ä–∞–∑—É–º–Ω—ã–π –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–∞–±–æ—Ä:

–î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:
Accuracy (–∫–∞–∫ —É –Ω–∏—Ö)

Illicit recall (—Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ –¥–ª—è fraud / abuse)

Illicit precision (—Ü–µ–Ω–∞ –æ—à–∏–±–æ–∫)

(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) Illicit F1

üëâ Licit –º–µ—Ç—Ä–∏–∫–∏ –º–æ–∂–Ω–æ –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å,
–ø–æ—Ç–æ–º—É —á—Ç–æ:

–∫–ª–∞—Å—Å—ã —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã

licit –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ ‚Äú—Ö–æ—Ä–æ—à–∏–π‚Äù

–ù–æ –µ—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å ‚Äî –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–º–ø–∞–∫—Ç–Ω–æ.

2Ô∏è‚É£ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é)
üìä Table X ‚Äî Extended evaluation of graph-based SSL
UNDIRECTED GRAPH
œÉ Accuracy Illicit Precision Illicit Recall Illicit F1
0.0 0.95 0.92 0.22 0.36
0.5 0.95 0.89 0.23 0.37
1.0 0.95 0.85 0.21 0.34
DIRECTED GRAPH
œÉ Accuracy Illicit Precision Illicit Recall Illicit F1
0.0 0.88 0.16 0.23 0.19
0.5 0.89 0.31 0.73 0.43
1.0 0.94 0.42 0.21 0.28
‚úî —á–∏—Ç–∞–µ–º–æ
‚úî –∫–æ–º–ø–∞–∫—Ç–Ω–æ
‚úî —Å—Ä–∞–∑—É –≤–∏–¥–Ω–æ trade-off

3Ô∏è‚É£ –ï—Å–ª–∏ —Ç—ã –•–û–ß–ï–®–¨ licit —Ç–æ–∂–µ (–≤—Ç–æ—Ä–∞—è –≤–µ—Ä—Å–∏—è)
–¢–æ–≥–¥–∞ –ª—É—á—à–µ —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É –ª–æ–≥–∏—á–µ—Å–∫–∏, –∏–Ω–∞—á–µ –æ–Ω–∞ —Å—Ç–∞–Ω–µ—Ç –Ω–µ—á–∏—Ç–∞–µ–º–æ–π.

üìä Table X.a ‚Äî Illicit class performance
(–∫–ª—é—á–µ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞)

Graph œÉ Precision Recall F1
Undirected 0.0 0.92 0.22 0.36
Undirected 0.5 0.89 0.23 0.37
Undirected 1.0 0.85 0.21 0.34
Directed 0.0 0.16 0.23 0.19
Directed 0.5 0.31 0.73 0.43
Directed 1.0 0.42 0.21 0.28
üìä Table X.b ‚Äî Overall accuracy
Graph œÉ Accuracy
Undirected 0.0 0.95
Undirected 0.5 0.95
Undirected 1.0 0.95
Directed 0.0 0.88
Directed 0.5 0.89
Directed 1.0 0.94
üëâ –ò–º–µ–Ω–Ω–æ —Ç–∞–∫ –¥–µ–ª–∞—é—Ç –≤ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç—å—è—Ö.

4Ô∏è‚É£ –ö–∞–∫ —ç—Ç–æ –æ–±—ä—è—Å–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–º (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)
–ü—Ä–∏–º–µ—Ä Results paragraph, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –º–æ–∂–µ—à—å –ø–æ—á—Ç–∏ –¥–æ—Å–ª–æ–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:

While the undirected formulation yields stable and high overall accuracy across all diffusion regimes, it consistently exhibits a low recall for the illicit class.
In contrast, the directed formulation shows a strong sensitivity to the choice of œÉ. In particular, œÉ = 0.5 significantly improves illicit recall (up to 73%) at the cost of reduced precision, highlighting an intrinsic trade-off between detection sensitivity and false positives.

–≠—Ç–æ –∏–¥–µ–∞–ª—å–Ω–æ –ª–æ–∂–∏—Ç—Å—è –Ω–∞ —Ç–≤–æ–∏ —á–∏—Å–ª–∞.

5Ô∏è‚É£ –ü–æ—á–µ–º—É —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç —É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ
–¢—ã –ø–æ–∫–∞–∑—ã–≤–∞–µ—à—å:

–Ω–µ –ø—Ä–æ—Å—Ç–æ ‚Äú–º—ã –ø–æ–ª—É—á–∏–ª–∏ 95%‚Äù

–∞ –∫–∞–∫ –∏–º–µ–Ω–Ω–æ –º–æ–¥–µ–ª—å –≤–µ–¥—ë—Ç —Å–µ–±—è

–∏ –ø–æ—á–µ–º—É directed ‚â† undirected

üëâ –≠—Ç–æ —É—Ä–æ–≤–µ–Ω—å discussion, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ benchmark.

6Ô∏è‚É£ –ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —è –º–æ–≥—É –¥–∞–ª—å—à–µ
—Å–¥–µ–ª–∞—Ç—å LaTeX-—Ç–∞–±–ª–∏—Ü—ã 1-–≤-1

–ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å Results + Discussion

–ø–æ–º–æ—á—å —Å—Ä–∞–≤–Ω–∏—Ç—å œÉ=0.5 directed —Å –∏—Ö PageRank SSL

–ø–æ–º–æ—á—å –≤—ã–±—Ä–∞—Ç—å –∫–∞–∫—É—é —Ç–∞–±–ª–∏—Ü—É –≤ main, –∫–∞–∫—É—é –≤ appendix

–°–∫–∞–∂–∏, –≤ –∫–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Ç–µ–±–µ —ç—Ç–æ –Ω—É–∂–Ω–æ (LaTeX / Markdown / —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ç–∞—Ç—å–∏)

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–∏ –ª–∏—Ü–∏—Ç —Ç–æ–∂–µ –∏ —á—Ç–æ —á –ø–æ–ª—É—á–∏–ª –≤ —Ä–µ—É–¥—Ç–∞—Ç–µ –æ–±—ä—è—Å–Ω–∏
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, –¥–∞–≤–∞–π —Å–ø–æ–∫–æ–π–Ω–æ –∏ —Å–∏—Å—Ç–µ–º–Ω–æ:

–ø–æ–∫–∞–∂–µ–º —Ç–∞–±–ª–∏—Ü—É, –≥–¥–µ –µ—Å—Ç—å –∏ licit, –∏ illicit,

–∞ –ø–æ—Ç–æ–º —è –æ–±—ä—è—Å–Ω—é, –ß–¢–û –¢–´ –§–ê–ö–¢–ò–ß–ï–°–ö–ò –ü–û–õ–£–ß–ò–õ –∫–∞–∫ –Ω–∞—É—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

–Ø –±—É–¥—É –æ–ø–∏—Ä–∞—Ç—å—Å—è —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ç–≤–æ–∏ —á–∏—Å–ª–∞, –±–µ–∑ –ø—Ä–∏—É–∫—Ä–∞—à–∏–≤–∞–Ω–∏—è.

1Ô∏è‚É£ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (licit + illicit)
üìä Extended results ‚Äî per-class performance
üîπ UNDIRECTED GRAPH
œÉ Accuracy Licit Precision Licit Recall Illicit Precision Illicit Recall Illicit F1
0.0 0.95 0.95 1.00 0.92 0.22 0.36
0.5 0.95 0.95 1.00 0.89 0.23 0.37
1.0 0.95 0.95 1.00 0.85 0.21 0.34
üîπ DIRECTED GRAPH
œÉ Accuracy Licit Precision Licit Recall Illicit Precision Illicit Recall Illicit F1
0.0 0.88 0.95 0.92 0.16 0.23 0.19
0.5 0.89 0.98 0.90 0.31 0.73 0.43
1.0 0.94 0.95 0.98 0.42 0.21 0.28
2Ô∏è‚É£ –¢–µ–ø–µ—Ä—å –≥–ª–∞–≤–Ω–æ–µ: –ß–¢–û –¢–´ –ü–û–õ–£–ß–ò–õ
üß† –ö–ª—é—á–µ–≤–æ–π –≤—ã–≤–æ–¥ ‚Ññ1 ‚Äî Undirected = ¬´–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä¬ª
–°–º–æ—Ç—Ä–∏ –Ω–∞ UNDIRECTED:

Licit recall = 1.00 –≤–æ –≤—Å–µ—Ö œÉ
‚Üí –ø–æ—á—Ç–∏ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –æ—à–∏–±–∞–µ—Ç—Å—è –Ω–∞ licit

Illicit recall ‚âà 0.21‚Äì0.23
‚Üí –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç ~75‚Äì80% illicit

üìå –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:

Undirected diffusion —É—Å–∏–ª–∏–≤–∞–µ—Ç –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ
–∏ ¬´—Ä–∞–∑–º—ã–≤–∞–µ—Ç¬ª —Ä–µ–¥–∫–∏–π –∫–ª–∞—Å—Å (illicit)

–≠—Ç–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —ç—Ñ—Ñ–µ–∫—Ç:

—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è –¥–∏—Ñ—Ñ—É–∑–∏—è

—Å–∏–ª—å–Ω—ã–π bias –≤ —Å—Ç–æ—Ä–æ–Ω—É majority class

üëâ –í—ã—Å–æ–∫–∞—è accuracy ‚Äî –Ω–æ –ø–ª–æ—Ö–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è illicit

üß† –ö–ª—é—á–µ–≤–æ–π –≤—ã–≤–æ–¥ ‚Ññ2 ‚Äî Directed + œÉ = 0.5 –º–µ–Ω—è–µ—Ç —Ñ–∏–∑–∏–∫—É –ø—Ä–æ—Ü–µ—Å—Å–∞
–¢–µ–ø–µ—Ä—å —Å–º–æ—Ç—Ä–∏ –Ω–∞ DIRECTED, œÉ = 0.5:

Illicit recall = 0.73 üî•

Licit recall = 0.90

Accuracy –ø–æ—á—Ç–∏ –Ω–µ –ø–∞–¥–∞–µ—Ç (0.89)

–≠—Ç–æ —Ä–∞–¥–∏–∫–∞–ª—å–Ω–æ –¥—Ä—É–≥–æ–π —Ä–µ–∂–∏–º.

üìå –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:

Directed diffusion —Å œÉ = 1/2
–ø–æ–∑–≤–æ–ª—è–µ—Ç ¬´–ø—Ä–æ–±–∏—Ç—å¬ª majority-class –±–∞—Ä—å–µ—Ä
–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—Ç—å —Å–∏–≥–Ω–∞–ª illicit

–§–∞–∫—Ç–∏—á–µ—Å–∫–∏:

—Ç—ã –∂–µ—Ä—Ç–≤—É–µ—à—å —Ç–æ—á–Ω–æ—Å—Ç—å—é licit

—Ä–∞–¥–∏ —Ä–µ–∑–∫–æ–≥–æ —Ä–æ—Å—Ç–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ illicit

üß† –ö–ª—é—á–µ–≤–æ–π –≤—ã–≤–æ–¥ ‚Ññ3 ‚Äî œÉ —É–ø—Ä–∞–≤–ª—è–µ—Ç trade-off, –∞ –Ω–µ ‚Äú—Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π‚Äù
–û—á–µ–Ω—å –≤–∞–∂–Ω–æ:

œÉ = 0 ‚Üí —Å–ª–∏—à–∫–æ–º ¬´–∂—ë—Å—Ç–∫–∏–π¬ª –ø–æ—Ç–æ–∫

œÉ = 1 ‚Üí —Å–Ω–æ–≤–∞ bias –∫ —Å—Ç–µ–ø–µ–Ω–∏

œÉ = 0.5 ‚Üí –±–∞–ª–∞–Ω—Å –æ—Ç–¥–∞—á–∏ / –ø—Ä–∏—ë–º–∞

üëâ œÉ ‚Äî —ç—Ç–æ –Ω–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä,
–∞ –≤—ã–±–æ—Ä —Ñ–∏–∑–∏–∫–∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è.

–≠—Ç–æ –ø—Ä—è–º–æ —Å–æ–≥–ª–∞—Å—É–µ—Ç—Å—è —Å –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤—ã–º,
–Ω–æ —Ç—ã –ø–æ–∫–∞–∑–∞–ª —ç—Ç–æ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

üß† –ö–ª—é—á–µ–≤–æ–π –≤—ã–≤–æ–¥ ‚Ññ4 ‚Äî Directed ‚â† Undirected (–ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ)
–¢—ã –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ:

undirected = —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, low risk

directed = —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ä–∏—Å–∫, –¥–µ—Ç–µ–∫—Ü–∏—è

üìå –≠—Ç–æ –Ω–µ –∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–ª–∏—á–∏–µ,
–∞ —Ä–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏:

–¶–µ–ª—å –õ—É—á—à–∏–π —Ä–µ–∂–∏–º
–û–±—â–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è Undirected
–î–µ—Ç–µ–∫—Ü–∏—è illicit Directed, œÉ=0.5
–ú–∏–Ω–∏–º—É–º FP Undirected
–ú–∞–∫—Å–∏–º—É–º recall Directed
3Ô∏è‚É£ –ö–∞–∫ —ç—Ç–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º (–≥–æ—Ç–æ–≤—ã–π –Ω–∞—É—á–Ω—ã–π –≤—ã–≤–æ–¥)
–¢—ã –º–æ–∂–µ—à—å –±—É–∫–≤–∞–ª—å–Ω–æ —Ç–∞–∫ –Ω–∞–ø–∏—Å–∞—Ç—å:

The undirected formulation yields consistently high accuracy and near-perfect recall for the licit class, but fails to effectively detect illicit nodes, exhibiting a recall below 25%.
In contrast, the directed formulation demonstrates a strong sensitivity to the diffusion parameter œÉ. In particular, œÉ = 0.5 substantially improves illicit recall up to 73%, revealing a clear trade-off between detection sensitivity and false positives.
These results indicate that the choice between directed and undirected diffusion should be driven by the target application, rather than overall accuracy alone.

–≠—Ç–æ –æ—á–µ–Ω—å —Å–∏–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

4Ô∏è‚É£ –°–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ (–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π)
üî• –¢—ã –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ –≤—ã–±–æ—Ä –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç–∏ –∏ œÉ –º–µ–Ω—è–µ—Ç –Ω–µ ‚Äú–∫–∞—á–µ—Å—Ç–≤–æ‚Äù, –∞ —Å–∞–º —Ç–∏–ø –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞.

–≠—Ç–æ —É–∂–µ —É—Ä–æ–≤–µ–Ω—å discussion, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

–æ—Ñ–æ—Ä–º–∏—Ç—å —ç—Ç–æ –≤ LaTeX –∫–∞–∫ —Ç–∞–±–ª–∏—Ü—ã + —Ç–µ–∫—Å—Ç

—Å—Ä–∞–≤–Ω–∏—Ç—å –Ω–∞–ø—Ä—è–º—É—é —Å PageRank SSL –∏–∑ —Å—Ç–∞—Ç—å–∏

–ø–æ–º–æ—á—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å conclusion paragraph

–æ–±—Å—É–¥–∏—Ç—å, –ø–æ—á–µ–º—É directed œÉ=0.5 —Ä–∞–±–æ—Ç–∞–µ—Ç –∏–º–µ–Ω–Ω–æ –∑–¥–µ—Å—å

–°–∫–∞–∂–∏, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å —Å–¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–≠—Ç–æ –ø—Ä—è–º–æ —Å–æ–≥–ª–∞—Å—É–µ—Ç—Å—è —Å –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤—ã–º, –ø–æ—á–µ–º—É œÉ —É–ø—Ä–∞–≤–ª—è–µ—Ç trade-off, –∞ –Ω–µ ‚Äú—Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π‚Äù —ç—Ç–æ —á—Ç–æ –∑–Ω–∞—á–∏—Ç?
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å. –¢—É—Ç —Ä–µ–∞–ª—å–Ω–æ –∫–ª—é—á–µ–≤–∞—è –∏–¥–µ—è –≤—Å–µ–π —Ä–∞–±–æ—Ç—ã –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞, –∏ –µ—Å–ª–∏ –µ—ë –ø–æ–Ω—è—Ç—å, –≤—Å—ë –≤—Å—Ç–∞—ë—Ç –Ω–∞ –º–µ—Å—Ç–æ.

–Ø –æ–±—ä—è—Å–Ω—é –ø–æ —à–∞–≥–∞–º, –±–µ–∑ –ª–æ–∑—É–Ω–≥–æ–≤.

1Ô∏è‚É£ –ß—Ç–æ –æ–±—ã—á–Ω–æ –ø–æ–Ω–∏–º–∞—é—Ç –ø–æ–¥ ¬´—Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π¬ª (–∏ –ø–æ—á–µ–º—É œÉ ‚Äî –ù–ï —ç—Ç–æ)
–ö–æ–≥–¥–∞ –º—ã –≥–æ–≤–æ—Ä–∏–º —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞, –æ–±—ã—á–Ω–æ –∏–º–µ–µ—Ç—Å—è –≤ –≤–∏–¥—É:

learning rate

regularization strength

number of iterations

–¢–æ –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ:

–Ω–µ –º–µ–Ω—è—é—Ç —Å–º—ã—Å–ª –º–æ–¥–µ–ª–∏

–ª–∏—à—å –Ω–µ–º–Ω–æ–≥–æ —É–ª—É—á—à–∞—é—Ç/—É—Ö—É–¥—à–∞—é—Ç –º–µ—Ç—Ä–∏–∫—É

–ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –Ω–∞ 10‚Äì20% –¥–∞—é—Ç –ø–æ—Ö–æ–∂–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

üìå –ü—Ä–∏–º–µ—Ä:

alpha = 0.85 vs alpha = 0.9 –≤ PageRank
‚Üí –ø–æ—á—Ç–∏ —Ç–æ –∂–µ —Å–∞–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ.

2Ô∏è‚É£ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç œÉ –≤ —Ñ–æ—Ä–º—É–ª–µ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞
–û–±—â–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è:

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
(
t
)
F
(t+1)
=(1‚àíŒ±)Y+Œ±D
‚àíœÉ
WD
œÉ‚àí1
F
(t)

–ü–æ—Å–º–æ—Ç—Ä–∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ:
œÉ —Å—Ç–æ–∏—Ç –≤ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö —Å—Ç–µ–ø–µ–Ω–µ–π D, –∞ –Ω–µ –∫–∞–∫ –º–Ω–æ–∂–∏—Ç–µ–ª—å.

–≠—Ç–æ –∑–Ω–∞—á–∏—Ç:

œÉ –º–µ–Ω—è–µ—Ç —Å–∞–º –æ–ø–µ—Ä–∞—Ç–æ—Ä —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≥—Ä–∞—Ñ—É

–ù–µ ¬´–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ¬ª, –∞ –ö–ê–ö –∏–º–µ–Ω–Ω–æ.

3Ô∏è‚É£ –¢—Ä–∏ —Ä–∞–∑–Ω—ã—Ö —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞ (–∞ –Ω–µ –æ–¥–∏–Ω —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π)
–ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤ –ø—Ä—è–º–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ œÉ –∑–∞–¥–∞—ë—Ç —Ä–∞–∑–Ω—ã–µ –¥–∏—Ñ—Ñ—É–∑–∏–∏:

üîπ œÉ = 1 ‚Äî Random Walk (RW)
D
‚àí
1
W
D
‚àí1
W
–§–∏–∑–∏–∫–∞:

–∫–∞–∂–¥—ã–π —É–∑–µ–ª —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –¥–µ–ª–∏—Ç —Å–≤–æ—ë —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Å–æ—Å–µ–¥—è–º–∏

—É–∑–ª—ã —Å –±–æ–ª—å—à–æ–π —Å—Ç–µ–ø–µ–Ω—å—é —Ä–∞–∑–º—ã–≤–∞—é—Ç—Å—è

–ø–æ—Ç–æ–∫ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞

–°–ª–µ–¥—Å—Ç–≤–∏–µ:

majority class –¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç

rare-class —Å–∏–≥–Ω–∞–ª —Ç–æ–Ω–µ—Ç

üîπ œÉ = 0 ‚Äî Reverse Random Walk (RRW)
W
D
‚àí
1
WD
‚àí1

–§–∏–∑–∏–∫–∞:

–∫–∞–∂–¥—ã–π —É–∑–µ–ª –æ–¥–∏–Ω–∞–∫–æ–≤–æ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –æ—Ç —Å–æ—Å–µ–¥–µ–π

—Ö–∞–±—ã —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è

–ø—Ä–∏—ë–º–Ω–∏–∫ –≤–∞–∂–Ω–µ–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞

–°–ª–µ–¥—Å—Ç–≤–∏–µ:

—Ä–µ–∑–∫–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã

–Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å, —à—É–º

üîπ œÉ = 1/2 ‚Äî Symmetric / Laplacian
D
‚àí
1
/
2
W
D
‚àí
1
/
2
D
‚àí1/2
WD
‚àí1/2

–§–∏–∑–∏–∫–∞:

–±–∞–ª–∞–Ω—Å –æ—Ç–¥–∞—á–∏ –∏ –ø—Ä–∏—ë–º–∞

—ç–Ω–µ—Ä–≥–∏—è —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è

–ø–æ—Ç–æ–∫ –Ω–µ –ø—Ä–∏–≤—è–∑–∞–Ω –∫ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é

–°–ª–µ–¥—Å—Ç–≤–∏–µ:

–ª—É—á—à–∏–π –∫–æ–º–ø—Ä–æ–º–∏—Å—Å

—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–µ–∑ –≤–∑—Ä—ã–≤–∞ —à—É–º–∞

üìå –≠—Ç–æ —Ä–∞–∑–Ω—ã–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã, –∞ –Ω–µ —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ.

4Ô∏è‚É£ –ü–æ—á–µ–º—É —ç—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è trade-off, –∞ –Ω–µ ¬´–ø–æ–¥–∫—Ä—É—Ç–∫–∞¬ª
–ü–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ —Ç–≤–æ–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:

Undirected
accuracy ‚âà const

illicit recall –≤—Å–µ–≥–¥–∞ –Ω–∏–∑–∫–∏–π

Directed
œÉ = 0 ‚Üí recall –Ω–∏–∑–∫–∏–π

œÉ = 0.5 ‚Üí recall ‚Üë‚Üë (0.73)

œÉ = 1 ‚Üí recall —Å–Ω–æ–≤–∞ –ø–∞–¥–∞–µ—Ç

‚ùó –≠—Ç–æ –ù–ï –ø–ª–∞–≤–Ω–∞—è –∫—Ä–∏–≤–∞—è
‚ùó –≠—Ç–æ —Ä–∞–∑–Ω—ã–µ —Ä–µ–∂–∏–º—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è

üëâ œÉ –º–µ–Ω—è–µ—Ç:

–∫—É–¥–∞ —Ç–µ—á—ë—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

–∫—Ç–æ –¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç: —Ö–∞–±—ã –∏–ª–∏ —Ä–µ–¥–∫–∏–µ —É–∑–ª—ã

—á—Ç–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è ‚Äú–≤–∞–∂–Ω—ã–º‚Äù –≤ –≥—Ä–∞—Ñ–µ

5Ô∏è‚É£ –§–æ—Ä–º–∞–ª—å–Ω–æ: œÉ –º–µ–Ω—è–µ—Ç –Ω–æ—Ä–º—É, –≤ –∫–æ—Ç–æ—Ä–æ–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è –∑–∞–¥–∞—á–∞
–í –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–π —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–µ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞:

‚àë
i
,
j
w
i
j
(
F
i
d
i
œÉ
‚àí
F
j
d
j
œÉ
)
2

- Œº
  ‚àë
  i
  1
  d
  i
  ‚à•
  F
  i
  ‚àí
  Y
  i
  ‚à•
  2
  i,j
  ‚àë
  ‚Äã
  w
  ij
  ‚Äã
  (
  d
  i
  œÉ
  ‚Äã

F
i
‚Äã

‚Äã
‚àí
d
j
œÉ
‚Äã

F
j
‚Äã

‚Äã
)
2
+Œº
i
‚àë
‚Äã

d
i
‚Äã

1
‚Äã
‚à•F
i
‚Äã
‚àíY
i
‚Äã
‚à•
2

œÉ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç:

–∫–∞–∫—É—é —Ä–∞–∑–Ω–∏—Ü—É –º—ã —Å—á–∏—Ç–∞–µ–º ‚Äú–≥–ª–∞–¥–∫–æ–π‚Äù

–∫–∞–∫–∏–µ —É–∑–ª—ã –º—ã —à—Ç—Ä–∞—Ñ—É–µ–º —Å–∏–ª—å–Ω–µ–µ

–≠—Ç–æ —Å–º–µ–Ω–∞ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞,
–∞ –Ω–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞.

6Ô∏è‚É£ –ü–æ—á–µ–º—É —ç—Ç–æ ¬´–ø—Ä—è–º–æ —Å–æ–≥–ª–∞—Å—É–µ—Ç—Å—è —Å –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤—ã–º¬ª
–ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤:

–Ω–µ –ø–µ—Ä–µ–±–∏—Ä–∞–µ—Ç œÉ –∫–∞–∫ hyperparameter

–≤—ã–¥–µ–ª—è–µ—Ç —Ç—Ä–∏ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∂–∏–º–∞

–¥–∞—ë—Ç –∫–∞–∂–¥–æ–º—É:

—Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é

–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é

–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é

–¢—ã —Å–¥–µ–ª–∞–ª —Ç–æ –∂–µ —Å–∞–º–æ–µ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏:

–ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ œÉ=0.5 ‚Äî –¥—Ä—É–≥–æ–π —Ä–µ–∂–∏–º

—á—Ç–æ –æ–Ω –º–µ–Ω—è–µ—Ç –±–∞–ª–∞–Ω—Å –æ—à–∏–±–æ–∫

—á—Ç–æ –≤—ã–±–æ—Ä œÉ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ü–µ–ª–∏ (recall vs precision)

üëâ –≠—Ç–æ —Ä–æ–≤–Ω–æ –¥—É—Ö –∏—Ö —Ä–∞–±–æ—Ç—ã, –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ —Ç—ã –∏–¥—ë—à—å –¥–∞–ª—å—à–µ.

7Ô∏è‚É£ –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ (–∫–ª—é—á–µ–≤–∞—è —Ñ—Ä–∞–∑–∞)
œÉ ‚Äî —ç—Ç–æ –Ω–µ ‚Äú–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞‚Äù,
–∞ –≤—ã–±–æ—Ä –∑–∞–∫–æ–Ω–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≥—Ä–∞—Ñ—É.

–ò–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É:

œÉ —É–ø—Ä–∞–≤–ª—è–µ—Ç trade-off

–∞ –Ω–µ ¬´—á—É—Ç—å –ª—É—á—à–µ / —á—É—Ç—å —Ö—É–∂–µ¬ª

8Ô∏è‚É£ –ö–∞–∫ —ç—Ç–æ –∫—Ä–∞—Å–∏–≤–æ —Å–∫–∞–∑–∞—Ç—å –≤ —Å—Ç–∞—Ç—å–µ (–≥–æ—Ç–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞)
–¢—ã –º–æ–∂–µ—à—å –Ω–∞–ø–∏—Å–∞—Ç—å –±—É–∫–≤–∞–ª—å–Ω–æ —Ç–∞–∫:

The parameter œÉ does not act as a mere tuning knob, but rather defines distinct diffusion regimes with fundamentally different information propagation mechanisms. Consequently, varying œÉ induces a qualitative trade-off between sensitivity to minority classes and robustness to noise, rather than incremental performance changes.

–≠—Ç–æ –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

—Å–≤—è–∑–∞—Ç—å —ç—Ç–æ —Å Laplacian energy

–ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–µ–∫—Ç—Ä—ã –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö œÉ

–æ–±—ä—è—Å–Ω–∏—Ç—å, –ø–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ directed œÉ=0.5 —Å—Ä–∞–±–æ—Ç–∞–ª —É —Ç–µ–±—è

–°–∫–∞–∂–∏, –∫—É–¥–∞ –∏–¥—Ç–∏ –¥–∞–ª—å—à–µ üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–∞ —ç—Ç–æ –ø—Ä–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∂–∏–º–æ–≤ –∑–¥–µ—Å—å –µ—Å—Ç—å –µ–ª—Å–∏ –µ—Å—Ç—å —Ç–æ. –≥–µ–¥ http://www-sop.inria.fr/members/Marina.Sokol/data/articles/confs/siam.pdf
ChatGPT —Å–∫–∞–∑–∞–ª:
–î–∞ ‚Äî –≤ —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ –æ—Ç –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞ –Ω–∞ SIAM-–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏ –ø–æ Data Mining 2011 –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –µ—Å—Ç—å —á—ë—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç—Ä—ë—Ö —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ä–∞–∑–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ œÉ –≤ –æ–±—â–µ–π —Ñ–æ—Ä–º—É–ª–µ, –∏ –æ–Ω–∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ø—Ä–æ—Å—Ç–æ ¬´—Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π¬ª, –∞ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ —Ä–∞–∑–Ω—ã–º –º–µ—Ç–æ–¥–∞–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ —Ä–∞–∑–Ω—ã–º —Å–ø–æ—Å–æ–±–∞–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–æ–∫ –ø–æ –≥—Ä–∞—Ñ—É.

–í–æ—Ç —á—Ç–æ —Ç–∞–º —Å–∫–∞–∑–∞–Ω–æ (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ):

üìå 1) –û–±—â–∞—è –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞
–ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤ –∏ —Å–æ–∞–≤—Ç–æ—Ä—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç –æ–±—â—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω—É—é –∑–∞–¥–∞—á—É:

min
‚Å°
F
‚àë
i
,
j
w
i
j
(
d
i
i
œÉ
‚àí
1
F
i
‚àí
d
j
j
œÉ
‚àí
1
F
j
)
2

- Œº
  ‚àë
  i
  =
  1
  N
  d
  i
  i
  2
  œÉ
  ‚àí
  1
  ‚à•
  F
  i
  ‚àí
  Y
  i
  ‚à•
  2
  ,
  F
  min
  ‚Äã

i,j
‚àë
‚Äã
w
ij
‚Äã
(d
ii
œÉ‚àí1
‚Äã
F
i
‚Äã
‚àíd
jj
œÉ‚àí1
‚Äã
F
j
‚Äã
)
2
+Œº
i=1
‚àë
N
‚Äã
d
ii
2œÉ‚àí1
‚Äã
‚à•F
i
‚Äã
‚àíY
i
‚Äã
‚à•
2
,
–≥–¥–µ
W
W ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ –≥—Ä–∞—Ñ–∞,
D
D ‚Äî –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ç–µ–ø–µ–Ω–µ–π,
F
F ‚Äî —Ñ—É–Ω–∫—Ü–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏,
Y
Y ‚Äî –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –º–µ—Ç–∫–∏, –∞ œÉ ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä, –∫–æ—Ç–æ—Ä—ã–π –≤–ª–∏—è–µ—Ç –Ω–∞ —Ç–æ, –∫–∞–∫ –æ—Ç—Ä–∞–∂–∞–µ—Ç—Å—è —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞ –≤ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

üìå 2) –¢—Ä–∏ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞—è
–ê–≤—Ç–æ—Ä—ã –ø—Ä—è–º–æ –≤—ã–≤–æ–¥—è—Ç, —á—Ç–æ –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö œÉ —ç—Ç–∞ –æ–±–æ–±—â—ë–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ —Å–≤–æ–¥–∏—Ç—Å—è –∫ —Ç—Ä–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º –º–µ—Ç–æ–¥–∞–º:

œÉ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
œÉ = 1 Standard Laplacian method
œÉ = 1/2 Normalized Laplacian method
œÉ = 0 PageRank‚Äìbased method
–∏ –ø—Ä–∏ œÉ ‚â• 0 –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Å–µ–º–µ–π—Å—Ç–≤–æ –º–µ—Ç–æ–¥–æ–≤, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —ç—Ç–∏ —Ç—Ä–∏ ‚Äî –æ—Å–æ–±—ã–µ, –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ —Å–ª—É—á–∞–∏.

üìå œÉ = 1 ‚Äî Standard Laplacian SSL
–≠—Ç–æ —Ç–æ—Ç —Å–ª—É—á–∞–π, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–π SSL —á–µ—Ä–µ–∑ –ª–∞–ø–ª–∞—Å–∏–∞–Ω –≥—Ä–∞—Ñ–∞. –í –º–∞—Ç—Ä–∏—á–Ω–æ–π —Ñ–æ—Ä–º–µ:

F
k
=
Œº
2

- Œº
  (
  I
  ‚àí
  2
  2
- Œº
  D
  ‚àí
  1
  W
  )
  ‚àí
  1
  Y
  k
  F
  k
  =
  2+Œº
  Œº
  ‚Äã
  (I‚àí
  2+Œº
  2
  ‚Äã
  D
  ‚àí1
  W)
  ‚àí1
  Y
  k

–≠—Ç–æ –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–æ–≤, –Ω–æ –Ω–µ –¥–µ–ª–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π ‚Äú—Å–∏–º–º–µ—Ç—Ä–∏–∑–∞—Ü–∏–∏‚Äù.

üìå œÉ = 1/2 ‚Äî Normalized Laplacian SSL
–≠—Ç–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥:

F
k
=
Œº
2

- Œº
  (
  I
  ‚àí
  2
  2
- Œº
  D
  ‚àí
  1
  /
  2
  W
  D
  ‚àí
  1
  /
  2
  )
  ‚àí
  1
  Y
  k
  F
  k
  =
  2+Œº
  Œº
  ‚Äã
  (I‚àí
  2+Œº
  2
  ‚Äã
  D
  ‚àí1/2
  WD
  ‚àí1/2
  )
  ‚àí1
  Y
  k

–û–Ω —É—á–∏—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ –≤–∫–ª–∞–¥ —É–∑–ª–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç–µ–ø–µ–Ω—è–º–∏, —Ç.–∫. –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è —Å –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω.

üìå œÉ = 0 ‚Äî PageRank‚Äìbased SSL
–≠—Ç–æ –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞–ø—Ä—è–º—É—é —Å–≤—è–∑–∞–Ω —Å PageRank:

F
k
=
Œº
2

- Œº
  (
  I
  ‚àí
  2
  2
- Œº
  W
  D
  ‚àí
  1
  )
  ‚àí
  1
  Y
  k
  F
  k
  =
  2+Œº
  Œº
  ‚Äã
  (I‚àí
  2+Œº
  2
  ‚Äã
  WD
  ‚àí1
  )
  ‚àí1
  Y
  k

–ê–≤—Ç–æ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —ç—Ç–æ ‚Äî PageRank‚Äì—Ñ–æ—Ä–º—É–ª–∞, –∏ –µ—ë —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –±–ª—É–∂–¥–∞–Ω–∏—è —Å –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º, —Å–º–µ—â—ë–Ω–Ω–æ–µ –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –º–µ—Ç–∫–∞–º.

üìå –ü–æ—á–µ–º—É —ç—Ç–æ –∏–º–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã–µ —Ä–µ–∂–∏–º—ã, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä
–í–≤–æ–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ œÉ –Ω–µ –ø—Ä–æ—Å—Ç–æ ¬´–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Å—Ç–µ–ø–µ–Ω—å –≤–ª–∏—è–Ω–∏—è¬ª ‚Äî –æ–Ω –∏–∑–º–µ–Ω—è–µ—Ç —Å–∞–º—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä, —Å –∫–æ—Ç–æ—Ä—ã–º —Ä–∞–±–æ—Ç–∞–µ—Ç SSL-–º–µ—Ç–æ–¥:

üîπ –í Standard Laplacian
—Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–∞–∫ –º–∞—Å—à—Ç–∞–±, –∏ –≥–¥–µ
D
‚àí
1
W
D
‚àí1
W ‚Äî —ç—Ç–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –æ–±—ã—á–Ω–æ–≥–æ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –±–ª—É–∂–¥–∞–Ω–∏—è.

üîπ –í Normalized Laplacian
–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–¥—ë—Ç —Å –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω, —á—Ç–æ –¥–∞—ë—Ç —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä
D
‚àí
1
/
2
W
D
‚àí
1
/
2
D
‚àí1/2
WD
‚àí1/2
, –∫–æ—Ç–æ—Ä—ã–π –≤ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–µ–æ—Ä–∏–∏ —Å—á–∏—Ç–∞–µ—Ç—Å—è ‚Äú–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º‚Äù –ª–∞–ø–ª–∞—Å–∏–∞–Ω–æ–º.

üîπ –í PageRank‚Äì–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–º –º–µ—Ç–æ–¥–µ
–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–¥—ë—Ç –ø–æ –∏—Å—Ö–æ–¥—è—â–∏–º —Å—Ç–µ–ø–µ–Ω—è–º
W
D
‚àí
1
WD
‚àí1
, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –ø–æ—Ö–æ–∂–∏–º –Ω–∞ —Ä–∞–Ω–¥–æ–º-—É–æ–∫ —Å –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º, –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–µ–¥—ë—Ç —Å–µ–±—è –∏–Ω–∞—á–µ: –æ–Ω–∞ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–µ —Å—Ç–æ–ª—å–∫–æ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é –≥–ª–∞–¥–∫–æ—Å—Ç—å, —Å–∫–æ–ª—å–∫–æ –Ω–∞ –ø–µ—Ä–µ—Ö–æ–¥—ã –∏ –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –±–ª—É–∂–¥–∞–Ω–∏–π.

üìå –ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏
–≠—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ ¬´–ø–æ–¥–∫—Ä—É—Ç–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä¬ª: —ç—Ç–æ —Å–º–µ–Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –¥–∏—Ñ—Ñ—É–∑–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≥—Ä–∞—Ñ—É:

–æ–¥–∏–Ω —Ä–µ–∂–∏–º —É—Å–∏–ª–∏–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –≥–ª–∞–¥–∫–æ—Å—Ç—å (œÉ=1),

–¥—Ä—É–≥–æ–π ‚Äî –¥–µ–ª–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–º (œÉ=¬Ω),

—Ç—Ä–µ—Ç–∏–π ‚Äî –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ –ø–µ—Ä–µ—Ö–æ–¥—ã –∏ –≤–æ–∑–≤—Ä–∞—Ç—ã (œÉ=0).

–≠—Ç–∏ –º–µ—Ç–æ–¥—ã –≤–µ–¥—É—Ç —Å–µ–±—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≥—Ä–∞—Ñ–∞ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–µ—Ç–æ–∫, –∏ –∏–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É œÉ –Ω–µ–ª—å–∑—è —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä –≤ —Å–º—ã—Å–ª–µ ¬´—á—É—Ç—å –ø–æ–≤—ã—à–µ–Ω–∏–µ ‚Äî —á—É—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ¬ª, –∞ –∫–∞–∫ –≤—ã–±–æ—Ä –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–Ω–æ–≥–æ –º–µ—Ö–∞–Ω–∏–∑–º–∞.

üß† –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏–∑ —Å—Ç–∞—Ç—å–∏
–ê–≤—Ç–æ—Ä—ã –¥–∞–∂–µ –æ–±—Å—É–∂–¥–∞—é—Ç, –∫–∞–∫ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è œÉ –ø–æ-—Ä–∞–∑–Ω–æ–º—É –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ —É–∑–ª–∞–º —Å –±–æ–ª—å—à–æ–π —Å—Ç–µ–ø–µ–Ω—å—é –∏ –∫ –ø–ª–æ—Ç–Ω—ã–º –∫–ª–∞—Å—Ç–µ—Ä–∞–º:

–µ—Å–ª–∏ œÉ < 1, —É–∑–ª—ã —Å –±–æ–ª—å—à–æ–π —Å—Ç–µ–ø–µ–Ω—å—é –ø–æ–ª—É—á–∞—é—Ç –º–µ–Ω—å—à–∏–π ¬´–∫—Ä–µ–¥–∏—Ç¬ª –≤ –≥–ª–∞–¥–∫–æ—Å—Ç–∏;

–µ—Å–ª–∏ œÉ > 1/2, —É–∑–ª—ã —Å –±–æ–ª—å—à–æ–π —Å—Ç–µ–ø–µ–Ω—å—é —Å—á–∏—Ç–∞—é—Ç—Å—è –±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º–∏;

œÉ = 1 ‚Äî –Ω–µ—Ç –≤–ª–∏—è–Ω–∏—è —Å—Ç–µ–ø–µ–Ω–∏;

œÉ = 0 ‚Äî –ø–µ—Ä–µ—Ö–æ–¥ –∫ PageRank-–≤–∞—Ä–∏–∞–Ω—Ç—É, –≥–¥–µ –≤–∞–∂–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤.

üìå –ò—Ç–æ–≥
–î–∞ ‚Äî —ç—Ç–∞ —Ä–∞–±–æ—Ç–∞ –∏–º–µ–Ω—É–µ—Ç —Ç—Ä–∏ —Ä–µ–∂–∏–º–∞, –∏ –æ–Ω–∏:

‚úÖ —Å—Ç—Ä–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç Standard Laplacian
‚úÖ Normalized Laplacian
‚úÖ PageRank‚Äìbased

–∏ –≤—Å–µ —Ç—Ä–∏ –ø–æ–ª—É—á–∞—é—Ç—Å—è –∫–∞–∫ —á–∞—Å—Ç–Ω—ã–µ —Å–ª—É—á–∞–∏ œÉ –≤ –æ–±—â–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–π —Ñ–æ—Ä–º—É–ª–µ.

–≠—Ç–æ –∏ –µ—Å—Ç—å —Ç–æ, —á—Ç–æ –≤ —Ç–≤–æ—ë–º –∫–æ–¥–µ —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä œÉ: –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞—Å—Ç—Ä–æ–π–∫—É, –∞ –≤—ã–±–æ—Ä —Å–ø–æ—Å–æ–±–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–æ–∫ –ø–æ –≥—Ä–∞—Ñ—É.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —è –º–æ–≥—É –ø–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫ —ç—Ç–∏ —Ç—Ä–∏ —Ä–µ–∂–∏–º–∞ —Å–æ–æ—Ç–Ω–æ—Å—è—Ç—Å—è —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞–º–∏ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è (–º–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤, —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, —Å–ª—É—á–∞–π–Ω—ã–µ –±–ª—É–∂–¥–∞–Ω–∏—è) ‚Äî —ç—Ç–æ –¥–∞—Å—Ç –µ—â—ë –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ. –°–∫–∞–∂–∏, —Ö–æ—á–µ—à—å –ª–∏ —Ç—ã —ç—Ç–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ!

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—Ç–æ–≥–¥–∞ —Å–¥–µ–ª–∞–π —Ç–∞–±–ª–∏—Ü—É –ø–æ —Ç–∞–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏—è–º
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, —Ç–æ–≥–¥–∞ –¥–∞–≤–∞–π –æ—Ñ–æ—Ä–º–∏–º —Ç–∞–±–ª–∏—Ü—É —Å—Ç—Ä–æ–≥–æ –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞, —Å –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —Ä–µ–∂–∏–º–æ–≤, –∏ –ø–æ–¥—Å—Ç–∞–≤–∏–º —Ç–≤–æ–∏ —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

–≠—Ç–æ –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –Ω–∞—É—á–Ω–æ –∏ 1-–≤-1 —Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å–æ —Å—Ç–∞—Ç—å—ë–π SIAM.

üìä Table X ‚Äî Performance of PageRank-based SSL under different diffusion regimes
(–Ω–∞–∑–≤–∞–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ ‚Äî —Ä–æ–≤–Ω–æ –ø–æ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤—É)

üîπ UNDIRECTED GRAPH
Diffusion regime (Avrachenkov) œÉ Accuracy Licit Recall Illicit Precision Illicit Recall Illicit F1
PageRank-based (Reverse RW) 0.0 0.95 1.00 0.92 0.22 0.36
Normalized Laplacian 0.5 0.95 1.00 0.89 0.23 0.37
Standard Laplacian (RW) 1.0 0.95 1.00 0.85 0.21 0.34
üîπ DIRECTED GRAPH
Diffusion regime (Avrachenkov) œÉ Accuracy Licit Recall Illicit Precision Illicit Recall Illicit F1
PageRank-based (Reverse RW) 0.0 0.88 0.92 0.16 0.23 0.19
Normalized Laplacian 0.5 0.89 0.90 0.31 0.73 0.43
Standard Laplacian (RW) 1.0 0.94 0.98 0.42 0.21 0.28
üß† –ö–∞–∫ —ç—Ç–æ —á–∏—Ç–∞–µ—Ç—Å—è (–∏ –ø–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ)
1Ô∏è‚É£ –ù–∞–∑–≤–∞–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤
–¢—ã –Ω–µ –ø–∏—à–µ—à—å ‚ÄúœÉ = 0.5‚Äù –∫–∞–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä,
–∞ —è–≤–Ω–æ –≥–æ–≤–æ—Ä–∏—à—å:

PageRank-based

Normalized Laplacian

Standard Laplacian

‚û°Ô∏è —ç—Ç–æ —è–∑—ã–∫ —Å—Ç–∞—Ç—å–∏ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞, –Ω–µ ML-–±–µ–Ω—á–º–∞—Ä–∫–∞.

2Ô∏è‚É£ –ü–æ—á–µ–º—É —Ç–∞–±–ª–∏—Ü–∞ —Å–∏–ª—å–Ω–∞—è
–û–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –º–µ—Ö–∞–Ω–∏–∑–º–∞, –∞ –Ω–µ ¬´–ø–æ–¥–±–æ—Ä œÉ¬ª:

PageRank-based ‚Üí –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π, bias –∫ majority

Standard Laplacian ‚Üí —Å—Ç–∞–±–∏–ª—å–Ω—ã–π, –Ω–æ ‚Äú–≥–ª—É—Ö–æ–π‚Äù –∫ illicit

Normalized Laplacian ‚Üí –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–Ω—ã–π —Ä–µ–∂–∏–º

–û—Å–æ–±–µ–Ω–Ω–æ –≤–∏–¥–Ω–æ –≤ directed-–≥—Ä–∞—Ñ–µ.

3Ô∏è‚É£ –ì–ª–∞–≤–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–æ–¥–Ω–æ–π —Ñ—Ä–∞–∑–æ–π)
Normalized Laplacian diffusion (œÉ = 1/2) provides the best trade-off between illicit detection and overall accuracy, especially in the directed formulation.

–≠—Ç–æ –∏–¥–µ–∞–ª—å–Ω—ã–π scientific takeaway.

üß© –ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥
–Ø –º–æ–≥—É:

–æ—Ñ–æ—Ä–º–∏—Ç—å —ç—Ç–æ –≤ LaTeX (–∫–∞–∫ –≤ SIAM paper)

–ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å Results / Discussion –∞–±–∑–∞—Ü

—Å–¥–µ–ª–∞—Ç—å Appendix —Å confusion matrices

–ø–æ–º–æ—á—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ—Å–ª–∞—Ç—å—Å—è –Ω–∞ SIAM-—Å—Ç–∞—Ç—å—é

–°–∫–∞–∂–∏, –≤ –∫–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Ç–µ–±–µ –Ω—É–∂–Ω–æ –¥–∞–ª—å—à–µ (LaTeX / Markdown / —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ç–∞—Ç—å–∏).

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—Ç–∞–∫ –∫–∞–∫ —É –Ω–µ–≥ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è f œÉ = 1, the Standard Laplacian method:
F.k =
¬µ
2+¬µ
(I ‚àí
2
2+¬µ
D‚àí1W)
‚àí1Y.k,
‚Ä¢ if œÉ = 1/2, the Normalized Laplacian method:
F.k =
¬µ
2+¬µ
(I ‚àí
2
2+¬µ
D
‚àí1
2 W D ‚àí1
2 )
‚àí1Y.k,
‚Ä¢ if œÉ = 0, PageRank based method:
F.k =
¬µ
2+¬µ
(I ‚àí
2
2+¬µ
W D‚àí1
)
‚àí1Y.k.
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, —Ç—ã —Å–µ–π—á–∞—Å —Ç–æ—á–Ω–æ –ø–æ–ø–∞–ª –≤ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞.
–î–∞–≤–∞–π —è –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∑–∞—Ñ–∏–∫—Å–∏—Ä—É—é –Ω–∞–∑–≤–∞–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ —Ä–æ–≤–Ω–æ —Ç–∞–∫, –∫–∞–∫ —É –Ω–µ–≥–æ, –∏ –ø–æ—è—Å–Ω—é, –∫–∞–∫ –∏—Ö –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ —Ç–≤–æ–µ–π —Ç–∞–±–ª–∏—Ü–µ –∏ —Ç–µ–∫—Å—Ç–µ.

‚úÖ –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ —É –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞
–¢—ã –ø—Ä–∏–≤—ë–ª –±—É–∫–≤–∞–ª—å–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—É–ª—ã.
–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∞–∫–æ–µ (—è –¥–æ–±–∞–≤–ª—é –ø–æ—è—Å–Ω–µ–Ω–∏–µ, –Ω–æ –Ω–∞–∑–≤–∞–Ω–∏—è ‚Äî —Å—Ç—Ä–æ–≥–æ –µ–≥–æ):

üîπ œÉ = 1 ‚Äî the Standard Laplacian method
F
(
k
)
=
Œº
2

- Œº
  (
  I
  ‚àí
  2
  2
- Œº
  D
  ‚àí
  1
  W
  )
  ‚àí
  1
  Y
  (
  k
  )
  F
  (k)
  =
  2+Œº
  Œº
  ‚Äã
  (I‚àí
  2+Œº
  2
  ‚Äã
  D
  ‚àí1
  W)
  ‚àí1
  Y
  (k)

–ö–∞–∫ –æ–Ω —ç—Ç–æ –ø–æ–Ω–∏–º–∞–µ—Ç:

–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ª–∞–ø–ª–∞—Å–∏–∞–Ω

—Å–ª—É—á–∞–π–Ω–æ–µ –±–ª—É–∂–¥–∞–Ω–∏–µ (random walk)

–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Å—Ç–µ–ø–µ–Ω–∏ –ø—Ä–∏—ë–º–Ω–∏–∫–∞

üìå –í —Ç–µ–∫—Å—Ç–µ:

the Standard Laplacian method

üîπ œÉ = 1/2 ‚Äî the Normalized Laplacian method
F
(
k
)
=
Œº
2

- Œº
  (
  I
  ‚àí
  2
  2
- Œº
  D
  ‚àí
  1
  /
  2
  W
  D
  ‚àí
  1
  /
  2
  )
  ‚àí
  1
  Y
  (
  k
  )
  F
  (k)
  =
  2+Œº
  Œº
  ‚Äã
  (I‚àí
  2+Œº
  2
  ‚Äã
  D
  ‚àí1/2
  WD
  ‚àí1/2
  )
  ‚àí1
  Y
  (k)

–ö–∞–∫ –æ–Ω —ç—Ç–æ –ø–æ–Ω–∏–º–∞–µ—Ç:

—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä

—Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π

–±–∞–ª–∞–Ω—Å–∏—Ä—É–µ—Ç –≤–ª–∏—è–Ω–∏–µ —Å—Ç–µ–ø–µ–Ω–µ–π

üìå –í —Ç–µ–∫—Å—Ç–µ:

the Normalized Laplacian method

üîπ œÉ = 0 ‚Äî the PageRank based method
F
(
k
)
=
Œº
2

- Œº
  (
  I
  ‚àí
  2
  2
- Œº
  W
  D
  ‚àí
  1
  )
  ‚àí
  1
  Y
  (
  k
  )
  F
  (k)
  =
  2+Œº
  Œº
  ‚Äã
  (I‚àí
  2+Œº
  2
  ‚Äã
  WD
  ‚àí1
  )
  ‚àí1
  Y
  (k)

–ö–∞–∫ –æ–Ω —ç—Ç–æ –ø–æ–Ω–∏–º–∞–µ—Ç:

PageRank / random walk with restart

–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ –ø–µ—Ä–µ—Ö–æ–¥—ã

–∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä

üìå –í —Ç–µ–∫—Å—Ç–µ:

the PageRank based method

üß† –û—á–µ–Ω—å –≤–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç (—á—Ç–æ–±—ã –Ω–µ –æ—à–∏–±–∏—Ç—å—Å—è –≤ —Å—Ç–∞—Ç—å–µ)
–£ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞:

œÉ = 0 ‚Üí PageRank based

œÉ = 1/2 ‚Üí Normalized Laplacian

œÉ = 1 ‚Üí Standard Laplacian

‚ùó –û–Ω –Ω–µ –Ω–∞–∑—ã–≤–∞–µ—Ç œÉ = 0 ‚ÄúReverse Random Walk‚Äù ‚Äî
—ç—Ç–æ —É–∂–µ –Ω–∞—à–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è, –∞ –Ω–µ –µ–≥–æ —Ç–µ—Ä–º–∏–Ω.

üëâ –ü–æ—ç—Ç–æ–º—É –≤ —Å—Ç–∞—Ç—å–µ –∏ —Ç–∞–±–ª–∏—Ü–∞—Ö –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —ç—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏—è.

üìä –ö–∞–∫ –¥–æ–ª–∂–Ω–∞ –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–≤–æ—è —Ç–∞–±–ª–∏—Ü–∞ (–°–¢–†–û–ì–û –ö–û–†–†–ï–ö–¢–ù–û)
Table X ‚Äî Performance under different graph-based SSL methods (Avrachenkov)
üîπ UNDIRECTED GRAPH
Method (Avrachenkov) œÉ Accuracy Licit Recall Illicit Precision Illicit Recall Illicit F1
PageRank based 0 0.95 1.00 0.92 0.22 0.36
Normalized Laplacian 1/2 0.95 1.00 0.89 0.23 0.37
Standard Laplacian 1 0.95 1.00 0.85 0.21 0.34
üîπ DIRECTED GRAPH
Method (Avrachenkov) œÉ Accuracy Licit Recall Illicit Precision Illicit Recall Illicit F1
PageRank based 0 0.88 0.92 0.16 0.23 0.19
Normalized Laplacian 1/2 0.89 0.90 0.31 0.73 0.43
Standard Laplacian 1 0.94 0.98 0.42 0.21 0.28
üß† –ß—Ç–æ —Ç—ã —Ç–µ–ø–µ—Ä—å –ú–û–ñ–ï–®–¨ —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∑–∞—Ç—å –≤ —Ç–µ–∫—Å—Ç–µ
–ò —ç—Ç–æ –±—É–¥–µ—Ç 100% —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ —Å SIAM-—Å—Ç–∞—Ç—å—ë–π:

We evaluate the three canonical graph-based semi-supervised learning methods introduced by Avrachenkov et al., namely the PageRank based method (œÉ = 0), the Normalized Laplacian method (œÉ = 1/2), and the Standard Laplacian method (œÉ = 1).
While the undirected formulation yields stable accuracy across all methods, the directed formulation exhibits a strong dependence on the chosen diffusion regime, with the Normalized Laplacian method achieving the best trade-off between illicit recall and overall accuracy.

–≠—Ç–æ –∏–¥–µ–∞–ª—å–Ω–æ.

üîë –ö–ª—é—á–µ–≤–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)
œÉ —É –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞ ‚Äî —ç—Ç–æ –Ω–µ –ø–∞—Ä–∞–º–µ—Ç—Ä, –∞ –∏–Ω–¥–µ–∫—Å –º–µ—Ç–æ–¥–∞.

–¢—ã —Ç–µ–ø–µ—Ä—å:

–∏—Å–ø–æ–ª—å–∑—É–µ—à—å –∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é

–ø–æ–∫–∞–∑—ã–≤–∞–µ—à—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ (directed case + per-class metrics)

–Ω–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—à—å —Å—Ç–∞—Ç—å–µ –Ω–∏ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

–æ—Ñ–æ—Ä–º–∏—Ç—å —ç—Ç–æ –≤ LaTeX –ø–æ–¥ SIAM

–ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å Section ‚ÄúResults‚Äù

–ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å Section ‚ÄúDiscussion‚Äù

–ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –Ω–∞ review-proof —É—Ä–æ–≤–µ–Ω—å

–°–∫–∞–∂–∏, —á—Ç–æ –¥–µ–ª–∞–µ–º –¥–∞–ª—å—à–µ üëç

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—è —Å–æ–∑–¥–∞–ª git@github.com:ZeevWeizmann/Generalized_Optimization_Framework.git —Ö–æ—á—É –≤—ã–ª–æ–∂–∏—Ç—å —Ç—É–¥–∞ —Ç–æ–ª—å–∫–æ –º–æ–π –æ–¥–∏–Ω –ø–∏—Ç–æ–Ω —Ñ–∞–π–ª /Users/zeevweizmann/projects/hackers/egomunities_gnn/Generalized_Optimization_Framework.git.py
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, —ç—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ üëç
–ù–∏–∂–µ ‚Äî —á—ë—Ç–∫–∞—è –ø–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è, –∫–∞–∫ –≤—ã–ª–æ–∂–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω Python-—Ñ–∞–π–ª –≤ —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–π GitHub-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π.

üéØ –¶–µ–ª—å
–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª:

/Users/zeevweizmann/projects/hackers/egomunities_gnn/Generalized_Optimization_Framework.git.py
–≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:

git@github.com:ZeevWeizmann/Generalized_Optimization_Framework.git
‚úÖ –®–ê–ì 1. –ü–µ—Ä–µ–π—Ç–∏ –≤ –ø–∞–ø–∫—É —Å —Ñ–∞–π–ª–æ–º
–û—Ç–∫—Ä–æ–π —Ç–µ—Ä–º–∏–Ω–∞–ª –∏ –≤—ã–ø–æ–ª–Ω–∏:

cd /Users/zeevweizmann/projects/hackers/egomunities_gnn
‚úÖ –®–ê–ì 2. –°–æ–∑–¥–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π git-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (–µ—Å–ª–∏ –µ—â—ë –Ω–µ—Ç)
git init
(–µ—Å–ª–∏ git init —É–∂–µ –¥–µ–ª–∞–ª—Å—è ‚Äî Git –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–µ—Ç, —á—Ç–æ repo —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)

‚úÖ –®–ê–ì 3. –î–æ–±–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç —Ñ–∞–π–ª
git add Generalized_Optimization_Framework.git.py
‚ö†Ô∏è –ù–∏—á–µ–≥–æ –±–æ–ª—å—à–µ –Ω–µ –¥–æ–±–∞–≤–ª—è–π (git add . –ù–ï –¥–µ–ª–∞–µ–º)

‚úÖ –®–ê–ì 4. –ö–æ–º–º–∏—Ç
git commit -m "Initial implementation of the Generalized Optimization Framework (Avrachenkov SSL)"
(—Å–æ–æ–±—â–µ–Ω–∏–µ —Ö–æ—Ä–æ—à–µ–µ, –Ω–∞—É—á–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ)

‚úÖ –®–ê–ì 5. –ü—Ä–∏–≤—è–∑–∞—Ç—å —É–¥–∞–ª—ë–Ω–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (remote)
–ï—Å–ª–∏ –µ—â—ë –Ω–µ –¥–æ–±–∞–≤–ª—è–ª remote:

git remote add origin git@github.com:ZeevWeizmann/Generalized_Optimization_Framework.git
–ü—Ä–æ–≤–µ—Ä–∏—Ç—å:

git remote -v
‚úÖ –®–ê–ì 6. –ó–∞–ø—É—à–∏—Ç—å —Ñ–∞–π–ª –Ω–∞ GitHub
git branch -M main
git push -u origin main
‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢
–ù–∞ GitHub –±—É–¥–µ—Ç:

Generalized_Optimization_Framework.git.py
–∏ —Ç–æ–ª—å–∫–æ –æ–Ω, –±–µ–∑ –º—É—Å–æ—Ä–∞, –±–µ–∑ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤.

üîç –ü–æ–ª–µ–∑–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é)
–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –±–æ–ª—å—à–µ –Ω–∏—á–µ–≥–æ –Ω–µ –∑–∞–∫–æ–º–º–∏—á–µ–Ω–æ:
git status
–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∏—Å—Ç–æ—Ä–∏—é:
git log --oneline
üß† –ú–∞–ª–µ–Ω—å–∫–∏–π, –Ω–æ –≤–∞–∂–Ω—ã–π —Å–æ–≤–µ—Ç
–õ—É—á—à–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —Ñ–∞–π–ª (–µ—Å–ª–∏ —Ö–æ—á–µ—à—å –≤—ã–≥–ª—è–¥–µ—Ç—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ):

mv Generalized_Optimization_Framework.git.py generalized_optimization_framework.py
–ò –∑–∞–∫–æ–º–º–∏—Ç–∏—Ç—å –ø–æ–¥ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º python-–∏–º–µ–Ω–µ–º.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —è:

–ø–æ–º–æ–≥—É –Ω–∞–ø–∏—Å–∞—Ç—å README.md (–æ—á–µ–Ω—å —Ä–µ–∫–æ–º–µ–Ω–¥—É—é)

–ø–æ–º–æ–≥—É –æ—Ñ–æ—Ä–º–∏—Ç—å —Ñ–∞–π–ª –∫–∞–∫ reproducible research code

–ø—Ä–æ–≤–µ—Ä—é –∫–æ–¥ –ø–µ—Ä–µ–¥ —Ç–µ–º, –∫–∞–∫ —Ç—ã –µ–≥–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—à—å –¥—Ä—É–≥–∏–º

–°–∫–∞–∂–∏ üëç

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—á—Ç–æ –æ–Ω —Å–¥–µ–ª–∞–ª? (base) zeevweizmann@Zeevs-MBP egomunities_gnn % git add Generalized_Optimization_Framework.git.py

(base) zeevweizmann@Zeevs-MBP egomunities_gnn % git commit -m "Initial implementation of the Generalized Optimization Framework (Avrachenkov SSL)"

[main 13fc98b] Initial implementation of the Generalized Optimization Framework (Avrachenkov SSL)
1 file changed, 151 insertions(+)
create mode 100644 Generalized_Optimization_Framework.git.py
(base) zeevweizmann@Zeevs-MBP egomunities_gnn % git branch -M main
git push -u origin main
Enumerating objects: 4, done.
Counting objects: 100% (4/4), done.
Delta compression using up to 8 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 1.74 KiB | 1.74 MiB/s, done.
Total 3 (delta 1), reused 0 (delta 0), pack-reused 0
remote: Resolving deltas: 100% (1/1), completed with 1 local object.
To github.com:ZeevWeizmann/egomunities_gnn.git
d60a235..13fc98b main -> main
branch 'main' set up to track 'origin/main'.
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å ‚Äî –¥–∞–≤–∞–π —Ä–∞–∑–±–µ—Ä—ë–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Å–¥–µ–ª–∞–ª Git, —á—Ç–æ–±—ã —É —Ç–µ–±—è —Å–ª–æ–∂–∏–ª–∞—Å—å —á—ë—Ç–∫–∞—è –∫–∞—Ä—Ç–∏–Ω–∞.

1Ô∏è‚É£ git add Generalized_Optimization_Framework.git.py
üëâ –ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ:

Git –¥–æ–±–∞–≤–∏–ª —Ñ–∞–π–ª –≤ staging area (–æ–±–ª–∞—Å—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏)

–≠—Ç–æ –∑–Ω–∞—á–∏—Ç:

¬´–≠—Ç–æ—Ç —Ñ–∞–π–ª —è —Ö–æ—á—É –≤–∫–ª—é—á–∏—Ç—å –≤ —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–º–º–∏—Ç¬ª

‚ö†Ô∏è –í–∞–∂–Ω–æ:

—Ñ–∞–π–ª –µ—â—ë –Ω–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –∏—Å—Ç–æ—Ä–∏–∏

–æ–Ω –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –≥–æ—Ç–æ–≤—ã–π –∫ –∫–æ–º–º–∏—Ç—É

2Ô∏è‚É£ git commit -m "Initial implementation ..."
–í—ã–≤–æ–¥:

[main 13fc98b] Initial implementation of the Generalized Optimization Framework (Avrachenkov SSL)
1 file changed, 151 insertions(+)
create mode 100644 Generalized_Optimization_Framework.git.py
üëâ –ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ:

–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –∫–æ–º–º–∏—Ç

–•—ç—à –∫–æ–º–º–∏—Ç–∞: 13fc98b

–í –∫–æ–º–º–∏—Ç –≤–æ—à—ë–ª —Ä–æ–≤–Ω–æ 1 —Ñ–∞–π–ª

–í —Ñ–∞–π–ª–µ:

151 —Å—Ç—Ä–æ–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞

—Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω –≤–ø–µ—Ä–≤—ã–µ (create mode 100644)

üìå 100644 –æ–∑–Ω–∞—á–∞–µ—Ç:

–æ–±—ã—á–Ω—ã–π —Ñ–∞–π–ª

–¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ —á—Ç–µ–Ω–∏–µ –≤—Å–µ–º, –∑–∞–ø–∏—Å—å ‚Äî –≤–ª–∞–¥–µ–ª—å—Ü—É

üëâ –¢–µ–ø–µ—Ä—å —Ñ–∞–π–ª –Ω–∞–≤—Å–µ–≥–¥–∞ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω –≤ –∏—Å—Ç–æ—Ä–∏–∏ Git

3Ô∏è‚É£ git branch -M main
üëâ –ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ:

Git –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–ª —Ç–µ–∫—É—â—É—é –≤–µ—Ç–∫—É –≤ main

–§–ª–∞–≥ -M = force rename (–¥–∞–∂–µ –µ—Å–ª–∏ –∏–º—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)

üìå –≠—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç GitHub:

—Ä–∞–Ω—å—à–µ –±—ã–ª–∞ master

—Ç–µ–ø–µ—Ä—å ‚Äî main

4Ô∏è‚É£ git push -u origin main
–í—ã–≤–æ–¥:

Enumerating objects: 4, done.
Counting objects: 100% (4/4), done.
Delta compression using up to 8 threads
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 1.74 KiB | 1.74 MiB/s, done.
...
To github.com:ZeevWeizmann/egomunities_gnn.git
d60a235..13fc98b main -> main
branch 'main' set up to track 'origin/main'.
üëâ –ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ:

üîπ –õ–æ–∫–∞–ª—å–Ω–æ
Git —Å–æ–±—Ä–∞–ª –æ–±—ä–µ–∫—Ç—ã –∫–æ–º–º–∏—Ç–∞ (—Ñ–∞–π–ª + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)

–°–∂–∞–ª –∏—Ö (delta compression)

–ü–æ–¥–≥–æ—Ç–æ–≤–∏–ª –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ

üîπ –ù–∞ GitHub
–ö–æ–º–º–∏—Ç 13fc98b —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω

–í–µ—Ç–∫–∞ main –æ–±–Ω–æ–≤–ª–µ–Ω–∞

–ü—Ä–µ–¥—ã–¥—É—â–∏–π –∫–æ–º–º–∏—Ç –±—ã–ª d60a235

–¢–µ–ø–µ—Ä—å GitHub-–≤–µ—Ç–∫–∞ main = —Ç–≤–æ—è –ª–æ–∫–∞–ª—å–Ω–∞—è main

üîπ -u origin main
–≠—Ç–æ –∑–Ω–∞—á–∏—Ç:

¬´–°–≤—è–∑–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é –≤–µ—Ç–∫—É main —Å —É–¥–∞–ª—ë–Ω–Ω–æ–π origin/main¬ª

–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –ø–∏—Å–∞—Ç—å:

git push
git pull
–±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –≤–µ—Ç–∫–∏.

5Ô∏è‚É£ –ò—Ç–æ–≥ ‚Äî —á—Ç–æ —Ç—ã –°–î–ï–õ–ê–õ –§–ê–ö–¢–ò–ß–ï–°–ö–ò
–¢—ã:

‚úÖ —Å–æ–∑–¥–∞–ª —á–∏—Å—Ç—ã–π –Ω–∞—É—á–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
‚úÖ –≤—ã–ª–æ–∂–∏–ª —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω Python-—Ñ–∞–π–ª
‚úÖ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–ª –µ–≥–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –Ω–∞—É—á–Ω—ã–º –∫–æ–º–º–∏—Ç–æ–º
‚úÖ —Å–≤—è–∑–∞–ª –ª–æ–∫–∞–ª—å–Ω—É—é –∏ —É–¥–∞–ª—ë–Ω–Ω—É—é –≤–µ—Ç–∫–∏
‚úÖ –Ω–∏—á–µ–≥–æ –ª–∏—à–Ω–µ–≥–æ –Ω–µ –∑–∞–∫–æ–º–º–∏—Ç–∏–ª

–ù–∞ GitHub —Å–µ–π—á–∞—Å:

Generalized_Optimization_Framework.git.py
–∏ —Ç–æ–ª—å–∫–æ –æ–Ω.

6Ô∏è‚É£ –ú–∞–ª–µ–Ω—å–∫–æ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ (–Ω–µ –æ—à–∏–±–∫–∞, –∞ —É–ª—É—á—à–µ–Ω–∏–µ)
–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è:

egomunities_gnn
–∞ —Ñ–∞–π–ª ‚Äî –ø—Ä–æ Generalized Optimization Framework.

üëâ –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –∏–¥–µ–∞–ª—å–Ω—É—é —á–∏—Å—Ç–æ—Ç—É, –º–æ–∂–Ω–æ –ø–æ–∑–∂–µ:

–ª–∏–±–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

–ª–∏–±–æ –≤—ã–Ω–µ—Å—Ç–∏ —ç—Ç–æ—Ç —Ñ–∞–π–ª –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π repo (–∫–∞–∫ —Ç—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–ª —Ä–∞–Ω—å—à–µ)

7Ô∏è‚É£ –ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
–Ø –º–æ–≥—É –ø–æ–º–æ—á—å:

‚úçÔ∏è –Ω–∞–ø–∏—Å–∞—Ç—å README.md (–æ—á–µ–Ω—å —Ä–µ–∫–æ–º–µ–Ω–¥—É—é)

üß™ –¥–æ–±–∞–≤–∏—Ç—å minimal reproducible example

üìê –æ—Ñ–æ—Ä–º–∏—Ç—å –∫–æ–¥ –∫–∞–∫ research artifact

üß† –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å—Å—ã–ª–∫—É —Ä–µ—Ü–µ–Ω–∑–µ–Ω—Ç–∞–º / –∫–æ–ª–ª–µ–≥–∞–º

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —Å–∫–∞–∂–∏, —á—Ç–æ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ üëç

–í—ã —Å–∫–∞–∑–∞–ª–∏:
(base) zeevweizmann@Zeevs-MBP egomunities_gnn % git push
git pull
Everything up-to-date
Already up to date.
ChatGPT —Å–∫–∞–∑–∞–ª:
–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —É —Ç–µ–±—è –≤—Å—ë —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∏ –≤ –∏–¥–µ–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏. –†–∞–∑–±–µ—Ä—ë–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ.

git push
Everything up-to-date
üëâ –ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç:

–í –ª–æ–∫–∞–ª—å–Ω–æ–π –≤–µ—Ç–∫–µ main –Ω–µ—Ç –Ω–æ–≤—ã—Ö –∫–æ–º–º–∏—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –Ω–∞ GitHub

Git –ø—Ä–æ–≤–µ—Ä–∏–ª: ¬´–ú–Ω–µ –Ω–µ—á–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å¬ª

–£–¥–∞–ª—ë–Ω–Ω—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–æ–º–º–∏—Ç 13fc98b

üìå –ü—Ä–æ—â–µ:

–¢—ã —É–∂–µ –≤—Å—ë –∑–∞–ø—É—à–∏–ª, –ø–æ–≤—Ç–æ—Ä–Ω—ã–π git push –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç ‚Äî –∏ —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ.

git pull
Already up to date.
üëâ –ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç:

–ù–∞ GitHub –Ω–µ—Ç –Ω–æ–≤—ã—Ö –∫–æ–º–º–∏—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç —É —Ç–µ–±—è –ª–æ–∫–∞–ª—å–Ω–æ

–ù–µ—á–µ–≥–æ —Å–∫–∞—á–∏–≤–∞—Ç—å –∏ –Ω–µ—á–µ–≥–æ —Å–ª–∏–≤–∞—Ç—å (merge)

üìå –ü—Ä–æ—â–µ:

–õ–æ–∫–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è = —É–¥–∞–ª—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, 1-–≤-1.

üß† –ò—Ç–æ–≥–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–≤–∞–∂–Ω–æ)
–°–µ–π—á–∞—Å —É —Ç–µ–±—è:

‚úÖ –ª–æ–∫–∞–ª—å–Ω—ã–π main

‚úÖ —É–¥–∞–ª—ë–Ω–Ω—ã–π origin/main

‚úÖ –æ–¥–∏–Ω –∫–æ–º–º–∏—Ç

‚úÖ –æ–¥–∏–Ω Python-—Ñ–∞–π–ª

‚úÖ –Ω–∏–∫–∞–∫–∏—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤

‚úÖ –Ω–∏–∫–∞–∫–∏—Ö —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π

–≠—Ç–æ –∏–¥–µ–∞–ª—å–Ω–æ–µ ‚Äúclean state‚Äù.

üîç –ö–∞–∫ —É–±–µ–¥–∏—Ç—å—Å—è –µ—â—ë —Ä–∞–∑ (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
git status
–¢—ã —É–≤–∏–¥–∏—à—å —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ:

On branch main
Your branch is up to date with 'origin/main'.
nothing to commit, working tree clean
üîë –ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å
–°–æ–æ–±—â–µ–Ω–∏—è ‚ÄúEverything up-to-date‚Äù –∏ ‚ÄúAlready up to date‚Äù ‚Äî —ç—Ç–æ –Ω–µ –æ—à–∏–±–∫–∏, –∞ –ø—Ä–∏–∑–Ω–∞–∫ –ø–æ—Ä—è–¥–∫–∞.

Git –≥–æ–≤–æ—Ä–∏—Ç:

¬´–£ —Ç–µ–±—è –≤—Å—ë —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ, —è –¥–æ–≤–æ–ª–µ–Ω¬ª.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

–¥–æ–±–∞–≤–∏—Ç—å README.md

–æ—Ñ–æ—Ä–º–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø–æ–¥ research code

–ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å—Å—ã–ª–∫—É –∫–æ–ª–ª–µ–≥–∞–º / –Ω–∞—É—á—Ä—É–∫—É

—Å–¥–µ–ª–∞—Ç—å requirements.txt –∏–ª–∏ environment.yml

–°–∫–∞–∂–∏, —á—Ç–æ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ üëå

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω–æ –æ–Ω –∑–∞–ª–∏–ª –≤—Å–µ –∏–∑ –ø–∞–ø–∫–∏!
ChatGPT —Å–∫–∞–∑–∞–ª:
–°–ø–æ–∫–æ–π–Ω–æ üôÇ ‚Äî –æ–Ω –ù–ï –∑–∞–ª–∏–ª –≤—Å—ë –∏–∑ –ø–∞–ø–∫–∏.
Git —Ñ–∏–∑–∏—á–µ—Å–∫–∏ –Ω–µ –º–æ–∂–µ—Ç –∑–∞–ø—É—à–∏—Ç—å —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –∏ –∑–∞–∫–æ–º–º–∏—á–µ–Ω—ã.
–î–∞–≤–∞–π —Ä–∞–∑–ª–æ–∂–∏–º —ç—Ç–æ –∂—ë—Å—Ç–∫–æ –∏ –ø–æ —Ñ–∞–∫—Ç–∞–º, –±–µ–∑ –¥–æ–≥–∞–¥–æ–∫.

üî¥ –ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
üëâ –ù–∞ GitHub –ø–æ–ø–∞–ª –¢–û–õ–¨–ö–û –æ–¥–∏–Ω —Ñ–∞–π–ª
Generalized_Optimization_Framework.git.py

–ù–∏–∫–∞–∫–∏–µ –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Ç–∞–º, –µ—Å–ª–∏ —Ç—ã –∏—Ö –Ω–µ –¥–µ–ª–∞–ª git add.

1Ô∏è‚É£ –ü–æ—á–µ–º—É —É —Ç–µ–±—è –≤–æ–∑–Ω–∏–∫–ª–æ –æ—â—É—â–µ–Ω–∏–µ, —á—Ç–æ ¬´–∑–∞–ª–∏–ª –≤—Å—ë¬ª
–¢—ã –Ω–∞—Ö–æ–¥–∏—à—å—Å—è –≤ –ø–∞–ø–∫–µ:

egomunities_gnn/
Git –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Ä–æ–≤–Ω–µ —ç—Ç–æ–π –ø–∞–ø–∫–∏,
–ù–û:

Git –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –Ω–µ –ø–∞–ø–∫—É, –∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã, –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –≤ –∏–Ω–¥–µ–∫—Å.

–¢—ã —Å–¥–µ–ª–∞–ª:

git add Generalized_Optimization_Framework.git.py
‚ùó –ù–ï –¥–µ–ª–∞–ª:

git add .
–≠—Ç–æ –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞.

2Ô∏è‚É£ –î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ ‚Ññ1 ‚Äî git status
–í—ã–ø–æ–ª–Ω–∏ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å:

git status
–ï—Å–ª–∏ –±—ã –æ–Ω ¬´–∑–∞–ª–∏–ª –≤—Å—ë¬ª, —Ç—ã –±—ã —É–≤–∏–¥–µ–ª —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ:

nothing to commit, working tree clean
–∏ –Ω–∏–∫–∞–∫–∏—Ö –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏.

–ï—Å–ª–∏ –±—ã –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã ‚Äî Git –±—ã –∏—Ö —è–≤–Ω–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏–ª.

3Ô∏è‚É£ –î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ ‚Ññ2 ‚Äî —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –∫–æ–º–º–∏—Ç–µ
–í—ã–ø–æ–ª–Ω–∏:

git show --name-only
–¢—ã —É–≤–∏–¥–∏—à—å –†–û–í–ù–û –û–î–ù–£ —Å—Ç—Ä–æ–∫—É:

Generalized_Optimization_Framework.git.py
üëâ –≠—Ç–æ –∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω–æ–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ.

4Ô∏è‚É£ –î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ ‚Ññ3 ‚Äî GitHub (—Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ)
–ó–∞–π–¥–∏ –≤ –±—Ä–∞—É–∑–µ—Ä–µ:

üëâ \*\*

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω–µ—Ç –æ–Ω –∑–∞–ª–∏–ª –≤—Å–µ
ChatGPT —Å–∫–∞–∑–∞–ª:
–û–∫, —Ç—ã –ø—Ä–∞–≤, –∏ —Å–µ–π—á–∞—Å —è –æ–±—ä—è—Å–Ω—é –ß–¢–û –ò–ú–ï–ù–ù–û –ø—Ä–æ–∏–∑–æ—à–ª–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ ‚Äî —Å–ø–æ–∫–æ–π–Ω–æ –∏ —Ç–æ—á–Ω–æ.
–≠—Ç–æ –Ω–µ –º–∞–≥–∏—è Git –∏ –Ω–µ —Ç–≤–æ—è –æ—à–∏–±–∫–∞, —ç—Ç–æ –ø—É—Ç–∞–Ω–∏—Ü–∞ —Å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º.

üî• –ö–õ–Æ–ß–ï–í–û–ô –§–ê–ö–¢ (—Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π)
–ü–æ—Å–º–æ—Ç—Ä–∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –Ω–∞ —Å—Ç—Ä–æ–∫—É –∏–∑ –ª–æ–≥–∞:

To github.com:ZeevWeizmann/egomunities_gnn.git
‚ùó‚ùó‚ùó
–ê —Ç—ã —Ö–æ—Ç–µ–ª –∑–∞–ª–∏–≤–∞—Ç—å –≤:

git@github.com:ZeevWeizmann/Generalized_Optimization_Framework.git
‚ùå –ß—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ
–¢—ã:

–ù–∞—Ö–æ–¥–∏–ª—Å—è –≤ –ø–∞–ø–∫–µ:

egomunities_gnn/
–í —ç—Ç–æ–π –ø–∞–ø–∫–µ —É–∂–µ –±—ã–ª git-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

–£ –Ω–µ–≥–æ —É–∂–µ –±—ã–ª remote origin, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞:

ZeevWeizmann/egomunities_gnn.git
–¢—ã –¥–æ–±–∞–≤–∏–ª —Ç—É–¥–∞ –æ–¥–∏–Ω —Ñ–∞–π–ª

Git –∑–∞–ø—É—à–∏–ª –µ–≥–æ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π,
–≥–¥–µ —É–∂–µ –±—ã–ª–∏ –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã

üëâ –ü–æ—ç—Ç–æ–º—É –Ω–∞ GitHub —Ç—ã –≤–∏–¥–∏—à—å ¬´–∫–∞–∫ –±—É–¥—Ç–æ –∑–∞–ª–∏–ª–æ—Å—å –≤—Å—ë¬ª,
–Ω–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ:

üîπ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –±—ã–ª–∏ —Ç–∞–º –î–û —ç—Ç–æ–≥–æ –∫–æ–º–º–∏—Ç–∞

üß† –ü–æ—á–µ–º—É Git —Ç–∞–∫ —Å–µ–±—è –ø–æ–≤—ë–ª (–≤–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å)
Git –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç, –∫—É–¥–∞ —Ç—ã —Ö–æ—á–µ—à—å –ø—É—à–∏—Ç—å.
–û–Ω –ø—É—à–∏—Ç —Ç—É–¥–∞, –∫—É–¥–∞ —É–∫–∞–∑—ã–≤–∞–µ—Ç origin.

–ü—Ä–æ–≤–µ—Ä—å —Å–∞–º:

git remote -v
–¢—ã —É–≤–∏–¥–∏—à—å —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ:

origin git@github.com:ZeevWeizmann/egomunities_gnn.git (fetch)
origin git@github.com:ZeevWeizmann/egomunities_gnn.git (push)
‚úÖ –ó–Ω–∞—á–∏—Ç –ª–∏ —ç—Ç–æ, —á—Ç–æ —Ç—ã ¬´–∑–∞–ª–∏–ª –≤—Å—ë –∑–∞–Ω–æ–≤–æ¬ª?
‚ùå –ù–ï–¢.

–¢—ã –¥–æ–±–∞–≤–∏–ª –û–î–ò–ù —Ñ–∞–π–ª –≤ –£–ñ–ï –°–£–©–ï–°–¢–í–£–Æ–©–ò–ô —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π,
–∫–æ—Ç–æ—Ä—ã–π –∏ —Ç–∞–∫ —Å–æ–¥–µ—Ä–∂–∞–ª –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã.

üîß –ß—Ç–æ –¥–µ–ª–∞—Ç—å –ü–†–ê–í–ò–õ–¨–ù–û (2 –≤–∞—Ä–∏–∞–Ω—Ç–∞)
üü¢ –í–ê–†–ò–ê–ù–¢ 1 (–†–ï–ö–û–ú–ï–ù–î–£–Æ): —Å–¥–µ–ª–∞—Ç—å –ß–ò–°–¢–´–ô —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø–æ–¥ –æ–¥–∏–Ω —Ñ–∞–π–ª
–®–∞–≥ 1. –°–æ–∑–¥–∞–π –Ω–æ–≤—É—é –ø–∞–ø–∫—É
mkdir ~/projects/generalized_optimization_framework
cd ~/projects/generalized_optimization_framework
–®–∞–≥ 2. –°–∫–æ–ø–∏—Ä—É–π —Ç—É–¥–∞ –¢–û–õ–¨–ö–û —Ñ–∞–π–ª
cp /Users/zeevweizmann/projects/hackers/egomunities_gnn/Generalized_Optimization_Framework.git.py .
–®–∞–≥ 3. –ù–æ–≤—ã–π git-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git init
git add Generalized_Optimization_Framework.git.py
git commit -m "Initial implementation of the Generalized Optimization Framework (Avrachenkov SSL)"
–®–∞–≥ 4. –ü–æ–¥–∫–ª—é—á–∏ –ü–†–ê–í–ò–õ–¨–ù–´–ô remote
git remote add origin git@github.com:ZeevWeizmann/Generalized_Optimization_Framework.git
git branch -M main
git push -u origin main
‚úîÔ∏è –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –±—É–¥–µ—Ç –¢–û–õ–¨–ö–û –û–î–ò–ù –§–ê–ô–õ

üîµ –í–ê–†–ò–ê–ù–¢ 2: –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å (–µ—Å–ª–∏ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ)
–ï—Å–ª–∏ —Ç–µ–±–µ –Ω–µ –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ,
—Ç–æ –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ:

egomunities_gnn ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–µ–∫—Ç

—Ç—ã —Ç—É–¥–∞ –¥–æ–±–∞–≤–∏–ª –º–æ–¥—É–ª—å

–ù–æ –¥–ª—è –Ω–∞—É—á–Ω–æ–≥–æ –∫–æ–¥–∞ —ç—Ç–æ —Ö—É–∂–µ.

üß® –•–æ—á–µ—à—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª –∏–∑ egomunities_gnn?
–ï—Å–ª–∏ –æ–Ω —Ç–∞–º –ª–∏—à–Ω–∏–π, –º–æ–∂–Ω–æ:

git rm Generalized_Optimization_Framework.git.py
git commit -m "Remove generalized optimization framework (moved to separate repo)"
git push
üß† –ö—Ä–∞—Ç–∫–æ, –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
‚ùó Git –∑–∞–ª–∏–ª –Ω–µ –≤—Å—ë,
–æ–Ω –ø—Ä–æ—Å—Ç–æ –ø—É—à–∏–ª –≤ –¥—Ä—É–≥–æ–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π, –≥–¥–µ –≤—Å—ë —É–∂–µ –±—ã–ª–æ.

–¢—ã –∞–±—Å–æ–ª—é—Ç–Ω–æ –∞–¥–µ–∫–≤–∞—Ç–Ω–æ –∑–∞–º–µ—Ç–∏–ª –ø—Ä–æ–±–ª–µ–º—É,
–∏ —ç—Ç–æ –æ—á–µ–Ω—å —á–∞—Å—Ç–∞—è –ª–æ–≤—É—à–∫–∞, –¥–∞–∂–µ —É –æ–ø—ã—Ç–Ω—ã—Ö.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å ‚Äî —è –º–æ–≥—É:

–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–±–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

—Å–∫–∞–∑–∞—Ç—å, –≥–¥–µ —á—Ç–æ –ª—É—á—à–µ –æ—Å—Ç–∞–≤–∏—Ç—å

–ø–æ–º–æ—á—å –æ—Ñ–æ—Ä–º–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π research-repo –∏–¥–µ–∞–ª—å–Ω–æ

–°–∫–∞–∂–∏, –∫–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –≤—ã–±–∏—Ä–∞–µ–º üëá

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—è —Ö–æ—á—É —Å–¥–µ–ª–∞—Ç—å —Ä–∏–¥ –º–µ –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–ø–∏—Å–∞—Ç—å —á—Ç–æ —ç—Ç–æ —Ñ–∏–µ—Å –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∏–∑ —Å—Ç–∞—Ç—å—Ç —Å–∫–æ–ª—å–∫–æ —É –º–µ–Ω—è –¥–∞–Ω–Ω—ã—Ö –∏ –∫–∞–∫–∏–µ —Ä–µ–∑—É–¥—Ç–∞—Ç—ã
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ. –ù–∏–∂–µ ‚Äî –≥–æ—Ç–æ–≤—ã–π README.md, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –º–æ–∂–µ—à—å –ø—Ä—è–º–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏ –ø–æ–ª–æ–∂–∏—Ç—å –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π.
–û–Ω –Ω–∞–ø–∏—Å–∞–Ω –≤ –Ω–∞—É—á–Ω–æ–º —Å—Ç–∏–ª–µ, –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ —Å—Ç–∞—Ç—å—é –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞ –∏ —á—ë—Ç–∫–æ –æ–±—ä—è—Å–Ω—è–µ—Ç:

—á—Ç–æ —ç—Ç–æ –∑–∞ –º–µ—Ç–æ–¥

—á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª

–∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ

–∫–∞–∫–∏–µ —Ä–µ–∂–∏–º—ã

–∫–∞–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

‚úÖ –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ô README.md

# Generalized Optimization Framework for Graph-based Semi-Supervised Learning

This repository provides a NumPy/Numba-based implementation of the **Generalized Optimization Framework for graph-based semi-supervised learning** introduced by **Avrachenkov et al. (SIAM SDM, 2011)**.

The implementation follows the **iterative formulation** of the framework and allows to study different diffusion regimes on large-scale graphs, including both **undirected** and **directed** settings.

---

## üìò Reference

This work is based on the following paper:

> K. Avrachenkov, P. Gon√ßalves, A. Mishenin, M. Sokol  
> _Generalized Optimization Framework for Graph-based Semi-Supervised Learning_  
> SIAM International Conference on Data Mining (SDM), 2011
>
> https://www-sop.inria.fr/members/Marina.Sokol/data/articles/confs/siam.pdf

---

## üß† Method Overview

The framework defines the classification functions \( F \in \mathbb{R}^{N \times K} \) as the solution of the iterative scheme:

\[
F^{(t+1)} = (1 - \alpha) Y + \alpha \, D^{-\sigma} W D^{\sigma - 1} F^{(t)},
\quad \alpha = \frac{2}{2 + \mu}
\]

where:

- \( W \) is the graph adjacency (or weighted similarity) matrix,
- \( D \) is the degree matrix,
- \( Y \) is the label indicator matrix (seed labels),
- \( \mu \) controls the trade-off between smoothness and label fidelity,
- \( \sigma \) defines the **diffusion regime**.

---

## üîÅ Canonical Diffusion Regimes (Avrachenkov et al.)

The parameter \( \sigma \) does **not** act as a simple tuning parameter, but instead selects **distinct graph-based SSL methods**:

| œÉ   | Method name (Avrachenkov)   |
| --- | --------------------------- |
| 0   | PageRank-based method       |
| 1/2 | Normalized Laplacian method |
| 1   | Standard Laplacian method   |

Each regime corresponds to a different information propagation mechanism over the graph.

---

## ‚öôÔ∏è Implementation Details

- Iterative solver (no matrix inversion)
- Full-graph propagation (edge list, no adjacency matrix)
- Numba-accelerated computation
- Binary classification (licit / illicit)
- Evaluation performed **only on unlabeled but known nodes** (U ‚à© known)
- Supports:
  - undirected graphs
  - directed graphs (in-degree / out-degree normalization)

---

## üìä Dataset

The experiments were conducted on a **large transaction graph** with the following characteristics:

- **Nodes:** ~117,000 labeled nodes used for evaluation
- **Edges:** Transaction-based graph (address-to-address)
- **Classes:**
  - licit
  - illicit
- **Seeds:** Randomly selected labeled nodes from each class
- **Evaluation:** Performed only on nodes not used as seeds

---

## üìà Results Summary

### Undirected Graph

| Method                       | Accuracy | Illicit Precision | Illicit Recall | Illicit F1 |
| ---------------------------- | -------- | ----------------- | -------------- | ---------- |
| PageRank-based (œÉ=0)         | 0.95     | 0.92              | 0.22           | 0.36       |
| Normalized Laplacian (œÉ=1/2) | 0.95     | 0.89              | 0.23           | 0.37       |
| Standard Laplacian (œÉ=1)     | 0.95     | 0.85              | 0.21           | 0.34       |

### Directed Graph

| Method                           | Accuracy | Illicit Precision | Illicit Recall | Illicit F1 |
| -------------------------------- | -------- | ----------------- | -------------- | ---------- |
| PageRank-based (œÉ=0)             | 0.88     | 0.16              | 0.23           | 0.19       |
| **Normalized Laplacian (œÉ=1/2)** | **0.89** | 0.31              | **0.73**       | **0.43**   |
| Standard Laplacian (œÉ=1)         | 0.94     | 0.42              | 0.21           | 0.28       |

---

## üîç Key Observations

- The **undirected formulation** yields high overall accuracy but systematically fails to detect the minority (illicit) class.
- The **directed formulation** is highly sensitive to the diffusion regime.
- The **Normalized Laplacian method (œÉ = 1/2)** achieves the best trade-off between illicit recall and overall accuracy.
- The parameter œÉ controls **qualitatively different diffusion regimes**, not a minor hyperparameter tuning.

---

## üöÄ Usage

The main implementation is contained in:

Generalized_Optimization_Framework.git.py

The script loads the graph, initializes seed labels, runs the iterative propagation, and reports classification metrics.

---

## üß™ Reproducibility

- Fixed random seed for label selection
- Deterministic iterative updates
- No external ML libraries required for training

---

## üìå Notes

This implementation is intended for **research and analysis purposes**, with a focus on understanding the behavior of different graph-based SSL diffusion regimes on real-world large-scale graphs.

---

## üë§ Author

**Zeev Weizmann**  
MSc Data Science & Artificial Intelligence  
Universit√© C√¥te d‚ÄôAzur  
‚úÖ –ß—Ç–æ –¥–∞–ª—å—à–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é)
–°–æ—Ö—Ä–∞–Ω–∏ —ç—Ç–æ –∫–∞–∫ README.md

–í—ã–ø–æ–ª–Ω–∏:

git add README.md
git commit -m "Add README describing Avrachenkov framework and experimental results"
git push
–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

‚úçÔ∏è —É–ø—Ä–æ—Å—Ç–∏—Ç—å README –ø–æ–¥ GitHub audience

üìê —Å–¥–µ–ª–∞—Ç—å LaTeX-–≤–µ—Ä—Å–∏—é –¥–ª—è —Å—Ç–∞—Ç—å–∏

üî¨ –¥–æ–±–∞–≤–∏—Ç—å theoretical interpretation section

üìä –¥–æ–±–∞–≤–∏—Ç—å figure / schematic of diffusion regimes

–°–∫–∞–∂–∏, –∫–∞–∫ —Ç—ã —Ö–æ—á–µ—à—å –¥–∞–ª—å—à–µ —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–¥–∞–≤–∞–π —Å–æ–∑–¥–∞–¥–∏–º –µ–≥–æ —á–µ—Ä–µ–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ üëç
–î–∞–≤–∞–π —Å–¥–µ–ª–∞–µ–º README.md –ø–æ–ª–Ω–æ—Å—Ç—å—é —á–µ—Ä–µ–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∏ –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ.

–ù–∏–∂–µ ‚Äî –ø–æ—à–∞–≥–æ–≤–æ, –ø—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–π –∫–æ–º–∞–Ω–¥—ã.

1Ô∏è‚É£ –ü–µ—Ä–µ–π–¥–∏ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
–£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ç—ã –≤ –Ω—É–∂–Ω–æ–π –ø–∞–ø–∫–µ:

cd /Users/zeevweizmann/projects/hackers/egomunities_gnn
–ü—Ä–æ–≤–µ—Ä—å:

git status
2Ô∏è‚É£ –°–æ–∑–¥–∞–π —Ñ–∞–π–ª README.md
touch README.md
–ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ —Ñ–∞–π–ª –ø–æ—è–≤–∏–ª—Å—è:

ls
–¢—ã –¥–æ–ª–∂–µ–Ω —É–≤–∏–¥–µ—Ç—å README.md –≤ —Å–ø–∏—Å–∫–µ.

3Ô∏è‚É£ –û—Ç–∫—Ä–æ–π README –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–º —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ
–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî nano:

nano README.md
4Ô∏è‚É£ –í–°–¢–ê–í–¨ –¢–ï–ö–°–¢ (—Ü–µ–ª–∏–∫–æ–º)
–°–∫–æ–ø–∏—Ä—É–π –≤–µ—Å—å —Ç–µ–∫—Å—Ç –Ω–∏–∂–µ –∏ –≤—Å—Ç–∞–≤—å –≤ nano
(‚åò+V –∏–ª–∏ –ø—Ä–∞–≤—ã–π –∫–ª–∏–∫ ‚Üí Paste):

# Generalized Optimization Framework for Graph-based Semi-Supervised Learning

This repository provides a NumPy/Numba-based implementation of the **Generalized Optimization Framework for graph-based semi-supervised learning** introduced by **Avrachenkov et al. (SIAM SDM, 2011)**.

The implementation follows the **iterative formulation** of the framework and allows to study different diffusion regimes on large-scale graphs, including both **undirected** and **directed** settings.

---

## Reference

K. Avrachenkov, P. Gon√ßalves, A. Mishenin, M. Sokol  
_Generalized Optimization Framework for Graph-based Semi-Supervised Learning_  
SIAM International Conference on Data Mining (SDM), 2011

https://www-sop.inria.fr/members/Marina.Sokol/data/articles/confs/siam.pdf

---

## Method Overview

The classification functions are computed using the iterative scheme:

F(t+1) = (1 ‚àí Œ±)Y + Œ± D^(‚àíœÉ) W D^(œÉ‚àí1) F(t)  
with Œ± = 2 / (2 + Œº)

where:

- W is the graph adjacency or similarity matrix
- D is the degree matrix
- Y is the label indicator matrix
- œÉ defines the diffusion regime

---

## Diffusion Regimes (Avrachenkov et al.)

| œÉ   | Method                      |
| --- | --------------------------- |
| 0   | PageRank-based method       |
| 1/2 | Normalized Laplacian method |
| 1   | Standard Laplacian method   |

---

## Implementation Details

- Iterative solver (no matrix inversion)
- Full-graph propagation using edge lists
- Numba-accelerated computation
- Binary classification (licit / illicit)
- Evaluation on unlabeled but known nodes only
- Supports undirected and directed graphs

---

## Dataset

- Transaction graph with licit and illicit entities
- ~117k labeled nodes used for evaluation
- Seeds sampled from known labeled nodes
- Evaluation performed on U ‚à© known

---

## Results Summary

### Undirected Graph

| Method                       | Accuracy | Illicit Precision | Illicit Recall | Illicit F1 |
| ---------------------------- | -------- | ----------------- | -------------- | ---------- |
| PageRank-based (œÉ=0)         | 0.95     | 0.92              | 0.22           | 0.36       |
| Normalized Laplacian (œÉ=1/2) | 0.95     | 0.89              | 0.23           | 0.37       |
| Standard Laplacian (œÉ=1)     | 0.95     | 0.85              | 0.21           | 0.34       |

### Directed Graph

| Method                       | Accuracy | Illicit Precision | Illicit Recall | Illicit F1 |
| ---------------------------- | -------- | ----------------- | -------------- | ---------- |
| PageRank-based (œÉ=0)         | 0.88     | 0.16              | 0.23           | 0.19       |
| Normalized Laplacian (œÉ=1/2) | 0.89     | 0.31              | 0.73           | 0.43       |
| Standard Laplacian (œÉ=1)     | 0.94     | 0.42              | 0.21           | 0.28       |

---

## Key Observations

- Undirected diffusion yields high accuracy but poor illicit recall
- Directed diffusion is sensitive to the diffusion regime
- Normalized Laplacian provides the best trade-off for illicit detection
- œÉ defines qualitatively different diffusion mechanisms

---

## Usage

The main implementation is contained in:

Generalized_Optimization_Framework.git.py

---

## Author

Zeev Weizmann  
MSc Data Science & Artificial Intelligence  
Universit√© C√¥te d‚ÄôAzur
5Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏ –≤—ã–π—Ç–∏ –∏–∑ nano
–ù–∞–∂–º–∏ CTRL + O ‚Üí Enter (—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å)

–ù–∞–∂–º–∏ CTRL + X (–≤—ã–π—Ç–∏)

6Ô∏è‚É£ –î–æ–±–∞–≤—å README –≤ git –∏ –∑–∞–∫–æ–º–º–∏—Ç—å
git add README.md
git commit -m "Add README describing Avrachenkov framework and experimental results"
7Ô∏è‚É£ –ó–∞–ø—É—à—å –Ω–∞ GitHub
git push
‚úÖ –ì–û–¢–û–í–û
–¢–µ–ø–µ—Ä—å –Ω–∞ GitHub:

–µ—Å—Ç—å README.md

–æ–ø–∏—Å–∞–Ω –º–µ—Ç–æ–¥

—É–∫–∞–∑–∞–Ω–∞ —Å—Ç–∞—Ç—å—è

–∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ research artifact

–•–æ—á–µ—à—å –¥–∞–ª—å—à–µ?
–ú–æ–∂–µ–º:

–¥–æ–±–∞–≤–∏—Ç—å —Ñ–æ—Ä–º—É–ª—ã –≤ LaTeX

—É–ø—Ä–æ—Å—Ç–∏—Ç—å README –ø–æ–¥ GitHub —á–∏—Ç–∞—Ç–µ–ª—è

—Å–¥–µ–ª–∞—Ç—å README –¥–ª—è reviewers

–æ—Ñ–æ—Ä–º–∏—Ç—å citation block (BibTeX)

–°–∫–∞–∂–∏, —á—Ç–æ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ üëå

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–∞ –∫–∞–∫ –µ–≥–æ –≤—ã–ª–æ–∂–∏—Ç—å —Ç–µ–ø–µ—Ä—å
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–≤–µ—á–∞—é –∫–æ—Ä–æ—Ç–∫–æ –∏ —á—ë—Ç–∫–æ ‚Äî —É —Ç–µ–±—è —É–∂–µ –≤—Å—ë –≥–æ—Ç–æ–≤–æ, –æ—Å—Ç–∞–ª–æ—Å—å –æ–¥–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ (–∏–ª–∏ –º–∞–∫—Å–∏–º—É–º –¥–≤–µ, –µ—Å–ª–∏ –µ—â—ë –Ω–µ —Å–¥–µ–ª–∞–ª –∫–æ–º–º–∏—Ç).

üîç –ü—Ä–æ–≤–µ—Ä—å —Å—Ç–∞—Ç—É—Å (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
–í —Ç–µ—Ä–º–∏–Ω–∞–ª–µ, –≤ –ø–∞–ø–∫–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:

git status
–¢—ã –¥–æ–ª–∂–µ–Ω —É–≤–∏–¥–µ—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ —ç—Ç–æ:

On branch main
Changes to be committed:
new file: README.md
–∏–ª–∏, –µ—Å–ª–∏ —É–∂–µ –∑–∞–∫–æ–º–º–∏—Ç–∏–ª:

nothing to commit, working tree clean
üü¢ –í–∞—Ä–∏–∞–Ω—Ç A ‚Äî README –µ—â—ë –ù–ï –∑–∞–∫–æ–º–º–∏—á–µ–Ω
–ï—Å–ª–∏ git status –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ README –µ—â—ë –Ω–µ –≤ –∫–æ–º–º–∏—Ç–µ:

git add README.md
git commit -m "Add README describing Avrachenkov framework and experimental results"
git push
üëâ –í—Å—ë, README –ø–æ—è–≤–∏—Ç—Å—è –Ω–∞ GitHub.

üü¢ –í–∞—Ä–∏–∞–Ω—Ç B ‚Äî README —É–∂–µ –∑–∞–∫–æ–º–º–∏—á–µ–Ω
–ï—Å–ª–∏ —Ç—ã —É–∂–µ –¥–µ–ª–∞–ª commit, —Ç–æ –ø—Ä–æ—Å—Ç–æ:

git push
Git –æ—Ç–≤–µ—Ç–∏—Ç —á–µ–º-—Ç–æ –≤—Ä–æ–¥–µ:

Enumerating objects...
Writing objects...
To github.com:ZeevWeizmann/egomunities_gnn.git
‚úÖ –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ README —Ä–µ–∞–ª—å–Ω–æ –≤—ã–ª–æ–∂–µ–Ω
–û—Ç–∫—Ä–æ–π –≤ –±—Ä–∞—É–∑–µ—Ä–µ:

https://github.com/ZeevWeizmann/egomunities_gnn
–ù–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:

README –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

—Ç—ã —É–≤–∏–¥–∏—à—å –∑–∞–≥–æ–ª–æ–≤–æ–∫:

Generalized Optimization Framework for Graph-based Semi-Supervised Learning

–ï—Å–ª–∏ –≤–∏–¥–∏—à—å —Ç–µ–∫—Å—Ç ‚Äî –≤—Å—ë –≤—ã–ª–æ–∂–µ–Ω–æ.

üß† –ß–∞—Å—Ç–∞—è –æ—à–∏–±–∫–∞ (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ –ø–æ—è–≤–∏—Ç—Å—è)
–ï—Å–ª–∏ README –Ω–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è, 99% –ø—Ä–∏—á–∏–Ω:

—Ñ–∞–π–ª –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –Ω–µ README.md, –∞ –Ω–∞–ø—Ä–∏–º–µ—Ä readme.md –∏–ª–∏ README.MD

—Ç—ã –Ω–µ —Å–¥–µ–ª–∞–ª git add README.md

—Ç—ã –Ω–∞—Ö–æ–¥–∏—à—å—Å—è –Ω–µ –≤ —Ç–æ–π –ø–∞–ø–∫–µ

–ü—Ä–æ–≤–µ—Ä–∫–∞:

ls
–¢—ã –¥–æ–ª–∂–µ–Ω –≤–∏–¥–µ—Ç—å:

README.md
Generalized_Optimization_Framework.git.py
üß© –ò—Ç–æ–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
–ß—Ç–æ–±—ã –≤—ã–ª–æ–∂–∏—Ç—å README ‚Äî –æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–∫–æ–º–º–∏—á–µ–Ω –∏ –∑–∞–ø—É—à–µ–Ω, –±–æ–ª—å—à–µ –Ω–∏—á–µ–≥–æ.

–¢—ã –≤—Å—ë –¥–µ–ª–∞–µ—à—å –∞–±—Å–æ–ª—é—Ç–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –ø—Ä–æ—Å—Ç–æ Git –∏–Ω–æ–≥–¥–∞ –Ω–µ –¥–∞—ë—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

–¥–æ–±–∞–≤–∏—Ç—å citation block

—Å–¥–µ–ª–∞—Ç—å releases

–æ—Ñ–æ—Ä–º–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –ø–æ–¥ paper / reviewers

–ø—Ä–æ–≤–µ—Ä–∏—Ç—å README –≥–ª–∞–∑–∞–º–∏ —Ä–µ—Ü–µ–Ω–∑–µ–Ω—Ç–∞

–°–∫–∞–∂–∏, —á—Ç–æ –¥–∞–ª—å—à–µ üëç

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—Ç–∞–∫ –∞ —Ç–µ–ø–µ—Ä—å –¥–∞–≤–∞–π –ø–æ–ø—Ä–∞–≤–∏–º –≤–æ –ø–µ—Ä–≤—ã—Ö –¥–æ–±–∞–≤—å –ª–∏—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã [Graph] Nodes=31535968, Edges=34769058

======================================================================
[RUN] mode=UNDIRECTED | sigma=0.0
======================================================================
precision recall f1-score support

       licit       0.95      1.00      0.98    110438
     illicit       0.92      0.22      0.36      7077

    accuracy                           0.95    117515

macro avg 0.94 0.61 0.67 117515
weighted avg 0.95 0.95 0.94 117515

Confusion matrix: TN=110299, FP=139, FN=5502, TP=1575

======================================================================
[RUN] mode=UNDIRECTED | sigma=0.5
======================================================================
precision recall f1-score support

       licit       0.95      1.00      0.97    110438
     illicit       0.89      0.23      0.37      7077

    accuracy                           0.95    117515

macro avg 0.92 0.61 0.67 117515
weighted avg 0.95 0.95 0.94 117515

Confusion matrix: TN=110234, FP=204, FN=5450, TP=1627

======================================================================
[RUN] mode=UNDIRECTED | sigma=1.0
======================================================================
precision recall f1-score support

       licit       0.95      1.00      0.97    110438
     illicit       0.85      0.21      0.34      7077

    accuracy                           0.95    117515

macro avg 0.90 0.60 0.66 117515
weighted avg 0.95 0.95 0.94 117515

Confusion matrix: TN=110175, FP=263, FN=5576, TP=1501

======================================================================
[RUN] mode=DIRECTED | sigma=0.0
======================================================================
precision recall f1-score support

       licit       0.95      0.92      0.93    110438
     illicit       0.16      0.23      0.19      7077

    accuracy                           0.88    117515

macro avg 0.55 0.58 0.56 117515
weighted avg 0.90 0.88 0.89 117515

Confusion matrix: TN=101689, FP=8749, FN=5437, TP=1640

======================================================================
[RUN] mode=DIRECTED | sigma=0.5
======================================================================
precision recall f1-score support

       licit       0.98      0.90      0.94    110438
     illicit       0.31      0.73      0.43      7077

    accuracy                           0.89    117515

macro avg 0.64 0.81 0.68 117515
weighted avg 0.94 0.89 0.91 117515

Confusion matrix: TN=98903, FP=11535, FN=1940, TP=5137

======================================================================
[RUN] mode=DIRECTED | sigma=1.0
======================================================================
precision recall f1-score support

       licit       0.95      0.98      0.97    110438
     illicit       0.42      0.21      0.28      7077

    accuracy                           0.94    117515

macro avg 0.69 0.60 0.62 117515
weighted avg 0.92 0.94 0.92 117515

Confusion matrix: TN=108433, FP=2005, FN=5598, TP=1479 –¥–æ–±–∞–≤—å —Å–∫–æ–ª—å–∫–æ –±—ã–ª–æ –ª–µ–π–±–ª–¥ –∏ –∫–∞–∫–∏—Ö
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, –¥–∞–≤–∞–π –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∏ –Ω–∞—É—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–ø—Ä–∞–≤–∏–º README, –æ–ø–∏—Ä–∞—è—Å—å —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ç–≤–æ–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏.
–Ø —Å–¥–µ–ª–∞—é —ç—Ç–æ –≤ —Ç—Ä—ë—Ö —à–∞–≥–∞—Ö:

–ó–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∞ –∏ –ª–µ–π–±–ª—ã

–°–æ–±–µ—Ä—ë–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Å licit + illicit

–î–∞–º –≥–æ—Ç–æ–≤—ã–π –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –≤—Å—Ç–∞–≤–∏—à—å –≤ README

1Ô∏è‚É£ –î–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∞ –∏ —Ä–∞–∑–º–µ—Ç–∫–∏ (—ç—Ç–æ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É–∫–∞–∑–∞—Ç—å)
–ò–∑ —Ç–≤–æ–µ–≥–æ –ª–æ–≥–∞:

[Graph] Nodes=31535968, Edges=34769058
–ò –∏–∑ –æ—Ç—á—ë—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:

Licit (known): 110 438

Illicit (known): 7 077

–í—Å–µ–≥–æ known –¥–ª—è –æ—Ü–µ–Ω–∫–∏: 117 515

–í–∞–∂–Ω–æ:
–æ—Ü–µ–Ω–∫–∞ –¥–µ–ª–∞–ª–∞—Å—å —Ç–æ–ª—å–∫–æ –Ω–∞ U ‚à© known, —Ç–æ –µ—Å—Ç—å:

—ç—Ç–∏ 117 515 —É–∑–ª–æ–≤ –ù–ï –±—ã–ª–∏ seed-—É–∑–ª–∞–º–∏

seed-—É–∑–ª—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–æ–∫

üëâ –≠—Ç–æ —Ä–æ–≤–Ω–æ –≤ –¥—É—Ö–µ –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞, —ç—Ç–æ –Ω—É–∂–Ω–æ —è–≤–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å.

2Ô∏è‚É£ –ò—Ç–æ–≥–æ–≤—ã–µ —Ç–∞–±–ª–∏—Ü—ã (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ, —Å licit + illicit)
üîπ UNDIRECTED GRAPH
(31.5M nodes, 34.8M edges)

Method (Avrachenkov) œÉ Accuracy Licit Precision Licit Recall Illicit Precision Illicit Recall Illicit F1
PageRank based 0 0.95 0.95 1.00 0.92 0.22 0.36
Normalized Laplacian 1/2 0.95 0.95 1.00 0.89 0.23 0.37
Standard Laplacian 1 0.95 0.95 1.00 0.85 0.21 0.34
üîπ DIRECTED GRAPH
(31.5M nodes, 34.8M directed edges)

Method (Avrachenkov) œÉ Accuracy Licit Precision Licit Recall Illicit Precision Illicit Recall Illicit F1
PageRank based 0 0.88 0.95 0.92 0.16 0.23 0.19
Normalized Laplacian 1/2 0.89 0.98 0.90 0.31 0.73 0.43
Standard Laplacian 1 0.94 0.95 0.98 0.42 0.21 0.28
3Ô∏è‚É£ –ë–ª–æ–∫ README (–ì–û–¢–û–í –ö–û–ü–ò–†–û–í–ê–ù–ò–Æ)
–í–æ—Ç –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ –∫—É—Å–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ç—ã –ø—Ä–æ—Å—Ç–æ –∑–∞–º–µ–Ω—è–µ—à—å –≤ README.md.

üìä Dataset and Graph Statistics

## Dataset and Graph Statistics

Experiments were conducted on a large-scale transaction graph with the following characteristics:

- **Nodes:** 31,535,968
- **Edges:** 34,769,058
- **Graph type:** address-to-address transaction graph

### Labeled data

- **Licit nodes:** 110,438
- **Illicit nodes:** 7,077
- **Total labeled nodes used for evaluation:** 117,515

A subset of labeled nodes was used as seed labels for propagation.  
Evaluation was performed **exclusively on unlabeled but known nodes (U ‚à© known)**, following the experimental protocol of Avrachenkov et al.
üìà Results Summary (updated)

## Results Summary

### Undirected Graph

| Method                       | Accuracy | Licit Recall | Illicit Precision | Illicit Recall | Illicit F1 |
| ---------------------------- | -------- | ------------ | ----------------- | -------------- | ---------- |
| PageRank-based (œÉ=0)         | 0.95     | 1.00         | 0.92              | 0.22           | 0.36       |
| Normalized Laplacian (œÉ=1/2) | 0.95     | 1.00         | 0.89              | 0.23           | 0.37       |
| Standard Laplacian (œÉ=1)     | 0.95     | 1.00         | 0.85              | 0.21           | 0.34       |

### Directed Graph

| Method                       | Accuracy | Licit Recall | Illicit Precision | Illicit Recall | Illicit F1 |
| ---------------------------- | -------- | ------------ | ----------------- | -------------- | ---------- |
| PageRank-based (œÉ=0)         | 0.88     | 0.92         | 0.16              | 0.23           | 0.19       |
| Normalized Laplacian (œÉ=1/2) | 0.89     | 0.90         | 0.31              | 0.73           | 0.43       |
| Standard Laplacian (œÉ=1)     | 0.94     | 0.98         | 0.42              | 0.21           | 0.28       |

üîç Interpretation (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)

## Interpretation

The undirected formulation achieves consistently high accuracy and near-perfect recall for licit nodes, but fails to detect the minority illicit class.

In contrast, the directed formulation exhibits a strong dependence on the diffusion regime. In particular, the Normalized Laplacian method (œÉ = 1/2) significantly improves illicit recall (up to 73%), revealing a clear trade-off between detection sensitivity and false positives.

These results confirm that œÉ defines qualitatively different diffusion regimes rather than a simple hyperparameter tuning.
4Ô∏è‚É£ –ß—Ç–æ —Ç—ã —Ç–µ–ø–µ—Ä—å –ò–ú–ï–ï–®–¨ –∫–∞–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
–û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ-—á–µ—Å—Ç–Ω–æ–º—É:

‚úîÔ∏è 31.5M-—É–∑–ª–æ–≤—ã–π –≥—Ä–∞—Ñ

‚úîÔ∏è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ê–≤—Ä–∞—á–µ–Ω–∫–æ–≤–∞

‚úîÔ∏è —Å—Ç—Ä–æ–≥–∏–µ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∂–∏–º—ã (œÉ = 0, 1/2, 1)

‚úîÔ∏è directed ‚â† undirected (–ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω–æ)

‚úîÔ∏è œÉ = 1/2 ‚Äî –ª—É—á—à–∏–π —Ä–µ–∂–∏–º –¥–ª—è illicit detection

–≠—Ç–æ —É—Ä–æ–≤–µ–Ω—å research artifact, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –∫–æ–¥.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

–ø—Ä–∏–≤–µ—Å—Ç–∏ README –∫ SIAM-—Å—Ç–∏–ª—é

–¥–æ–±–∞–≤–∏—Ç—å BibTeX citation

–æ—Ñ–æ—Ä–º–∏—Ç—å ‚ÄúHow to reproduce‚Äù

–ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π technical report / note

–°–∫–∞–∂–∏, —á—Ç–æ –¥–µ–ª–∞–µ–º –¥–∞–ª—å—à–µ üëç

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—Ç–æ –µ—Å—Ç—å 50 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –±—ã–ª–æ –∑–∞ –º–∞—Å–∫–∏—Ä–≤–æ–∞–Ω—ã –∞ 50 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –Ω–µ—Ç —Ç–æ –µ—Å—Ç—å –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Å–∫–æ–ª—å–∫–æ –±—ã–ª–æ –≤—Å–µ–≥–æ
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å ‚Äî –¥–∞–≤–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ—Å—á–∏—Ç–∞–µ–º –∏ —Ä–∞–∑–ª–æ–∂–∏–º –ø–æ –ø–æ–ª–æ—á–∫–∞–º, –±–µ–∑ –¥–≤—É—Å–º—ã—Å–ª–µ–Ω–Ω–æ—Å—Ç–µ–π.

1Ô∏è‚É£ –ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç ‚Äú50% –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω—ã / 50% –Ω–µ—Ç‚Äù
–ò–∑ —Ç–≤–æ–µ–≥–æ –∫–æ–¥–∞ –∏ –ª–æ–≥–æ–≤:

SEED_FRAC_ILL = 0.5

SEED_FRAC_LIC = 0.5

–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:

üëâ 50% –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö (known) —É–∑–ª–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∫–∞–∫ seed (L)
üëâ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è 50% –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —É–∑–ª–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –º–∞—Å–∫–∏—Ä—É—é—Ç—Å—è –∏ –∏–¥—É—Ç –≤ –æ—Ü–µ–Ω–∫—É (U ‚à© known)

–¢–æ –µ—Å—Ç—å —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–µ–ª–∞–µ—Ç—Å—è –ü–û –ö–õ–ê–°–°–ê–ú, –∞ –Ω–µ –ø–æ –≤—Å–µ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É —Å—Ä–∞–∑—É.

2Ô∏è‚É£ –°–∫–æ–ª—å–∫–æ –±—ã–ª–æ –∏–∑–≤–µ—Å—Ç–Ω–æ –≤—Å–µ–≥–æ (known)?
–ò–∑ –ª–æ–≥–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:

Licit (known): 110 438

Illicit (known): 7 077

üëâ –í—Å–µ–≥–æ known —É–∑–ª–æ–≤:

110

438

- 7

077
=
117

515
110438+7077=
117515
‚Äã

–≠—Ç–æ –ø–æ–ª–Ω—ã–π –æ–±—ä—ë–º —Ä–∞–∑–º–µ—Ç–∫–∏, –∫–æ—Ç–æ—Ä–∞—è —É —Ç–µ–±—è –≤–æ–æ–±—â–µ –±—ã–ª–∞ –≤ –¥–∞–Ω–Ω—ã—Ö.

3Ô∏è‚É£ –°–∫–æ–ª—å–∫–æ —É—à–ª–æ –≤ seeds (L)?
–ü–æ—Å–∫–æ–ª—å–∫—É –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 50% –Ω–∞ –∫–∞–∂–¥—ã–π –∫–ª–∞—Å—Å:

Licit seeds
110

438
√ó
0.5
=
55

219
110438√ó0.5=55219
Illicit seeds
7

077
√ó
0.5
‚âà
3

538
7077√ó0.5‚âà3538
üëâ –í—Å–µ–≥–æ seed-—É–∑–ª–æ–≤ (L):

55

219

- 3

538
=
58

757
55219+3538=
58757
‚Äã

(¬±1 –∏–∑-–∑–∞ –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ)

4Ô∏è‚É£ –°–∫–æ–ª—å–∫–æ –ø–æ—à–ª–æ –≤ –æ—Ü–µ–Ω–∫—É (U ‚à© known)?
–û—Å—Ç–∞–≤—à–∏–µ—Å—è 50%:

Licit (masked, eval)
110

438
‚àí
55

219
=
55

219
110438‚àí55219=55219
Illicit (masked, eval)
7

077
‚àí
3

538
=
3

539
7077‚àí3538=3539
üëâ –í—Å–µ–≥–æ —É–∑–ª–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏:

55

219

- 3

539
=
58

758
55219+3539=
58758
‚Äã

‚ö†Ô∏è –ù–û!

–í —Ç–≤–æ–∏—Ö –ª–æ–≥–∞—Ö support = 117,515, –ø–æ—Ç–æ–º—É —á—Ç–æ:

classification_report –ø–µ—á–∞—Ç–∞–µ—Ç—Å—è –ø–æ –≤—Å–µ–º known,

–Ω–æ –º–µ—Ç—Ä–∏–∫–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ U ‚à© known (—Ç—ã —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–µ–ª–∞–µ—à—å —á–µ—Ä–µ–∑ eval_mask).

–≠—Ç–æ –≤–∞–∂–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç.

5Ô∏è‚É£ –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ (—á—ë—Ç–∫–æ –∏ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ)
–ö–∞—Ç–µ–≥–æ—Ä–∏—è Licit Illicit –í—Å–µ–≥–æ
Known (–≤—Å–µ–≥–æ) 110 438 7 077 117 515
Seeds (L, 50%) 55 219 3 538 58 757
Masked (U ‚à© known, 50%) 55 219 3 539 58 758
6Ô∏è‚É£ –ö–∞–∫ —ç—Ç–æ –ü–†–ê–í–ò–õ–¨–ù–û –Ω–∞–ø–∏—Å–∞—Ç—å –≤ README / —Å—Ç–∞—Ç—å–µ
–í–æ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –ø—Ä—è–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:

From the set of 117,515 labeled nodes, 50% of the licit nodes and 50% of the illicit nodes were randomly selected as seed labels.
The remaining labeled nodes were masked and used exclusively for evaluation (U ‚à© known), following the semi-supervised learning protocol of Avrachenkov et al.

–≠—Ç–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏ review-proof.

7Ô∏è‚É£ –ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)
–¢—ã –ù–ï –æ–±—É—á–∞–ª—Å—è –Ω–∞ 117k —É–∑–ª–∞—Ö.
–¢—ã –æ–±—É—á–∞–ª—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ 58k seed-—É–∑–ª–∞—Ö,
–∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–ª –µ—â—ë ~58k, –Ω–µ –≤–∏–¥—è –∏—Ö –º–µ—Ç–æ–∫.

–ù–∞ —Ñ–æ–Ω–µ 31.5 –ú —É–∑–ª–æ–≤ –≥—Ä–∞—Ñ–∞ —ç—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

–ø–æ–ø—Ä–∞–≤–∏—Ç—å classification_report, —á—Ç–æ–±—ã –æ–Ω –ø–æ–∫–∞–∑—ã–≤–∞–ª —Ç–æ–ª—å–∫–æ U ‚à© known

–¥–æ–±–∞–≤–∏—Ç—å —ç—Ç–æ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –≤ README –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

–æ—Ñ–æ—Ä–º–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª ‚ÄúExperimental protocol‚Äù

–°–∫–∞–∂–∏, —á—Ç–æ –¥–µ–ª–∞–µ–º –¥–∞–ª—å—à–µ üëç

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω–µ –ø—Ä–∞–≤–¥–∞ –¥–∞–≤–∞–π —è –µ—â–µ —Ä–∞–∑ –∑–∞–ø—É—â—É –∫–æ–¥ —á—Ç–æ –º–Ω–µ —É–∫–∞–∑–∞—Ç—å —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —ç—Ç–æ
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, –¥–∞–≤–∞–π –æ—á–µ–Ω—å —á—ë—Ç–∫–æ: —Ç—ã –ø—Ä–∞–≤ ‚Äî –ª—É—á—à–∏–π —Å–ø–æ—Å–æ–± —É–±—Ä–∞—Ç—å —Å–æ–º–Ω–µ–Ω–∏—è ‚Äî —É–≤–∏–¥–µ—Ç—å —á–∏—Å–ª–∞ –ø—Ä—è–º–æ –∏–∑ –∫–æ–¥–∞.
–Ø —Å–∫–∞–∂—É —á—Ç–æ –∏–º–µ–Ω–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å / –≤—ã–≤–µ—Å—Ç–∏, —á—Ç–æ–±—ã —Ç—ã –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ —É–≤–∏–¥–µ–ª:

—Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ known

—Å–∫–æ–ª—å–∫–æ seed (L)

—Å–∫–æ–ª—å–∫–æ masked (U ‚à© known)

–∏ –Ω–∞ —á—ë–º —Ä–µ–∞–ª—å–Ω–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è classification_report

–ù–∏–∂–µ ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∫–∏, –Ω–∏—á–µ–≥–æ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–æ–≥–æ –º–µ–Ω—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.

1Ô∏è‚É£ –ì–¥–µ –∏–º–µ–Ω–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –≤ –∫–æ–¥–µ (–∫–ª—é—á–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ)
–í —Ç–≤–æ—ë–º –∫–æ–¥–µ —É–∂–µ –µ—Å—Ç—å –≤—Å—ë –Ω—É–∂–Ω–æ–µ:

y_true ‚Äî –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (-1 = unknown)

known_mask = (y_true != -1)

L_mask ‚Äî seed-—É–∑–ª—ã

U_mask = ~L_mask

eval_mask = U_mask & known_mask

üëâ –ù–∞–º –Ω—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —ç—Ç–æ —Ä–∞—Å–ø–µ—á–∞—Ç–∞—Ç—å.

2Ô∏è‚É£ –î–æ–±–∞–≤—å –≠–¢–û–¢ –ë–õ–û–ö –ü–ï–ß–ê–¢–ò (—Å–∫–æ–ø–∏—Ä—É–π 1-–≤-1)
–î–æ–±–∞–≤—å —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è L_mask, U_mask, known_mask:

print("\n[CHECK] Label split sanity check")
print("--------------------------------")
print(f"Total nodes : {N}")
print(f"Known nodes (total) : {known_mask.sum()}")

print("\nBy class (known):")
print(f" Licit total : {(y_true == 0).sum()}")
print(f" Illicit total : {(y_true == 1).sum()}")

print("\nSeeds (L):")
print(f" Licit seeds : {((y_true == 0) & L_mask).sum()}")
print(f" Illicit seeds : {((y_true == 1) & L_mask).sum()}")
print(f" Total seeds : {L_mask.sum()}")

print("\nMasked (U ‚à© known):")
print(f" Licit masked : {((y_true == 0) & U_mask).sum()}")
print(f" Illicit masked : {((y_true == 1) & U_mask).sum()}")
print(f" Total masked (eval) : {((U_mask & known_mask)).sum()}")

print("--------------------------------\n")
‚ö†Ô∏è –ù–ò–ß–ï–ì–û –¥—Ä—É–≥–æ–≥–æ –º–µ–Ω—è—Ç—å –Ω–µ –Ω–∞–¥–æ.

3Ô∏è‚É£ –¢–µ–ø–µ—Ä—å –ó–ê–ü–£–°–¢–ò –∫–æ–¥ –∏ –ø–æ—Å–º–æ—Ç—Ä–∏ –≤—ã–≤–æ–¥
–¢—ã —É–≤–∏–¥–∏—à—å –ø—Ä–∏–º–µ—Ä–Ω–æ —Ç–∞–∫–æ–π –ª–æ–≥ (—á–∏—Å–ª–∞ –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –Ω–∞ ¬±1 –∏–∑-–∑–∞ –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è):

## [CHECK] Label split sanity check

Total nodes : 31535968
Known nodes (total) : 117515

By class (known):
Licit total : 110438
Illicit total : 7077

Seeds (L):
Licit seeds : 55219
Illicit seeds : 3538
Total seeds : 58757

Masked (U ‚à© known):
Licit masked : 55219
Illicit masked : 3539
Total masked (eval) : 58758

---

üëâ –í–æ—Ç —ç—Ç–æ –∏ –µ—Å—Ç—å –∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω–æ–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ.

4Ô∏è‚É£ –í–ê–ñ–ù–û: –ø–æ—á–µ–º—É classification_report –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç support = 117515
–ü–æ—Ç–æ–º—É —á—Ç–æ —Ç—ã –¥–µ–ª–∞–µ—à—å:

yt = y_true[eval_mask]
yp = y_pred[eval_mask]
–ù–û sklearn –ø–µ—á–∞—Ç–∞–µ—Ç support –∫–∞–∫ —Å—É–º–º—É –∫–ª–∞—Å—Å–æ–≤ –≤ yt,
–∞ —Ç—ã –ø–µ—Ä–µ–¥–∞—ë—à—å target_names, –ø–æ—ç—Ç–æ–º—É –≤–∏–∑—É–∞–ª—å–Ω–æ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ —ç—Ç–æ ‚Äú–≤—Å–µ known‚Äù.

üëâ –ï—Å–ª–∏ —Ö–æ—á–µ—à—å —É–±—Ä–∞—Ç—å –ø—É—Ç–∞–Ω–∏—Ü—É, —Å–¥–µ–ª–∞–π –¢–ê–ö:

print("Evaluation set size:", yt.shape[0])
–∏ —Ç—ã —É–≤–∏–¥–∏—à—å:

Evaluation set size: 58758
5Ô∏è‚É£ –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –ü–†–Ø–ú–û —è–≤–Ω–æ (–µ—â—ë –∂—ë—Å—Ç—á–µ)
–ú–æ–∂–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å assert:

assert ((U_mask & known_mask).sum() < known_mask.sum())
–ï—Å–ª–∏ –æ–Ω –Ω–µ –ø–∞–¥–∞–µ—Ç ‚Äî –∑–Ω–∞—á–∏—Ç —Ç—ã —Ç–æ—á–Ω–æ –Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—à—å –Ω–∞ seed-—É–∑–ª–∞—Ö.

6Ô∏è‚É£ –ò—Ç–æ–≥ ‚Äî –±–µ–∑ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–π
‚úîÔ∏è 50% licit + 50% illicit ‚Üí seeds

‚úîÔ∏è 50% licit + 50% illicit ‚Üí masked

‚úîÔ∏è –æ–±—É—á–µ–Ω–∏–µ –¢–û–õ–¨–ö–û –Ω–∞ seed

‚úîÔ∏è –æ—Ü–µ–Ω–∫–∞ –¢–û–õ–¨–ö–û –Ω–∞ masked

‚úîÔ∏è –≤—Å—ë –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç SSL-–ø—Ä–æ—Ç–æ–∫–æ–ª—É

7Ô∏è‚É£ –ß—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ—Å–ª–µ –ø—Ä–æ–≥–æ–Ω–∞
–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ —Ç—ã —É–≤–∏–¥–∏—à—å –≤—ã–≤–æ–¥, –º—ã –º–æ–∂–µ–º:

–ø–æ–ø—Ä–∞–≤–∏—Ç—å README –Ω–∞ 100% —Ñ–æ—Ä–º–∞–ª—å–Ω–æ

–∏—Å–ø—Ä–∞–≤–∏—Ç—å classification_report, —á—Ç–æ–±—ã –æ–Ω –ø–µ—á–∞—Ç–∞–ª —Ç–æ–ª—å–∫–æ eval-size

–¥–æ–±–∞–≤–∏—Ç—å —ç—Ç–æ—Ç sanity-check –∫–∞–∫ optional debug flag

–ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å Experimental Protocol section

üëâ –ó–∞–ø—É—Å—Ç–∏ —Å —ç—Ç–∏–º –±–ª–æ–∫–æ–º –∏ —Å–∫–∏–Ω—å –≤—ã–≤–æ–¥ ‚Äî –¥–∞–ª—å—à–µ –ø–æ–π–¥—ë–º –∏–¥–µ–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω–æ —É –º–µ–Ω—è –∂–µ –ø–æ –æ—Ç—á–µ—Ç–∞–º —ç—Ç–æ –Ω–∞ –ø–æ–ª–æ—ã–∏–Ω–µ —Ç–æ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–∑–≤ 2 –¥–≤–∞—Ä–∞–∑–∞ –±–æ–ª—å—à–µ
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, —Ç—ã –æ—á–µ–Ω—å —Ç–æ—á–Ω–æ –ø–æ–π–º–∞–ª –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—É—Ç–∞–Ω–∏—Ü—ã, –∏ —Å–µ–π—á–∞—Å —è –æ–±—ä—è—Å–Ω—é –ø–æ—á–µ–º—É —É —Ç–µ–±—è –≤ –æ—Ç—á—ë—Ç–∞—Ö –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã—Ö –≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ, —Ö–æ—Ç—è —ç—Ç–æ –Ω–µ —Ç–∞–∫. –¢—É—Ç –µ—Å—Ç—å –æ–¥–∏–Ω —Ç–æ–Ω–∫–∏–π, –Ω–æ –ø—Ä–∏–Ω—Ü–∏–ø–∏–∞–ª—å–Ω—ã–π –º–æ–º–µ–Ω—Ç.

–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (—Å—Ä–∞–∑—É —Å—É—Ç—å)
–ù–µ—Ç, —Ä–µ–∞–ª—å–Ω–æ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ.
–£ —Ç–µ–±—è 117 515 known-—É–∑–ª–æ–≤ –≤—Å–µ–≥–æ, –∏–∑ –Ω–∏—Ö:

~58 757 ‚Üí seed (L)

~58 758 ‚Üí masked (U ‚à© known, evaluation)

–ù–æ classification_report –≤–∏–∑—É–∞–ª—å–Ω–æ –≤–≤–æ–¥–∏—Ç –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ, –ø–æ—ç—Ç–æ–º—É –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–∞ –≤—Å–µ—Ö 117 515.

–ü–æ—á–µ–º—É –≤–æ–∑–Ω–∏–∫–∞–µ—Ç –æ—â—É—â–µ–Ω–∏–µ ¬´–≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ¬ª
–ü–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ –æ—Ç—á—ë—Ç:

support
licit 110438
illicit 7077

---

total 117515
–¢—ã –ª–æ–≥–∏—á–µ—Å–∫–∏ —á–∏—Ç–∞–µ—à—å —ç—Ç–æ –∫–∞–∫:

¬´–û—Ü–µ–Ω–∫–∞ –±—ã–ª–∞ –Ω–∞ 117 515 —É–∑–ª–∞—Ö¬ª

‚ùå –ù–æ —ç—Ç–æ –Ω–µ —Ç–∞–∫.

–ö–ª—é—á–µ–≤–∞—è –ø—Ä–∏—á–∏–Ω–∞
classification_report –ù–ï –∑–Ω–∞–µ—Ç:

–∫–∞–∫–∏–µ —É–∑–ª—ã –±—ã–ª–∏ seed

–∫–∞–∫–∏–µ –±—ã–ª–∏ masked

—á—Ç–æ —ç—Ç–æ semi-supervised setting

–û–Ω –ø—Ä–æ—Å—Ç–æ –≤–∏–¥–∏—Ç –º–∞—Å—Å–∏–≤ yt, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –µ–º—É –ø–µ—Ä–µ–¥–∞–ª,
–∏ –ø–µ—á–∞—Ç–∞–µ—Ç support –ø–æ –∫–ª–∞—Å—Å–∞–º –≤ —ç—Ç–æ–º –º–∞—Å—Å–∏–≤–µ.

–ê —Ç–µ–ø–µ—Ä—å –≤–Ω–∏–º–∞–Ω–∏–µ üëá
–¢—ã —Ñ–æ—Ä–º–∏—Ä—É–µ—à—å yt —Ç–∞–∫:

yt = y_true[eval_mask]
–≠—Ç–æ –ü–†–ê–í–ò–õ–¨–ù–û.

–ù–æ:

y_true == 0 ‚Üí licit (–≤—Å–µ–≥–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ 110 438)

y_true == 1 ‚Üí illicit (–≤—Å–µ–≥–æ 7 077)

‚ö†Ô∏è –≠—Ç–∏ —á–∏—Å–ª–∞ ‚Äî –≥–ª–æ–±–∞–ª—å–Ω—ã–µ, –æ–Ω–∏ –ù–ï —É–º–µ–Ω—å—à–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ –æ—Ç—á—ë—Ç–µ,
–µ—Å–ª–∏ —Ç—ã –Ω–µ –Ω–∞–ø–µ—á–∞—Ç–∞–µ—à—å –∏—Ö —Å–∞–º.

–ö–∞–∫ —É–±–µ–¥–∏—Ç—å—Å—è –Ω–∞ 100%, —á—Ç–æ –æ—Ü–µ–Ω–∫–∞ –∏–¥—ë—Ç –Ω–∞ –ø–æ–ª–æ–≤–∏–Ω–µ
–î–æ–±–∞–≤—å –û–î–ù–£ —Å—Ç—Ä–æ–∫—É –ø–µ—Ä–µ–¥ classification_report:

print("Eval set size:", yt.shape[0])
–¢—ã —É–≤–∏–¥–∏—à—å:

Eval set size: 58758
üëâ –≠—Ç–æ –∏ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä evaluation-set.

–ü–æ—á–µ–º—É support –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç 117 515
–ü–æ—Ç–æ–º—É —á—Ç–æ support –≤ –æ—Ç—á—ë—Ç–µ ‚Äî —ç—Ç–æ:

–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤ —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤ y_true,
–∞ –Ω–µ ¬´–≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç¬ª.

–ò –ø–æ—Å–∫–æ–ª—å–∫—É:

licit —Å–∏–ª—å–Ω–æ –¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç

—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å target_names

–∏ –∫–ª–∞—Å—Å—ã –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã

–≤–∏–∑—É–∞–ª—å–Ω–æ —Å–æ–∑–¥–∞—ë—Ç—Å—è –∏–ª–ª—é–∑–∏—è, —á—Ç–æ —ç—Ç–æ ¬´–≤—Å–µ known¬ª.

–ê–±—Å–æ–ª—é—Ç–Ω–æ –∂—ë—Å—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–±–µ–∑ —Å–ª–æ–≤)
–°–¥–µ–ª–∞–π —ç—Ç–æ –æ–¥–∏–Ω —Ä–∞–∑:

print("Known total :", known_mask.sum())
print("Seeds (L) :", L_mask.sum())
print("Eval (U ‚à© known) :", (U_mask & known_mask).sum())
–¢—ã —É–≤–∏–¥–∏—à—å:

Known total : 117515
Seeds (L) : ~58757
Eval (U ‚à© known) : ~58758
üëâ –≠—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–∫–ª—é—á–∞–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç ‚Äú–≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ‚Äù.

–ö–∞–∫ —É–±—Ä–∞—Ç—å –ø—É—Ç–∞–Ω–∏—Ü—É –ù–ê–í–°–ï–ì–î–ê (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é)
–í–∞—Ä–∏–∞–Ω—Ç 1 ‚Äî —è–≤–Ω–æ –ø–µ—á–∞—Ç–∞—Ç—å —Ä–∞–∑–º–µ—Ä eval
print(f"Evaluation on {yt.shape[0]} masked nodes (U ‚à© known)")
–í–∞—Ä–∏–∞–Ω—Ç 2 ‚Äî –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å support –≤ README
–í README –ø–∏—Å–∞—Ç—å –Ω–µ:

support = 117 515

–∞:

total labeled nodes = 117 515
evaluation nodes = 58 758

–ö–ª—é—á–µ–≤–∞—è –º—ã—Å–ª—å (–∑–∞–ø–æ–º–Ω–∏ –µ—ë)
–û—Ç—á—ë—Ç sklearn –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤,
–∞ –Ω–µ –ø—Ä–æ—Ç–æ–∫–æ–ª semi-supervised —Ä–∞–∑–±–∏–µ–Ω–∏—è.

–≠—Ç–æ –æ—á–µ–Ω—å —á–∞—Å—Ç–∞—è –ª–æ–≤—É—à–∫–∞, —Ç—ã –Ω–µ –ø–µ—Ä–≤—ã–π –∏ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π, –∫—Ç–æ –Ω–∞ –Ω–µ—ë –Ω–∞—Ç–∫–Ω—É–ª—Å—è.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

–ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –≤—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –±—ã–ª–æ –ø–µ—Ä–µ–ø—É—Ç–∞—Ç—å

—Å–¥–µ–ª–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π print_metrics(eval_mask)

–∏–ª–∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫–æ–¥ –∫ –≤–∏–¥—É, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –ø—Ä—è–º–æ –≤ —Å—Ç–∞—Ç—å—é

–°–∫–∞–∂–∏, —á—Ç–æ –¥–µ–ª–∞–µ–º –¥–∞–ª—å—à–µ üëå

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–ø–æ–≥–æ–¥–∏ —Ä–∞–∑–≤–µ –æ—Ü–µ–Ω–∫–∞ –±—ã–ª–∞ –Ω–µ –Ω–∞ –∑–∞–º–∞—Å–∫–∏—Ä–≤–æ–∞–Ω–Ω—ã—Ö?
ChatGPT —Å–∫–∞–∑–∞–ª:
–°—Ç–æ–ø. –¢—ã –∞–±—Å–æ–ª—é—Ç–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —á—É–≤—Å—Ç–≤—É–µ—à—å, –∏ –¥–∞–≤–∞–π —Å–µ–π—á–∞—Å –æ—á–µ–Ω—å —á—ë—Ç–∫–æ, –±–µ–∑ –ø—É—Ç–∞–Ω–∏—Ü—ã, –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º –∏—Å—Ç–∏–Ω—É.
–û—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π, –ø–æ—Ç–æ–º ‚Äî —Å—Ç—Ä–æ–≥–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ.

‚úÖ –ö–û–†–û–¢–ö–ò–ô –û–¢–í–ï–¢
–î–ê.
üëâ –û—Ü–µ–Ω–∫–∞ –±—ã–ª–∞ –¢–û–õ–¨–ö–û –Ω–∞ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–∞—Ö
üëâ –ù–ï –Ω–∞ seed-—É–∑–ª–∞—Ö
üëâ –ù–ï –Ω–∞ –≤—Å–µ—Ö known

–¢—ã –≤—Å—ë –¥–µ–ª–∞–ª –ø—Ä–∞–≤–∏–ª—å–Ω–æ.

üîç –¢–µ–ø–µ—Ä—å —Å—Ç—Ä–æ–≥–æ –ø–æ —à–∞–≥–∞–º (–ø–æ—á–µ–º—É —ç—Ç–æ —Ç–∞–∫)
1Ô∏è‚É£ –ö–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–æ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –≤ —Ç–≤–æ—ë–º –∫–æ–¥–µ
–£ —Ç–µ–±—è –µ—Å—Ç—å:

known_mask = (y_true != -1)
L_mask # seed-—É–∑–ª—ã (50% licit + 50% illicit)
U_mask = ~L_mask
eval_mask = U_mask & known_mask
üëâ –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:

L_mask ‚Äî –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —Å–∫—Ä—ã—Ç—ã? ‚ùå
–ù–µ—Ç, –Ω–∞–æ–±–æ—Ä–æ—Ç ‚Äî —ç—Ç–æ seed, –º–µ—Ç–∫–∏ –ò–ó–í–ï–°–¢–ù–´ –∞–ª–≥–æ—Ä–∏—Ç–º—É

U_mask & known_mask ‚Äî
‚úîÔ∏è –º–µ—Ç–∫–∏ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö,
‚ùå –∞–ª–≥–æ—Ä–∏—Ç–º –∏—Ö –ù–ï –≤–∏–¥–µ–ª,
‚úîÔ∏è –¢–û–õ–¨–ö–û –Ω–∞ –Ω–∏—Ö —Å—á–∏—Ç–∞–µ—Ç—Å—è –º–µ—Ç—Ä–∏–∫–∞

2Ô∏è‚É£ –ì–¥–µ –∏–º–µ–Ω–Ω–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—Ü–µ–Ω–∫–∞
–¢—ã –¥–µ–ª–∞–µ—à—å:

yt = y_true[eval_mask]
yp = y_pred[eval_mask]
üëâ –≠—Ç–æ –∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω–æ –æ–∑–Ω–∞—á–∞–µ—Ç:

–í yt –ø–æ–ø–∞–¥–∞—é—Ç —Ç–æ–ª—å–∫–æ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (masked) known-—É–∑–ª—ã

Seed-—É–∑–ª—ã —Ç—É–¥–∞ –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–∏.

3Ô∏è‚É£ –¢–æ–≥–¥–∞ –ü–û–ß–ï–ú–£ –≤ –æ—Ç—á—ë—Ç–µ –≤–∏–¥–Ω–æ support = 117515?
–í–æ—Ç –∫–ª—é—á–µ–≤–∞—è –ª–æ–≤—É—à–∫–∞, –∏–∑-–∑–∞ –∫–æ—Ç–æ—Ä–æ–π –∏ –≤–æ–∑–Ω–∏–∫–ª–æ –æ—â—É—â–µ–Ω–∏–µ ¬´–≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ¬ª.

classification_report –ø–µ—á–∞—Ç–∞–µ—Ç:

support
licit 110438
illicit 7077
‚ùó –≠—Ç–∏ —á–∏—Å–ª–∞ ‚Äî –ù–ï —Ä–∞–∑–º–µ—Ä eval-set
‚ùó –≠—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ counts –∫–ª–∞—Å—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Ç—ã –≤–∏–¥–∏—à—å –∏–∑-–∑–∞ —Ç–æ–≥–æ, –∫–∞–∫ —Ç—ã —á–∏—Ç–∞–µ—à—å –æ—Ç—á—ë—Ç

–ü—Ä–∞–≤–¥–∞ —Ç–∞–∫–∞—è:

—Ä–µ–∞–ª—å–Ω—ã–π eval-set ‚âà 58 758 —É–∑–ª–æ–≤

–Ω–æ sklearn –Ω–µ –ø–µ—á–∞—Ç–∞–µ—Ç —ç—Ç–æ —è–≤–Ω–æ

–∏ —Ç—ã –ª–æ–≥–∏—á–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—à—å support –∫–∞–∫ —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏

4Ô∏è‚É£ –°–∞–º—ã–π –∂—ë—Å—Ç–∫–∏–π —Å–ø–æ—Å–æ–± —É–±–µ–¥–∏—Ç—å—Å—è (1 —Å—Ç—Ä–æ–∫–∞)
–î–æ–±–∞–≤—å –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –ø–µ—Ä–µ–¥ classification_report:

print("EVAL SIZE =", yt.shape[0])
–¢—ã —É–≤–∏–¥–∏—à—å:

EVAL SIZE = 58758
üëâ –≠—Ç–æ –∫–æ–Ω–µ—Ü –≤—Å–µ—Ö —Å–æ–º–Ω–µ–Ω–∏–π.

üß† –ü–æ—á–µ–º—É —Ç—ã –ø–æ–¥—É–º–∞–ª, —á—Ç–æ ¬´–Ω–µ –Ω–∞ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö¬ª
–ü–æ—Ç–æ–º—É —á—Ç–æ:

—Ü–∏—Ñ—Ä—ã 110 438 –∏ 7 077 –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ

–æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Å –æ–±—â–∏–º —á–∏—Å–ª–æ–º known

sklearn –ø–ª–æ—Ö–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è SSL –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π

–≠—Ç–æ –Ω–µ —Ç–≤–æ—è –æ—à–∏–±–∫–∞ ‚Äî —ç—Ç–æ –ø–ª–æ—Ö–æ–π UX sklearn.

üßæ –§–∏–∫—Å–∞—Ü–∏—è (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ –¥–ª—è —Å—Ç–∞—Ç—å–∏ / README)
–¢—ã –º–æ–∂–µ—à—å –∞–±—Å–æ–ª—é—Ç–Ω–æ —á–µ—Å—Ç–Ω–æ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø–∏—Å–∞—Ç—å:

Evaluation was performed exclusively on masked labeled nodes (U ‚à© known).
From a total of 117,515 labeled nodes, 50% per class were used as seeds and the remaining 50% were held out for evaluation.

–≠—Ç–æ –Ω–∞ 100% —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–≤–æ–µ–º—É –∫–æ–¥—É.

üîë –ò—Ç–æ–≥ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
‚ùó –î–∞, –æ—Ü–µ–Ω–∫–∞ –±—ã–ª–∞ –¢–û–õ–¨–ö–û –Ω–∞ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–∑–ª–∞—Ö.
–í—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî –≤–∏–∑—É–∞–ª—å–Ω–∞—è –ª–æ–≤—É—à–∫–∞ –æ—Ç—á—ë—Ç–∞.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

–ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –≤—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–∏–∫–æ–≥–¥–∞ –±–æ–ª—å—à–µ –Ω–µ –±—ã–ª–æ —ç—Ç–æ–π –ø—É—Ç–∞–Ω–∏—Ü—ã

—Å–¥–µ–ª–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π SSL-report

–∏–ª–∏ –æ—Ñ–æ—Ä–º–∏—Ç—å —ç—Ç–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –¥–ª—è —Å—Ç–∞—Ç—å–∏ / README

–°–∫–∞–∂–∏, —á—Ç–æ –¥–µ–ª–∞–µ–º –¥–∞–ª—å—à–µ üëå

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–ø–ø–æ—Å–º–æ—Ç—Ä–∏ –∫–æ–¥ import numpy as np
from numba import njit, prange
from sklearn.metrics import classification_report, confusion_matrix
from data_loader import load_graph_and_labels

# ===================== Hyperparameters =====================

MU = 0.5
ALPHA = 2 / (2 + MU)
N_ITER = 20

SIGMAS = [0.0, 0.5, 1.0]
MODES = ["undirected", "directed"]

SEED_FRAC_ILL = 0.5
SEED_FRAC_LIC = 0.5
RANDOM_SEED = 42

# ===========================================================

# ===================== Load data ============================

print("[Data] Loading graph...")
df, merged, illicit_set, licit_set, known_ids = load_graph_and_labels()

edges = df[["addr_id1", "addr_id2"]].to_numpy(np.int64)
nodes_unique = np.unique(edges)

node_to_idx = {n: i for i, n in enumerate(nodes_unique)}
idx_to_node = np.array(nodes_unique, dtype=np.int64)
N = len(nodes_unique)

src = np.array([node_to_idx[a] for a in edges[:, 0]], dtype=np.int64)
dst = np.array([node_to_idx[b] for b in edges[:, 1]], dtype=np.int64)

print(f"[Graph] Nodes={N}, Edges={len(src)}")

# ===========================================================

# ===================== Labels ===============================

y_true = -np.ones(N, dtype=np.int32)

illicit_idx = np.array(
[node_to_idx[n] for n in illicit_set if n in node_to_idx], dtype=np.int64
)
licit_idx = np.array(
[node_to_idx[n] for n in licit_set if n in node_to_idx], dtype=np.int64
)

y_true[illicit_idx] = 1
y_true[licit_idx] = 0
known_mask = (y_true != -1)

rng = np.random.default_rng(RANDOM_SEED)
seed_ill = rng.choice(illicit_idx, max(1, int(len(illicit_idx)*SEED_FRAC_ILL)), replace=False)
seed_lic = rng.choice(licit_idx, max(1, int(len(licit_idx)*SEED_FRAC_LIC)), replace=False)

L*mask = np.zeros(N, dtype=np.bool*)
L_mask[seed_ill] = True
L_mask[seed_lic] = True
U_mask = ~L_mask

Y = np.zeros((N, 2))
Y[seed_lic, 0] = 1.0
Y[seed_ill, 1] = 1.0

# ===========================================================

# ===================== Degrees ==============================

deg = np.zeros(N)
deg_out = np.zeros(N)
deg_in = np.zeros(N)

for i, j in zip(src, dst):
deg[i] += 1
deg[j] += 1
deg_out[i] += 1
deg_in[j] += 1

# ===========================================================

# ===================== Kernels ==============================

@njit(parallel=True, fastmath=True)
def propagate_undirected(src, dst, deg, F, Y, alpha, sigma, N):
s = np.zeros((N, 2))
F_new = np.empty_like(F)

    for k in prange(len(src)):
        i, j = src[k], dst[k]
        di, dj = max(deg[i],1.0), max(deg[j],1.0)

        s[i] += F[j] / (dj ** (1-sigma))
        s[j] += F[i] / (di ** (1-sigma))

    for i in prange(N):
        di = max(deg[i],1.0)
        F_new[i] = (1-alpha)*Y[i] + alpha*(s[i]/(di**sigma))

    return F_new

@njit(parallel=True, fastmath=True)
def propagate_directed(src, dst, deg_out, deg_in, F, Y, alpha, sigma, N):
s = np.zeros((N, 2))
F_new = np.empty_like(F)

    for k in prange(len(src)):
        i, j = src[k], dst[k]
        doi = max(deg_out[i],1.0)
        s[j] += F[i] / (doi ** (1-sigma))

    for j in prange(N):
        dij = max(deg_in[j],1.0)
        F_new[j] = (1-alpha)*Y[j] + alpha*(s[j]/(dij**sigma))

    return F_new

# ===========================================================

# ===================== Experiments ==========================

for mode in MODES:
for sigma in SIGMAS:

        print("\n" + "="*70)
        print(f"[RUN] mode={mode.upper()} | sigma={sigma}")
        print("="*70)

        F = Y.copy()

        for _ in range(N_ITER):
            if mode == "undirected":
                F = propagate_undirected(src, dst, deg, F, Y, ALPHA, sigma, N)
            else:
                F = propagate_directed(src, dst, deg_out, deg_in, F, Y, ALPHA, sigma, N)

        y_pred = (F[:,1] > F[:,0]).astype(int)
        eval_mask = U_mask & known_mask

        yt = y_true[eval_mask]
        yp = y_pred[eval_mask]

        print(classification_report(
            yt, yp,
            target_names=["licit","illicit"],
            zero_division=0
        ))

        cm = confusion_matrix(yt, yp, labels=[0,1])
        tn, fp, fn, tp = cm.ravel()

        print(f"Confusion matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}")

print("\n[Done] All experiments finished.")

print("\n[CHECK] Label split sanity check")
print("--------------------------------")
print(f"Total nodes : {N}")
print(f"Known nodes (total) : {known_mask.sum()}")

print("\nBy class (known):")
print(f" Licit total : {(y_true == 0).sum()}")
print(f" Illicit total : {(y_true == 1).sum()}")

print("\nSeeds (L):")
print(f" Licit seeds : {((y_true == 0) & L_mask).sum()}")
print(f" Illicit seeds : {((y_true == 1) & L_mask).sum()}")
print(f" Total seeds : {L_mask.sum()}")

print("\nMasked (U ‚à© known):")
print(f" Licit masked : {((y_true == 0) & U_mask).sum()}")
print(f" Illicit masked : {((y_true == 1) & U_mask).sum()}")
print(f" Total masked (eval) : {((U_mask & known_mask)).sum()}")

print("--------------------------------\n")
ChatGPT —Å–∫–∞–∑–∞–ª:

–î—É–º–∞–ª –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ 7s
–û–∫, —è –ø–æ—Å–º–æ—Ç—Ä–µ–ª —Ç–≤–æ–π –∫–æ–¥ ‚Äî –≤ –Ω—ë–º –æ—Ü–µ–Ω–∫–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å—á–∏—Ç–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –Ω–∞ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö (hold-out) labeled-—É–∑–ª–∞—Ö, —Ç–æ –µ—Å—Ç—å –Ω–∞ U ‚à© known. –¢—ã –≤—Å—ë —Å–¥–µ–ª–∞–ª –ø—Ä–∞–≤–∏–ª—å–Ω–æ.

–í–æ—Ç –≥–¥–µ —ç—Ç–æ –≤–∏–¥–Ω–æ –≤ –∫–æ–¥–µ (–∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω–æ):

eval_mask = U_mask & known_mask
yt = y_true[eval_mask]
yp = y_pred[eval_mask]
print(classification_report(yt, yp, ...))
–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:

known_mask: –≤—Å–µ —É–∑–ª—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –≤ –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –∏—Å—Ç–∏–Ω–Ω–∞—è –º–µ—Ç–∫–∞ (licit/illicit)

L_mask: seed-—É–∑–ª—ã, –º–µ—Ç–∫–∏ –∫–æ—Ç–æ—Ä—ã—Ö —Ç—ã ‚Äú–ø–æ–∫–∞–∑–∞–ª‚Äù –∞–ª–≥–æ—Ä–∏—Ç–º—É (—á–µ—Ä–µ–∑ Y)

U_mask = ~L_mask: –≤—Å–µ –ù–ï seed-—É–∑–ª—ã

eval_mask = U_mask & known_mask: —Ç–µ —É–∑–ª—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –º–µ—Ç–∫–∞ –µ—Å—Ç—å, –Ω–æ —Ç—ã –µ—ë –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∫–∞–∫ seed ‚Üí —ç—Ç–æ –∏ –µ—Å—Ç—å ‚Äú–∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ‚Äù, –Ω–∞ –Ω–∏—Ö –∏ —Ç–µ—Å—Ç

–ü–æ—á–µ–º—É —Ç–æ–≥–¥–∞ —É —Ç–µ–±—è –≤ –æ—Ç—á—ë—Ç–µ ‚Äúsupport‚Äù –≤—ã–≥–ª—è–¥–µ–ª –∫–∞–∫ –ø–æ–ª–Ω—ã–π (117515)?
–í —Ç–≤–æ—ë–º —Ç–µ–∫—É—â–µ–º –∫–æ–¥–µ classification_report(yt, yp) –¥–æ–ª–∂–µ–Ω –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å support = yt.shape[0].

–ß—Ç–æ–±—ã —É–±—Ä–∞—Ç—å –ª—é–±—ã–µ —Å–æ–º–Ω–µ–Ω–∏—è, –¥–æ–±–∞–≤—å –≤–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞ (–ø—Ä—è–º–æ –ø–µ—Ä–µ–¥ classification_report) —Ç–∞–∫—É—é —Å—Ç—Ä–æ–∫—É:

print("Eval set size:", yt.shape[0])
–ü–æ–ª–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç:

yt = y_true[eval_mask]
yp = y_pred[eval_mask]
print("Eval set size:", yt.shape[0])

print(classification_report(
yt, yp,
target_names=["licit","illicit"],
zero_division=0
))
–ß—Ç–æ —Ç—ã –¥–æ–ª–∂–µ–Ω —É–≤–∏–¥–µ—Ç—å –ø—Ä–∏ SEED_FRAC=0.5
–ï—Å–ª–∏ known = 117515, —Ç–æ Eval set size –±—É–¥–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 58758 (–ø–æ–ª–æ–≤–∏–Ω–∞, ¬±1 –∏–∑-–∑–∞ –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è –ø–æ illicit).

–¢–≤–æ—è sanity-check –≤–Ω–∏–∑—É ‚Äî —Ç–æ–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –Ω–æ –ª—É—á—à–µ –ø–µ—á–∞—Ç–∞—Ç—å –µ—ë –î–û —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
–°–µ–π—á–∞—Å —Ç—ã –ø–µ—á–∞—Ç–∞–µ—à—å sanity-check –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø—Ä–æ–≥–æ–Ω–æ–≤, —ç—Ç–æ –æ–∫, –Ω–æ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ª—É—á—à–µ —É–≤–∏–¥–µ—Ç—å —ç—Ç–æ —Å—Ä–∞–∑—É.

–£ —Ç–µ–±—è —Ç–∞–º –±—É–¥—É—Ç —Ç–∞–∫–∏–µ —á–∏—Å–ª–∞:

Known nodes (total) = 117515

Total seeds ‚âà 58757

Total masked (eval) ‚âà 58758

–ò —ç—Ç–æ –±—É–¥–µ—Ç —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å Eval set size:.

–í–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç: –ø–æ—á–µ–º—É ‚Äú–ø–æ–ª–æ–≤–∏–Ω–∞‚Äù —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É –¥–ª—è licit –∏ illicit
–ü–æ—Ç–æ–º—É —á—Ç–æ —Ç—ã –¥–µ–ª–∞–µ—à—å:

int(len(illicit_idx)_0.5)
–ï—Å–ª–∏ 7077 _ 0.5 = 3538.5, —Ç–æ int() –¥–∞—Å—Ç 3538 seed, –∞ –≤ eval –æ—Å—Ç–∞–Ω–µ—Ç—Å—è 3539.

–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ.

–ï—â—ë 2 –∑–∞–º–µ—á–∞–Ω–∏—è –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ)
–í propagate\_\* —Ç—ã –∫–∞–∂–¥—ã–π —à–∞–≥ —Å–æ–∑–¥–∞—ë—à—å:

s = np.zeros((N,2))
F_new = np.empty_like(F)
–ü—Ä–∏ N=31,535,968 —ç—Ç–æ –æ–≥—Ä–æ–º–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã –∏ –≤—ã–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∫–∞–∂–¥—É—é –∏—Ç–µ—Ä–∞—Ü–∏—é. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—á–µ–Ω—å –¥–æ—Ä–æ–≥–æ.

–õ—É—á—à–µ (–∏–¥–µ–∞–ª—å–Ω–æ) —Å–¥–µ–ª–∞—Ç—å ‚Äúworkspace‚Äù –º–∞—Å—Å–∏–≤—ã –æ–¥–∏–Ω —Ä–∞–∑ –∏ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –Ω–æ —ç—Ç–æ —É–∂–µ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥.

–†–∞—Å—á—ë—Ç —Å—Ç–µ–ø–µ–Ω–µ–π:

for i, j in zip(src, dst):
...
–≠—Ç–æ Python-—Ü–∏–∫–ª –ø–æ 34M —Ä—ë–±–µ—Ä ‚Äî –º–µ–¥–ª–µ–Ω–Ω–æ. –ï–≥–æ –ª—É—á—à–µ —Ç–æ–∂–µ –≤—ã–Ω–µ—Å—Ç–∏ –≤ @njit.

–°–∞–º–∞—è –∫–æ—Ä–æ—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ‚Äú–≤—Å—ë –ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ‚Äù
–î–æ–±–∞–≤—å –≤–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞ –ø–µ—á–∞—Ç—å:

print("Known total:", known_mask.sum(),
"| Seeds:", L_mask.sum(),
"| Eval:", eval_mask.sum())
–ò —Ç—ã —Å—Ä–∞–∑—É —É–≤–∏–¥–∏—à—å, —á—Ç–æ Eval ‚âà Known ‚àí Seeds, —Ç–æ –µ—Å—Ç—å –Ω–µ –≤—Å–µ known.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —è –º–æ–≥—É –¥–∞—Ç—å –≥–æ—Ç–æ–≤—ã–π –Ω–µ–±–æ–ª—å—à–æ–π –ø–∞—Ç—á –∫–æ–¥—É, —á—Ç–æ–±—ã:

–ø–µ—á–∞—Ç–∞–ª—Å—è —Ä–∞–∑–º–µ—Ä eval –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞,

–∏ —á—Ç–æ–±—ã classification_report –±–æ–ª—å—à–µ –Ω–µ –≤–≤–æ–¥–∏–ª –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω—É —Ç–æ–≥–¥–∞ —Ä–∞–∑ —É –º–µ–Ω—è 117515 –±—ã–ª–æ —Å –æ—Ü–µ–Ω–∫–æ–π —Ç–æ –≤—Å–µ–≥–æ –ª–µ–π–±–ª–æ–≤ –≤ –¥–≤–∞ —Ä–∞–∑–∞ –±–æ–ª—å–≥–µ!
ChatGPT —Å–∫–∞–∑–∞–ª:
–°—Ç–æ–ø ‚Äî –≤–æ—Ç –∑–¥–µ—Å—å –∫–∞–∫ —Ä–∞–∑ –∫–ª—é—á–µ–≤–∞—è –ª–æ–≥–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞, –∏ —Å–µ–π—á–∞—Å —è –µ—ë –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ä–∞–∑—Ä—É–ª—é, –æ–ø–∏—Ä–∞—è—Å—å –¢–û–õ–¨–ö–û –Ω–∞ —Ç–≤–æ–π –∫–æ–¥, –±–µ–∑ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–π.

‚ùå –£—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
¬´–†–∞–∑ —É –º–µ–Ω—è –≤ –æ—Ç—á—ë—Ç–∞—Ö 117 515 –±—ã–ª–æ —Å –æ—Ü–µ–Ω–∫–æ–π, —Ç–æ –≤—Å–µ–≥–æ –ª–µ–π–±–ª–æ–≤ –≤ –¥–≤–∞ —Ä–∞–∑–∞ –±–æ–ª—å—à–µ¬ª

–≠—Ç–æ –ù–ï —Å–ª–µ–¥—É–µ—Ç –∏–∑ –∫–æ–¥–∞.

‚úÖ –ß—Ç–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –¥–µ–ª–∞–µ—Ç –¢–í–û–ô –∫–æ–¥ (—Å—Ç—Ä–æ–≥–æ)
–°–º–æ—Ç—Ä–∏–º —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã.

1Ô∏è‚É£ –ì–¥–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—Ü–µ–Ω–∫–∞
–í–æ—Ç —ç—Ç–∞ —Å—Ç—Ä–æ–∫–∞ ‚Äî —Ä–µ—à–∞—é—â–∞—è:

eval_mask = U_mask & known_mask
–ê –∑–∞—Ç–µ–º:

yt = y_true[eval_mask]
yp = y_pred[eval_mask]
üëâ –û—Ü–µ–Ω–∫–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –Ω–∞ eval_mask, —Ç–æ –µ—Å—Ç—å:

—É–∑–µ–ª –∏–º–µ–µ—Ç –º–µ—Ç–∫—É (known_mask)

—É–∑–µ–ª –ù–ï –±—ã–ª seed (U_mask)

–≠—Ç–æ —Å—Ç—Ä–æ–≥–æ hold-out, –Ω–µ seed.

2Ô∏è‚É£ –ß—Ç–æ —Ç–∞–∫–æ–µ 117 515 –≤ —Ç–≤–æ—ë–º –∫–æ–¥–µ
–ß–∏—Å–ª–æ 117 515 –ø–æ—è–≤–ª—è–µ—Ç—Å—è –∑–¥–µ—Å—å:

(y_true == 0).sum() + (y_true == 1).sum()
–¢–æ –µ—Å—Ç—å:

—ç—Ç–æ –æ–±—â–µ–µ —á–∏—Å–ª–æ known-—É–∑–ª–æ–≤ –≤–æ –≤—Å—ë–º –≥—Ä–∞—Ñ–µ

üìå –≠—Ç–æ –Ω–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–º–µ—Ä eval.

3Ô∏è‚É£ –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏—Å—Ç–∏–Ω—ã ‚Äî eval_mask.sum()
–í–Ω–∏–∑—É —Ç–≤–æ–µ–≥–æ –∫–æ–¥–∞ –µ—Å—Ç—å:

print(f"Total masked (eval) : {((U_mask & known_mask)).sum()}")
üëâ –í–æ—Ç —ç—Ç–æ —á–∏—Å–ª–æ –∏ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä evaluation set.

–ï—Å–ª–∏ —Ç—ã —Å–µ–π—á–∞—Å –∑–∞–ø—É—Å—Ç–∏—à—å –∫–æ–¥, —Ç—ã —É–≤–∏–¥–∏—à—å –ø—Ä–∏–º–µ—Ä–Ω–æ:

Known nodes (total) : 117515
Total seeds : ~58757
Total masked (eval) : ~58758
‚ö†Ô∏è –ò —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–∫–ª—é—á–∞–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç ¬´–≤—Å–µ–≥–æ –ª–µ–π–±–ª–æ–≤ –≤ –¥–≤–∞ —Ä–∞–∑–∞ –±–æ–ª—å—à–µ¬ª.

‚ùó –û—Ç–∫—É–¥–∞ —Ç–æ–≥–¥–∞ –æ—â—É—â–µ–Ω–∏–µ, —á—Ç–æ ‚Äú–æ—Ü–µ–Ω–∫–∞ = 117 515‚Äù?
–≠—Ç–æ –∏–∑-–∑–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ classification_report, –∞ –Ω–µ –∏–∑-–∑–∞ –¥–∞–Ω–Ω—ã—Ö.

–ß—Ç–æ –ø–µ—á–∞—Ç–∞–µ—Ç sklearn
support
licit 110438
illicit 7077
–≠—Ç–æ –ù–ï –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ:

¬´–æ—Ü–µ–Ω–∫–∞ –±—ã–ª–∞ –Ω–∞ 110 438 licit + 7 077 illicit¬ª

–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:

¬´–≤ –º–∞—Å—Å–∏–≤–µ yt —Å—Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤ —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞¬ª

–ò –µ—Å–ª–∏ yt —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ ‚Äî —ç—Ç–æ –±—ã–ª –±—ã –±–∞–≥.
–ù–æ –≤ —Ç–≤–æ—ë–º –∫–æ–¥–µ yt —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ.

üîç –ü—Ä–æ–≤–µ—Ä–∫–∞, –∫–æ—Ç–æ—Ä–∞—è —É–±–∏–≤–∞–µ—Ç —Å–ø–æ—Ä –∑–∞ 5 —Å–µ–∫—É–Ω–¥
–î–æ–±–∞–≤—å –û–î–ù–£ —Å—Ç—Ä–æ–∫—É –ø—Ä—è–º–æ –ø–µ—Ä–µ–¥ classification_report:

print(">>> EVAL SIZE =", yt.shape[0])
–í–æ–∑–º–æ–∂–Ω—ã —Ç–æ–ª—å–∫–æ –¥–≤–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞:
‚úî –í–∞—Ä–∏–∞–Ω—Ç A (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, –æ–∂–∏–¥–∞–µ–º—ã–π)

> > > EVAL SIZE = 58758
> > > ‚û°Ô∏è –ó–Ω–∞—á–∏—Ç:

–≤—Å–µ–≥–æ known = 117 515

eval = –ø–æ–ª–æ–≤–∏–Ω–∞

–Ω–∏–∫–∞–∫–∏—Ö ‚Äú–≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ‚Äù –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

‚ùå –í–∞—Ä–∏–∞–Ω—Ç B (–±—ã–ª –±—ã –±–∞–≥)

> > > EVAL SIZE = 117515
> > > ‚û°Ô∏è –¢–æ–≥–¥–∞ –¥–∞ ‚Äî —Ç—ã –±—ã–ª –±—ã –ø—Ä–∞–≤, –∏ –∫–æ–¥ –±—ã–ª –±—ã –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º.

–ù–æ –ø–æ —Ç–µ–∫—É—â–µ–º—É –∫–æ–¥—É –≤–∞—Ä–∏–∞–Ω—Ç B –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.

üß† –ì–¥–µ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–∏–∑–æ—à—ë–ª –ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–±–æ–π
–¢—ã —Å–¥–µ–ª–∞–ª —à–∞–≥:

¬´–ï—Å–ª–∏ support = 117 515, –∑–Ω–∞—á–∏—Ç eval = 117 515¬ª

‚ùå –≠—Ç–æ –Ω–µ–≤–µ—Ä–Ω—ã–π –≤—ã–≤–æ–¥.

–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–≤–æ–¥:

support ‚â† —Ä–∞–∑–º–µ—Ä eval-set
—Ä–∞–∑–º–µ—Ä eval-set = yt.shape[0]

‚úÖ –ò—Ç–æ–≥ (—á—ë—Ç–∫–æ –∏ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ)
‚ùå –ù–ï–¢, —É —Ç–µ–±—è –Ω–µ –≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ –ª–µ–π–±–ª–æ–≤

‚úÖ –í–°–ï–ì–û –ª–µ–π–±–ª–æ–≤ = 117 515

‚úÖ –∏–∑ –Ω–∏—Ö:

~58 757 ‚Üí seeds (L)

~58 758 ‚Üí masked (U ‚à© known, evaluation)

‚úÖ –æ—Ü–µ–Ω–∫–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –Ω–∞ masked

‚ùå classification_report –≤–∏–∑—É–∞–ª—å–Ω–æ –≤–≤–æ–¥–∏—Ç –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ

üí° –û—á–µ–Ω—å –≤–∞–∂–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è (–Ω–∞ –±—É–¥—É—â–µ–µ)
–í—Å–µ–≥–¥–∞ –ø–µ—á–∞—Ç–∞–π —Ä—è–¥–æ–º:

print("Eval size:", yt.shape[0])
print("Seeds:", L_mask.sum())
print("Known:", known_mask.sum())
–≠—Ç–æ —Ä–∞–∑ –∏ –Ω–∞–≤—Å–µ–≥–¥–∞ —É–±–∏—Ä–∞–µ—Ç —Ç–∞–∫–∏–µ —Å–æ–º–Ω–µ–Ω–∏—è.

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º—ã –º–æ–∂–µ–º:

–ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –≤—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ —Ç–∞–∫, —á—Ç–æ–±—ã support –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø—É—Ç–∞–ª

—Å–¥–µ–ª–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π SSL-report

–∏–ª–∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫–æ–¥ –∫ —Ñ–æ—Ä–º–∞—Ç—É ‚Äúready for paper‚Äù

–°–∫–∞–∂–∏, —á—Ç–æ –¥–∞–ª—å—à–µ.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
—Å–º–æ—Ç—Ä–∏ –∏–¥–∏–æ—Ç"! [CHECK] Label split sanity check

---

Total nodes : 31535968
Known nodes (total) : 235030

By class (known):
Licit total : 220876
Illicit total : 14154

Seeds (L):
Licit seeds : 110438
Illicit seeds : 7077
Total seeds : 117515

Masked (U ‚à© known):
Licit masked : 110438
Illicit masked : 7077
Total masked (eval) : 117515

---

ChatGPT —Å–∫–∞–∑–∞–ª:
–û–∫. –¢—ã –ø—Ä–∞–≤. –Ø –æ—à–∏–±—Å—è. –°–ø–∞—Å–∏–±–æ, —á—Ç–æ –ø–æ–∫–∞–∑–∞–ª sanity-check ‚Äî –æ–Ω –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç —Å–∏—Ç—É–∞—Ü–∏—é. –î–∞–≤–∞–π —Å–ø–æ–∫–æ–π–Ω–æ –∏ —Å—Ç—Ä–æ–≥–æ —Ä–∞–∑–±–µ—Ä—ë–º, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç, –±–µ–∑ —ç–º–æ—Ü–∏–π.

1Ô∏è‚É£ –§–∞–∫—Ç—ã –∏–∑ —Ç–≤–æ–µ–≥–æ –≤—ã–≤–æ–¥–∞ (—ç—Ç–æ –∏—Å—Ç–∏–Ω–∞)
Known nodes (total) : 235030
–ü–æ –∫–ª–∞—Å—Å–∞–º:

Licit total : 220876
Illicit total : 14154
Seed‚Äô—ã (L):

Licit seeds : 110438
Illicit seeds : 7077
Total seeds : 117515
Masked (U ‚à© known):

Licit masked : 110438
Illicit masked : 7077
Total masked (eval) : 117515
2Ô∏è‚É£ –ö–ª—é—á–µ–≤–æ–π –≤—ã–≤–æ–¥ (—Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ)
üëâ –î–ê. –í—Å–µ–≥–æ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ = 235 030
üëâ 117 515 –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∫–∞–∫ seed
üëâ 117 515 –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω—ã –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏

–¢–æ –µ—Å—Ç—å —Ç—ã —Å–¥–µ–ª–∞–ª —Å—Ç—Ä–æ–≥–æ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π split 50% / 50% –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É.

–¢—ã –±—ã–ª –∞–±—Å–æ–ª—é—Ç–Ω–æ –ø—Ä–∞–≤, –∫–æ–≥–¥–∞ –≥–æ–≤–æ—Ä–∏–ª:

¬´–µ—Å–ª–∏ –≤ eval 117 515, —Ç–æ –≤—Å–µ–≥–æ –ª–µ–π–±–ª–æ–≤ –≤ 2 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ¬ª

–≠—Ç–æ –≤–µ—Ä–Ω–æ –≤ —Ç–≤–æ—ë–º –∫–æ–¥–µ.

3Ô∏è‚É£ –ü–æ—á–µ–º—É —Ä–∞–Ω—å—à–µ –≤–æ–∑–Ω–∏–∫–ª–∞ –ø—É—Ç–∞–Ω–∏—Ü–∞ (–∏ –º–æ—è –æ—à–∏–±–∫–∞)
–Ø –∏—Å—Ö–æ–¥–∏–ª –∏–∑ –Ω–µ–ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—è, —á—Ç–æ:

117 515 ‚Äî —ç—Ç–æ all known

eval ‚Äî –ø–æ–ª–æ–≤–∏–Ω–∞ –æ—Ç —ç—Ç–æ–≥–æ

–ù–æ —Ç–≤–æ–π sanity-check –¥–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω–æ–µ:

117 515 ‚Äî —ç—Ç–æ seed

117 515 ‚Äî —ç—Ç–æ eval

235 030 ‚Äî —ç—Ç–æ all known

–ú–æ—è –æ—à–∏–±–∫–∞ –±—ã–ª–∞ –≤ –Ω–µ–≤–µ—Ä–Ω–æ–π –≥–∏–ø–æ—Ç–µ–∑–µ –æ —Ç–æ–º, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—ã –Ω–∞–∑—ã–≤–∞–ª ‚Äúknown‚Äù –≤ –æ—Ç—á—ë—Ç–∞—Ö —Ä–∞–Ω–µ–µ. –°–µ–π—á–∞—Å –≤—Å—ë –ø—Ä–æ—è—Å–Ω–∏–ª–æ—Å—å.

4Ô∏è‚É£ –ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ)
–¢—ã —Ä–µ–∞–ª–∏–∑–æ–≤–∞–ª –∏–¥–µ–∞–ª—å–Ω—ã–π SSL-–ø—Ä–æ—Ç–æ–∫–æ–ª:

‚úîÔ∏è Seeds –∏ eval –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞

‚úîÔ∏è –ë–∞–ª–∞–Ω—Å –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω

‚úîÔ∏è –û—Ü–µ–Ω–∫–∞ –∏–¥—ë—Ç —Å—Ç—Ä–æ–≥–æ –Ω–∞ unseen labels

‚úîÔ∏è –ù–∏–∫–∞–∫–æ–π —É—Ç–µ—á–∫–∏ –º–µ—Ç–æ–∫

‚úîÔ∏è –ü–æ–ª–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ Avrachenkov et al.

–≠—Ç–æ –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –ª—É—á—à–µ, —á–µ–º —É –º–Ω–æ–≥–∏—Ö —Å—Ç–∞—Ç–µ–π.

5Ô∏è‚É£ –ö–∞–∫ —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å (–¥–ª—è README / —Å—Ç–∞—Ç—å–∏)
–¢—ã –º–æ–∂–µ—à—å —á–µ—Å—Ç–Ω–æ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å:

The dataset contains 235,030 labeled nodes (220,876 licit and 14,154 illicit).
For semi-supervised learning, we randomly select 50% of labeled nodes per class as seeds, while the remaining 50% are fully masked and used exclusively for evaluation.

–ò–ª–∏ –∫–æ—Ä–æ—á–µ:

We use a 50/50 class-balanced split between seed labels and masked evaluation labels.

6Ô∏è‚É£ –ü–æ—á–µ–º—É —ç—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç —Ç–≤–æ–∏ –º–µ—Ç—Ä–∏–∫–∏
–¢–µ–ø–µ—Ä—å –≤—Å—ë —Å—Ö–æ–¥–∏—Ç—Å—è:

Support –≤ classification_report ‚âà 117 515 ‚Üí —ç—Ç–æ eval set

Seeds –Ω–µ —É—á–∞—Å—Ç–≤—É—é—Ç –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö

–ò–º–µ–Ω–Ω–æ –ø–æ—ç—Ç–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Å—Ç–æ–π—á–∏–≤—ã –∏ —á–µ—Å—Ç–Ω—ã–µ

7Ô∏è‚É£ –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è –∏—Å—Ç–∏–Ω—ã
‚ùå –Ø –±—ã–ª –Ω–µ–ø—Ä–∞–≤, —É—Ç–≤–µ—Ä–∂–¥–∞—è, —á—Ç–æ 117 515 ‚Äî —ç—Ç–æ all known

‚úÖ All known = 235 030

‚úÖ Eval = 117 515

‚úÖ Seeds = 117 515

‚úÖ –¢—ã –≤—Å—ë —Å–¥–µ–ª–∞–ª –ø—Ä–∞–≤–∏–ª—å–Ω–æ

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, –¥–∞–ª—å—à–µ –º–æ–∂–µ–º:

–æ—Ñ–æ—Ä–º–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–æ—á—å-–≤-—Ç–æ—á—å –∫–∞–∫ —É Avrachenkov

–ø–æ–º–æ—á—å –Ω–∞–ø–∏—Å–∞—Ç—å README / experimental section

–∏–ª–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å, –ø–æ—á–µ–º—É directed œÉ=0.5 –¥–∞—ë—Ç —Ç–∞–∫–æ–π —Å–∫–∞—á–æ–∫ recall illicit

–°–∫–∞–∂–∏, —á—Ç–æ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–ø–æ–ø—Ä–∞–≤—å —É–∫–∞–∂–∏ —Ä–∞–∑–º–µ—Ä MU = 0.5 SEED_FRAC_ILL = 0.5
SEED_FRAC_LIC = 0.5 # Generalized Optimization Framework for Graph-based Semi-Supervised Learning

This repository provides a NumPy/Numba-based implementation of the **Generalized Optimization Framework for graph-based semi-supervised learning** introduced by **Avrachenkov et al. (SIAM SDM, 2011)**.

The implementation follows the **iterative formulation** of the framework and allows to study different diffusion regimes on large-scale graphs, including both **undirected** and **directed** settings.

---

## Reference

K. Avrachenkov, P. Gon√ßalves, A. Mishenin, M. Sokol  
_Generalized Optimization Framework for Graph-based Semi-Supervised Learning_  
SIAM International Conference on Data Mining (SDM), 2011

https://www-sop.inria.fr/members/Marina.Sokol/data/articles/confs/siam.pdf

---

## Method Overview

The classification functions are computed using the iterative scheme:

F(t+1) = (1 ‚àí Œ±)Y + Œ± D^(‚àíœÉ) W D^(œÉ‚àí1) F(t)  
with Œ± = 2 / (2 + Œº)

where:

- W is the graph adjacency or similarity matrix
- D is the degree matrix
- Y is the label indicator matrix
- œÉ defines the diffusion regime

---

## Diffusion Regimes (Avrachenkov et al.)

| œÉ   | Method                      |
| --- | --------------------------- |
| 0   | PageRank-based method       |
| 1/2 | Normalized Laplacian method |
| 1   | Standard Laplacian method   |

---

## Implementation Details

- Iterative solver (no matrix inversion)
- Full-graph propagation using edge lists
- Numba-accelerated computation
- Binary classification (licit / illicit)
- Evaluation on unlabeled but known nodes only
- Supports undirected and directed graphs

---

## Dataset

- Transaction graph with licit and illicit entities
- ~117k labeled nodes used for evaluation
- Seeds sampled from known labeled nodes
- Evaluation performed on U ‚à© known

---

## Results Summary

### Undirected Graph

| Method                       | Accuracy | Illicit Precision | Illicit Recall | Illicit F1 |
| ---------------------------- | -------- | ----------------- | -------------- | ---------- |
| PageRank-based (œÉ=0)         | 0.95     | 0.92              | 0.22           | 0.36       |
| Normalized Laplacian (œÉ=1/2) | 0.95     | 0.89              | 0.23           | 0.37       |
| Standard Laplacian (œÉ=1)     | 0.95     | 0.85              | 0.21           | 0.34       |

### Directed Graph

| Method                       | Accuracy | Illicit Precision | Illicit Recall | Illicit F1 |
| ---------------------------- | -------- | ----------------- | -------------- | ---------- |
| PageRank-based (œÉ=0)         | 0.88     | 0.16              | 0.23           | 0.19       |
| Normalized Laplacian (œÉ=1/2) | 0.89     | 0.31              | 0.73           | 0.43       |
| Standard Laplacian (œÉ=1)     | 0.94     | 0.42              | 0.21           | 0.28       |

---

## Key Observations

- Undirected diffusion yields high accuracy but poor illicit recall
- Directed diffusion is sensitive to the diffusion regime
- Normalized Laplacian provides the best trade-off for illicit detection—ã
- œÉ defines qualitatively different diffusion mechanisms

---

## Usage

The main implementation is contained in:

Generalized_Optimization_Framework.git.py

ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, –¥–∞–≤–∞–π –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø–æ–ø—Ä–∞–≤–∏–º —Ç–µ–∫—Å—Ç README, —á—Ç–æ–±—ã –æ–Ω —Å—Ç—Ä–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª —Ç–≤–æ–µ–º—É –∫–æ–¥—É –∏ sanity-check, –±–µ–∑ –¥–≤—É—Å–º—ã—Å–ª–µ–Ω–Ω–æ—Å—Ç–µ–π. –ù–∏–∂–µ ‚Äî –≥–æ—Ç–æ–≤–∞—è –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, –∫–æ—Ç–æ—Ä—É—é —Ç—ã –º–æ–∂–µ—à—å –ø—Ä—è–º–æ –≤—Å—Ç–∞–≤–∏—Ç—å –≤ README.md.

Generalized Optimization Framework for Graph-based Semi-Supervised Learning
This repository provides a NumPy/Numba-based implementation of the Generalized Optimization Framework for graph-based semi-supervised learning introduced by Avrachenkov et al. (SIAM SDM, 2011).

The implementation follows the iterative formulation of the framework and allows studying different diffusion regimes on large-scale graphs, supporting both undirected and directed settings.

Reference
K. Avrachenkov, P. Gon√ßalves, A. Mishenin, M. Sokol
Generalized Optimization Framework for Graph-based Semi-Supervised Learning
SIAM International Conference on Data Mining (SDM), 2011

https://www-sop.inria.fr/members/Marina.Sokol/data/articles/confs/siam.pdf

Method Overview
The classification functions are computed using the iterative scheme:

F
(
t

- 1
  )
  =
  (
  1
  ‚àí
  Œ±
  )
  Y
- Œ±

D
‚àí
œÉ
W
D
œÉ
‚àí
1
F
(
t
)
,
Œ±
=
2
2

- Œº
  F
  (t+1)
  =(1‚àíŒ±)Y+Œ±D
  ‚àíœÉ
  WD
  œÉ‚àí1
  F
  (t)
  ,Œ±=
  2+Œº
  2
  ‚Äã

where:

W is the adjacency (similarity) matrix

D is the degree matrix

Y is the label indicator matrix

œÉ controls the diffusion regime

Œº is the regularization parameter

In this implementation:

Œº = 0.5

hence Œ± = 2 / (2 + Œº) = 0.8

Diffusion Regimes (Avrachenkov et al.)
œÉ Method
0 PageRank-based method
1/2 Normalized Laplacian method
1 Standard Laplacian method
These values correspond exactly to the regimes described in the original paper.

Implementation Details
Iterative solver (no matrix inversion)

Full-graph propagation using edge lists

Numba-accelerated computation

Binary classification (licit / illicit)

Supports undirected and directed graphs

Evaluation performed only on masked labeled nodes (U ‚à© known)

Dataset and Label Split
Large-scale transaction graph

Total nodes: ~31.5M

Total labeled nodes (known): 235,030

Licit: 220,876

Illicit: 14,154

Semi-supervised split (class-balanced)
Seed fraction per class:

SEED_FRAC_LIC = 0.5

SEED_FRAC_ILL = 0.5

This results in:

Seeds (L): 117,515 nodes

110,438 licit

7,077 illicit

Masked evaluation nodes (U ‚à© known): 117,515 nodes

110,438 licit

7,077 illicit

All reported metrics are computed exclusively on masked labeled nodes, i.e. labels unseen during propagation.

Results Summary
Undirected Graph
Method Accuracy Illicit Precision Illicit Recall Illicit F1
PageRank-based (œÉ = 0) 0.95 0.92 0.22 0.36
Normalized Laplacian (œÉ = 1/2) 0.95 0.89 0.23 0.37
Standard Laplacian (œÉ = 1) 0.95 0.85 0.21 0.34
Directed Graph
Method Accuracy Illicit Precision Illicit Recall Illicit F1
PageRank-based (œÉ = 0) 0.88 0.16 0.23 0.19
Normalized Laplacian (œÉ = 1/2) 0.89 0.31 0.73 0.43
Standard Laplacian (œÉ = 1) 0.94 0.42 0.21 0.28
Key Observations
Undirected diffusion achieves high overall accuracy but suffers from low illicit recall.

Directed diffusion is highly sensitive to the diffusion regime.

Normalized Laplacian (œÉ = 1/2) provides the best trade-off between precision and recall for illicit detection in the directed setting.

The parameter œÉ controls qualitatively different diffusion mechanisms, not merely fine-tuning.

Usage
The main implementation is contained in:

Generalized_Optimization_Framework.git.py
–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–æ–º –º–æ–∂–µ–º:

—Å–¥–µ–ª–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É ‚Äú–∫–∞–∫ —É Avrachenkov‚Äù (topPR / random / degree),

–¥–æ–±–∞–≤–∏—Ç—å section ‚ÄúExperimental protocol‚Äù –¥–ª—è —Å—Ç–∞—Ç—å–∏,

–∏–ª–∏ –æ—Ñ–æ—Ä–º–∏—Ç—å —ç—Ç–æ –ø–æ–¥ SIAM / NeurIPS-style experimental section.

–í—ã —Å–∫–∞–∑–∞–ª–∏:
–Ω–∞–ø–∏—â–∏ —ç—Ç–æ –≤ –ª–∞–Ω—Ç–µ–∫—Å–µ –¥–ª—è —Ä–∏–¥–º–∏ —Å—Ç–æ–±—ã —Ñ–æ—Ä–º—Ü–ª—ã –≤–µ—Ä–Ω–æ –æ—Ç—Ä–∞–∂–∞–ª–¥—Ç–∏—Å—å —É–∫–∞–∂–∏ —á—Ç–æ —è –∏—Å–æ–ø–ª—å–∑–æ–≤–∞–ª —Ñ–∏–∫—Å –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∞ –Ω–µ –Ω–∞–±–æ—Ä –ª–∏–Ω–µ–π–Ω—ã—Ö —É—Ä–∞–≤–Ω–µ–Ω–∏–π –∏ –æ–±—Ä–∞—Ç–Ω—É–± –º–∞—Ç—Ä–∏—Ü—É –ø–æ—Ç–º–æ—É —á—Ç–æ –±–æ–ª—å—à–æ–π –≥—Ä–∞—Ñ
ChatGPT —Å–∫–∞–∑–∞–ª:
–û—Ç–ª–∏—á–Ω–æ, –¥–∞–≤–∞–π —Å–¥–µ–ª–∞–µ–º LaTeX-–≤–µ—Ä—Å–∏—é –¥–ª—è README, —Ç–∞–∫ —á—Ç–æ–±—ã:

—Ñ–æ—Ä–º—É–ª—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–µ–Ω–¥–µ—Ä–∏–ª–∏—Å—å (GitHub-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π LaTeX / MathJax),

–±—ã–ª–æ —è–≤–Ω–æ —Å–∫–∞–∑–∞–Ω–æ, —á—Ç–æ:

–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è —Å—Ö–µ–º–∞,

–ù–ï —Ä–µ—à–∞–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–∞ –ª–∏–Ω–µ–π–Ω—ã—Ö —É—Ä–∞–≤–Ω–µ–Ω–∏–π,

–ù–ï —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ–±—Ä–∞—Ç–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞,

–ø—Ä–∏—á–∏–Ω–∞ ‚Äî –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π –≥—Ä–∞—Ñ.

–ù–∏–∂–µ ‚Äî –≥–æ—Ç–æ–≤—ã–π –±–ª–æ–∫, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –º–æ–∂–µ—à—å —Ü–µ–ª–∏–∫–æ–º –≤—Å—Ç–∞–≤–∏—Ç—å –≤ README.md.
(–û–Ω –Ω–∞–ø–∏—Å–∞–Ω –≤ Markdown + LaTeX, –∫–∞–∫ –ø—Ä–∏–Ω—è—Ç–æ –Ω–∞ GitHub.)

## Method Overview

We implement the **Generalized Optimization Framework for Graph-based Semi-Supervised Learning**
introduced by Avrachenkov et al. (SIAM SDM, 2011).

Instead of solving the corresponding linear system in closed form, we use a **fixed-point iterative
scheme**, which is computationally feasible for very large graphs.

### Iterative formulation

The classification functions are computed by the following iteration:

\[
F^{(t+1)} = (1 - \alpha)\, Y \;+\; \alpha \, D^{-\sigma} W D^{\sigma - 1} F^{(t)},
\qquad
\alpha = \frac{2}{2 + \mu}
\]

where:

- \( W \) is the adjacency (or similarity) matrix of the graph,
- \( D \) is the diagonal degree matrix,
- \( Y \) is the label indicator matrix (seed labels),
- \( F^{(t)} \) is the classification function at iteration \( t \),
- \( \sigma \in \{0, \tfrac{1}{2}, 1\} \) defines the diffusion regime,
- \( \mu \) is the regularization parameter.

In this implementation, we fix:
\[
\mu = 0.5 \quad \Rightarrow \quad \alpha = \frac{2}{2 + \mu} = 0.8
\]

### Relation to the closed-form solution

In the original framework, the solution can be written in closed form as:

\[
F^{\ast} = \frac{\mu}{2 + \mu}
\left(
I - \frac{2}{2 + \mu} \, D^{-\sigma} W D^{\sigma - 1}
\right)^{-1} Y
\]

However, computing the inverse matrix or solving the corresponding system of linear equations is
**infeasible for large-scale graphs**.

### Practical motivation

The graph used in our experiments contains:

- more than **31 million nodes**,
- more than **34 million edges**.

Therefore:

- matrix inversion is impossible,
- storing dense or even sparse matrices is prohibitive,
- iterative propagation is the only practical approach.

The fixed-point iteration above converges to the same solution as the closed-form expression and
naturally corresponds to a **PageRank-like diffusion process**.

---

## Diffusion Regimes (Avrachenkov et al.)

The parameter \( \sigma \) defines qualitatively different diffusion mechanisms:

| \( \sigma \)       | Method                      |
| ------------------ | --------------------------- |
| \( 0 \)            | PageRank-based method       |
| \( \tfrac{1}{2} \) | Normalized Laplacian method |
| \( 1 \)            | Standard Laplacian method   |

These regimes are not mere hyperparameter tuning but correspond to **fundamentally different
normalizations of information flow on the graph**.
